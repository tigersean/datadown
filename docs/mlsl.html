<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第8章 统计模型 | 数据分析残卷</title>
  <meta name="description" content="数据分析世界的清明上河图" />
  <meta name="generator" content="bookdown 0.27 and GitBook 2.6.7" />

  <meta property="og:title" content="第8章 统计模型 | 数据分析残卷" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="数据分析世界的清明上河图" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第8章 统计模型 | 数据分析残卷" />
  
  <meta name="twitter:description" content="数据分析世界的清明上河图" />
  

<meta name="author" content="于淼" />


<meta name="date" content="2022-07-09" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="opt.html"/>
<link rel="next" href="product.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">数据分析残卷</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>序</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> 导论</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#数据科学"><i class="fa fa-check"></i><b>1.1</b> 数据科学</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#基本问题"><i class="fa fa-check"></i><b>1.2</b> 基本问题</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#工作流程"><i class="fa fa-check"></i><b>1.3</b> 工作流程</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#概率与分布"><i class="fa fa-check"></i><b>1.4</b> 概率与分布</a></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#统计量"><i class="fa fa-check"></i><b>1.5</b> 统计量</a></li>
<li class="chapter" data-level="1.6" data-path="intro.html"><a href="intro.html#si"><i class="fa fa-check"></i><b>1.6</b> 统计推断</a></li>
<li class="chapter" data-level="1.7" data-path="intro.html"><a href="intro.html#sm"><i class="fa fa-check"></i><b>1.7</b> 统计模型</a></li>
<li class="chapter" data-level="1.8" data-path="intro.html"><a href="intro.html#其他主题"><i class="fa fa-check"></i><b>1.8</b> 其他主题</a></li>
<li class="chapter" data-level="1.9" data-path="intro.html"><a href="intro.html#应用"><i class="fa fa-check"></i><b>1.9</b> 应用</a></li>
<li class="chapter" data-level="1.10" data-path="intro.html"><a href="intro.html#链接"><i class="fa fa-check"></i><b>1.10</b> 链接</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="tool.html"><a href="tool.html"><i class="fa fa-check"></i><b>2</b> 数据分析工具</a>
<ul>
<li class="chapter" data-level="2.1" data-path="tool.html"><a href="tool.html#基础知识"><i class="fa fa-check"></i><b>2.1</b> 基础知识</a></li>
<li class="chapter" data-level="2.2" data-path="tool.html"><a href="tool.html#命令行基础"><i class="fa fa-check"></i><b>2.2</b> 命令行基础</a></li>
<li class="chapter" data-level="2.3" data-path="tool.html"><a href="tool.html#版本控制"><i class="fa fa-check"></i><b>2.3</b> 版本控制</a></li>
<li class="chapter" data-level="2.4" data-path="tool.html"><a href="tool.html#数据获取"><i class="fa fa-check"></i><b>2.4</b> 数据获取</a></li>
<li class="chapter" data-level="2.5" data-path="tool.html"><a href="tool.html#远程控制"><i class="fa fa-check"></i><b>2.5</b> 远程控制</a></li>
<li class="chapter" data-level="2.6" data-path="tool.html"><a href="tool.html#高级命令"><i class="fa fa-check"></i><b>2.6</b> 高级命令</a></li>
<li class="chapter" data-level="2.7" data-path="tool.html"><a href="tool.html#r"><i class="fa fa-check"></i><b>2.7</b> R</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="tool.html"><a href="tool.html#语言导论"><i class="fa fa-check"></i><b>2.7.1</b> 语言导论</a></li>
<li class="chapter" data-level="2.7.2" data-path="tool.html"><a href="tool.html#获得帮助"><i class="fa fa-check"></i><b>2.7.2</b> 获得帮助</a></li>
<li class="chapter" data-level="2.7.3" data-path="tool.html"><a href="tool.html#数据类型及基本运算"><i class="fa fa-check"></i><b>2.7.3</b> 数据类型及基本运算</a></li>
<li class="chapter" data-level="2.7.4" data-path="tool.html"><a href="tool.html#环境文件操作"><i class="fa fa-check"></i><b>2.7.4</b> 环境／文件操作</a></li>
<li class="chapter" data-level="2.7.5" data-path="tool.html"><a href="tool.html#下载"><i class="fa fa-check"></i><b>2.7.5</b> 下载</a></li>
<li class="chapter" data-level="2.7.6" data-path="tool.html"><a href="tool.html#截取数据"><i class="fa fa-check"></i><b>2.7.6</b> 截取数据</a></li>
<li class="chapter" data-level="2.7.7" data-path="tool.html"><a href="tool.html#读取数据"><i class="fa fa-check"></i><b>2.7.7</b> 读取数据</a></li>
<li class="chapter" data-level="2.7.8" data-path="tool.html"><a href="tool.html#数据总结"><i class="fa fa-check"></i><b>2.7.8</b> 数据总结</a></li>
<li class="chapter" data-level="2.7.9" data-path="tool.html"><a href="tool.html#数据整理"><i class="fa fa-check"></i><b>2.7.9</b> 数据整理</a></li>
<li class="chapter" data-level="2.7.10" data-path="tool.html"><a href="tool.html#数据操作data.table包"><i class="fa fa-check"></i><b>2.7.10</b> <span><em>数据操作data.table包</em></span></a></li>
<li class="chapter" data-level="2.7.11" data-path="tool.html"><a href="tool.html#文本处理"><i class="fa fa-check"></i><b>2.7.11</b> 文本处理</a></li>
<li class="chapter" data-level="2.7.12" data-path="tool.html"><a href="tool.html#控制结构"><i class="fa fa-check"></i><b>2.7.12</b> 控制结构</a></li>
<li class="chapter" data-level="2.7.13" data-path="tool.html"><a href="tool.html#函数"><i class="fa fa-check"></i><b>2.7.13</b> 函数</a></li>
<li class="chapter" data-level="2.7.14" data-path="tool.html"><a href="tool.html#编程标准"><i class="fa fa-check"></i><b>2.7.14</b> 编程标准</a></li>
<li class="chapter" data-level="2.7.15" data-path="tool.html"><a href="tool.html#范围规则"><i class="fa fa-check"></i><b>2.7.15</b> 范围规则</a></li>
<li class="chapter" data-level="2.7.16" data-path="tool.html"><a href="tool.html#向量化操作"><i class="fa fa-check"></i><b>2.7.16</b> 向量化操作</a></li>
<li class="chapter" data-level="2.7.17" data-path="tool.html"><a href="tool.html#绘图系统"><i class="fa fa-check"></i><b>2.7.17</b> 绘图系统</a></li>
<li class="chapter" data-level="2.7.18" data-path="tool.html"><a href="tool.html#日期与时间"><i class="fa fa-check"></i><b>2.7.18</b> 日期与时间</a></li>
<li class="chapter" data-level="2.7.19" data-path="tool.html"><a href="tool.html#循环"><i class="fa fa-check"></i><b>2.7.19</b> 循环</a></li>
<li class="chapter" data-level="2.7.20" data-path="tool.html"><a href="tool.html#模拟"><i class="fa fa-check"></i><b>2.7.20</b> 模拟</a></li>
<li class="chapter" data-level="2.7.21" data-path="tool.html"><a href="tool.html#调试"><i class="fa fa-check"></i><b>2.7.21</b> 调试</a></li>
<li class="chapter" data-level="2.7.22" data-path="tool.html"><a href="tool.html#分析代码"><i class="fa fa-check"></i><b>2.7.22</b> 分析代码</a></li>
<li class="chapter" data-level="2.7.23" data-path="tool.html"><a href="tool.html#包开发"><i class="fa fa-check"></i><b>2.7.23</b> 包开发</a></li>
<li class="chapter" data-level="2.7.24" data-path="tool.html"><a href="tool.html#方法与类型"><i class="fa fa-check"></i><b>2.7.24</b> 方法与类型</a></li>
<li class="chapter" data-level="2.7.25" data-path="tool.html"><a href="tool.html#并行计算"><i class="fa fa-check"></i><b>2.7.25</b> 并行计算</a></li>
<li class="chapter" data-level="2.7.26" data-path="tool.html"><a href="tool.html#分布式计算"><i class="fa fa-check"></i><b>2.7.26</b> 分布式计算</a></li>
<li class="chapter" data-level="2.7.27" data-path="tool.html"><a href="tool.html#异常值监测"><i class="fa fa-check"></i><b>2.7.27</b> 异常值监测</a></li>
<li class="chapter" data-level="2.7.28" data-path="tool.html"><a href="tool.html#图片处理"><i class="fa fa-check"></i><b>2.7.28</b> 图片处理</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="tool.html"><a href="tool.html#python"><i class="fa fa-check"></i><b>2.8</b> Python</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="tool.html"><a href="tool.html#工具包"><i class="fa fa-check"></i><b>2.8.1</b> 工具包</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="tool.html"><a href="tool.html#tex"><i class="fa fa-check"></i><b>2.9</b> Tex</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="tool.html"><a href="tool.html#语言基础"><i class="fa fa-check"></i><b>2.9.1</b> 语言基础</a></li>
<li class="chapter" data-level="2.9.2" data-path="tool.html"><a href="tool.html#关于xetex"><i class="fa fa-check"></i><b>2.9.2</b> 关于<code>xetex</code></a></li>
<li class="chapter" data-level="2.9.3" data-path="tool.html"><a href="tool.html#常见问题"><i class="fa fa-check"></i><b>2.9.3</b> 常见问题</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="repro.html"><a href="repro.html"><i class="fa fa-check"></i><b>3</b> 可复算性研究</a>
<ul>
<li class="chapter" data-level="3.1" data-path="repro.html"><a href="repro.html#replication"><i class="fa fa-check"></i><b>3.1</b> Replication</a></li>
<li class="chapter" data-level="3.2" data-path="repro.html"><a href="repro.html#reproducible"><i class="fa fa-check"></i><b>3.2</b> Reproducible</a></li>
<li class="chapter" data-level="3.3" data-path="repro.html"><a href="repro.html#研究流程"><i class="fa fa-check"></i><b>3.3</b> 研究流程</a></li>
<li class="chapter" data-level="3.4" data-path="repro.html"><a href="repro.html#数据分析步骤"><i class="fa fa-check"></i><b>3.4</b> 数据分析步骤</a></li>
<li class="chapter" data-level="3.5" data-path="repro.html"><a href="repro.html#数据分析文件结构"><i class="fa fa-check"></i><b>3.5</b> 数据分析文件结构</a></li>
<li class="chapter" data-level="3.6" data-path="repro.html"><a href="repro.html#文本化统计编程-knitr"><i class="fa fa-check"></i><b>3.6</b> 文本化统计编程-Knitr</a></li>
<li class="chapter" data-level="3.7" data-path="repro.html"><a href="repro.html#结果通讯"><i class="fa fa-check"></i><b>3.7</b> 结果通讯</a></li>
<li class="chapter" data-level="3.8" data-path="repro.html"><a href="repro.html#检查列表"><i class="fa fa-check"></i><b>3.8</b> 检查列表</a></li>
<li class="chapter" data-level="3.9" data-path="repro.html"><a href="repro.html#基于证据的数据分析"><i class="fa fa-check"></i><b>3.9</b> 基于证据的数据分析</a></li>
<li class="chapter" data-level="3.10" data-path="repro.html"><a href="repro.html#结果可解释"><i class="fa fa-check"></i><b>3.10</b> 结果可解释</a></li>
<li class="chapter" data-level="3.11" data-path="repro.html"><a href="repro.html#数据分析的理论"><i class="fa fa-check"></i><b>3.11</b> 数据分析的理论</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="exp.html"><a href="exp.html"><i class="fa fa-check"></i><b>4</b> 探索性数据分析</a>
<ul>
<li class="chapter" data-level="4.1" data-path="exp.html"><a href="exp.html#aces-模型"><i class="fa fa-check"></i><b>4.1</b> ACES 模型</a></li>
<li class="chapter" data-level="4.2" data-path="exp.html"><a href="exp.html#探索绘图原则"><i class="fa fa-check"></i><b>4.2</b> 探索绘图原则</a></li>
<li class="chapter" data-level="4.3" data-path="exp.html"><a href="exp.html#探索性绘图"><i class="fa fa-check"></i><b>4.3</b> 探索性绘图</a></li>
<li class="chapter" data-level="4.4" data-path="exp.html"><a href="exp.html#分层聚类"><i class="fa fa-check"></i><b>4.4</b> 分层聚类</a></li>
<li class="chapter" data-level="4.5" data-path="exp.html"><a href="exp.html#k-means聚类"><i class="fa fa-check"></i><b>4.5</b> k-means聚类</a></li>
<li class="chapter" data-level="4.6" data-path="exp.html"><a href="exp.html#维度还原"><i class="fa fa-check"></i><b>4.6</b> 维度还原</a></li>
<li class="chapter" data-level="4.7" data-path="exp.html"><a href="exp.html#可视化图形"><i class="fa fa-check"></i><b>4.7</b> 可视化图形</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="infer.html"><a href="infer.html"><i class="fa fa-check"></i><b>5</b> 统计推断</a>
<ul>
<li class="chapter" data-level="5.1" data-path="infer.html"><a href="infer.html#导论"><i class="fa fa-check"></i><b>5.1</b> 导论</a></li>
<li class="chapter" data-level="5.2" data-path="infer.html"><a href="infer.html#概率"><i class="fa fa-check"></i><b>5.2</b> 概率</a></li>
<li class="chapter" data-level="5.3" data-path="infer.html"><a href="infer.html#期望"><i class="fa fa-check"></i><b>5.3</b> 期望</a></li>
<li class="chapter" data-level="5.4" data-path="infer.html"><a href="infer.html#方差"><i class="fa fa-check"></i><b>5.4</b> 方差</a></li>
<li class="chapter" data-level="5.5" data-path="infer.html"><a href="infer.html#独立性"><i class="fa fa-check"></i><b>5.5</b> 独立性</a></li>
<li class="chapter" data-level="5.6" data-path="infer.html"><a href="infer.html#条件概率"><i class="fa fa-check"></i><b>5.6</b> 条件概率</a></li>
<li class="chapter" data-level="5.7" data-path="infer.html"><a href="infer.html#贝叶斯定理"><i class="fa fa-check"></i><b>5.7</b> 贝叶斯定理</a></li>
<li class="chapter" data-level="5.8" data-path="infer.html"><a href="infer.html#常见分布"><i class="fa fa-check"></i><b>5.8</b> 常见分布</a></li>
<li class="chapter" data-level="5.9" data-path="infer.html"><a href="infer.html#渐进"><i class="fa fa-check"></i><b>5.9</b> 渐进</a></li>
<li class="chapter" data-level="5.10" data-path="infer.html"><a href="infer.html#置信区间"><i class="fa fa-check"></i><b>5.10</b> 置信区间</a></li>
<li class="chapter" data-level="5.11" data-path="infer.html"><a href="infer.html#似然函数"><i class="fa fa-check"></i><b>5.11</b> 似然函数</a></li>
<li class="chapter" data-level="5.12" data-path="infer.html"><a href="infer.html#贝叶斯推断"><i class="fa fa-check"></i><b>5.12</b> 贝叶斯推断</a></li>
<li class="chapter" data-level="5.13" data-path="infer.html"><a href="infer.html#两独立样本t检验"><i class="fa fa-check"></i><b>5.13</b> 两独立样本t检验</a></li>
<li class="chapter" data-level="5.14" data-path="infer.html"><a href="infer.html#假设检验"><i class="fa fa-check"></i><b>5.14</b> 假设检验</a></li>
<li class="chapter" data-level="5.15" data-path="infer.html"><a href="infer.html#p值"><i class="fa fa-check"></i><b>5.15</b> P值</a></li>
<li class="chapter" data-level="5.16" data-path="infer.html"><a href="infer.html#功效"><i class="fa fa-check"></i><b>5.16</b> 功效</a></li>
<li class="chapter" data-level="5.17" data-path="infer.html"><a href="infer.html#多重比较"><i class="fa fa-check"></i><b>5.17</b> 多重比较</a></li>
<li class="chapter" data-level="5.18" data-path="infer.html"><a href="infer.html#重采样推断"><i class="fa fa-check"></i><b>5.18</b> 重采样推断</a></li>
<li class="chapter" data-level="5.19" data-path="infer.html"><a href="infer.html#概念可视化"><i class="fa fa-check"></i><b>5.19</b> 概念可视化</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="reg.html"><a href="reg.html"><i class="fa fa-check"></i><b>6</b> 回归模型</a>
<ul>
<li class="chapter" data-level="6.1" data-path="reg.html"><a href="reg.html#回归模型导论"><i class="fa fa-check"></i><b>6.1</b> 回归模型导论</a></li>
<li class="chapter" data-level="6.2" data-path="reg.html"><a href="reg.html#术语"><i class="fa fa-check"></i><b>6.2</b> 术语</a></li>
<li class="chapter" data-level="6.3" data-path="reg.html"><a href="reg.html#回归线的最小二乘回归"><i class="fa fa-check"></i><b>6.3</b> 回归线的最小二乘回归</a></li>
<li class="chapter" data-level="6.4" data-path="reg.html"><a href="reg.html#统计线性回归模型"><i class="fa fa-check"></i><b>6.4</b> 统计线性回归模型</a></li>
<li class="chapter" data-level="6.5" data-path="reg.html"><a href="reg.html#残差"><i class="fa fa-check"></i><b>6.5</b> 残差</a></li>
<li class="chapter" data-level="6.6" data-path="reg.html"><a href="reg.html#回归推断"><i class="fa fa-check"></i><b>6.6</b> 回归推断</a></li>
<li class="chapter" data-level="6.7" data-path="reg.html"><a href="reg.html#多元回归"><i class="fa fa-check"></i><b>6.7</b> 多元回归</a></li>
<li class="chapter" data-level="6.8" data-path="reg.html"><a href="reg.html#模型诊断与选择"><i class="fa fa-check"></i><b>6.8</b> 模型诊断与选择</a></li>
<li class="chapter" data-level="6.9" data-path="reg.html"><a href="reg.html#广义线性模型"><i class="fa fa-check"></i><b>6.9</b> 广义线性模型</a></li>
<li class="chapter" data-level="6.10" data-path="reg.html"><a href="reg.html#二元响应"><i class="fa fa-check"></i><b>6.10</b> 二元响应</a></li>
<li class="chapter" data-level="6.11" data-path="reg.html"><a href="reg.html#计数或速率响应"><i class="fa fa-check"></i><b>6.11</b> 计数或速率响应</a></li>
<li class="chapter" data-level="6.12" data-path="reg.html"><a href="reg.html#分段平滑"><i class="fa fa-check"></i><b>6.12</b> 分段平滑</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="opt.html"><a href="opt.html"><i class="fa fa-check"></i><b>7</b> 最优化</a>
<ul>
<li class="chapter" data-level="7.1" data-path="opt.html"><a href="opt.html#数学本质"><i class="fa fa-check"></i><b>7.1</b> 数学本质</a></li>
<li class="chapter" data-level="7.2" data-path="opt.html"><a href="opt.html#简史"><i class="fa fa-check"></i><b>7.2</b> 简史</a></li>
<li class="chapter" data-level="7.3" data-path="opt.html"><a href="opt.html#最小二乘法"><i class="fa fa-check"></i><b>7.3</b> 最小二乘法</a></li>
<li class="chapter" data-level="7.4" data-path="opt.html"><a href="opt.html#线性规划"><i class="fa fa-check"></i><b>7.4</b> 线性规划</a></li>
<li class="chapter" data-level="7.5" data-path="opt.html"><a href="opt.html#凸优化"><i class="fa fa-check"></i><b>7.5</b> 凸优化</a></li>
<li class="chapter" data-level="7.6" data-path="opt.html"><a href="opt.html#仿射集"><i class="fa fa-check"></i><b>7.6</b> 仿射集</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mlsl.html"><a href="mlsl.html"><i class="fa fa-check"></i><b>8</b> 统计模型</a>
<ul>
<li class="chapter" data-level="8.1" data-path="mlsl.html"><a href="mlsl.html#统计学习概论"><i class="fa fa-check"></i><b>8.1</b> 统计学习概论</a></li>
<li class="chapter" data-level="8.2" data-path="mlsl.html"><a href="mlsl.html#统计学习简史"><i class="fa fa-check"></i><b>8.2</b> 统计学习简史</a></li>
<li class="chapter" data-level="8.3" data-path="mlsl.html"><a href="mlsl.html#统计学习定义"><i class="fa fa-check"></i><b>8.3</b> 统计学习定义</a></li>
<li class="chapter" data-level="8.4" data-path="mlsl.html"><a href="mlsl.html#预测"><i class="fa fa-check"></i><b>8.4</b> 预测</a></li>
<li class="chapter" data-level="8.5" data-path="mlsl.html"><a href="mlsl.html#推断"><i class="fa fa-check"></i><b>8.5</b> 推断</a></li>
<li class="chapter" data-level="8.6" data-path="mlsl.html"><a href="mlsl.html#估计模型"><i class="fa fa-check"></i><b>8.6</b> 估计模型</a></li>
<li class="chapter" data-level="8.7" data-path="mlsl.html"><a href="mlsl.html#评价模型"><i class="fa fa-check"></i><b>8.7</b> 评价模型</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="mlsl.html"><a href="mlsl.html#拟合质量测量"><i class="fa fa-check"></i><b>8.7.1</b> 拟合质量测量</a></li>
<li class="chapter" data-level="8.7.2" data-path="mlsl.html"><a href="mlsl.html#聚类评价"><i class="fa fa-check"></i><b>8.7.2</b> 聚类评价</a></li>
</ul></li>
<li class="chapter" data-level="8.8" data-path="mlsl.html"><a href="mlsl.html#研究设计"><i class="fa fa-check"></i><b>8.8</b> 研究设计</a></li>
<li class="chapter" data-level="8.9" data-path="mlsl.html"><a href="mlsl.html#错误率"><i class="fa fa-check"></i><b>8.9</b> 错误率</a></li>
<li class="chapter" data-level="8.10" data-path="mlsl.html"><a href="mlsl.html#roc-曲线"><i class="fa fa-check"></i><b>8.10</b> ROC 曲线</a></li>
<li class="chapter" data-level="8.11" data-path="mlsl.html"><a href="mlsl.html#重采样技术"><i class="fa fa-check"></i><b>8.11</b> 重采样技术</a>
<ul>
<li class="chapter" data-level="8.11.1" data-path="mlsl.html"><a href="mlsl.html#交叉检验"><i class="fa fa-check"></i><b>8.11.1</b> 交叉检验</a></li>
<li class="chapter" data-level="8.11.2" data-path="mlsl.html"><a href="mlsl.html#bootstrap"><i class="fa fa-check"></i><b>8.11.2</b> bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="8.12" data-path="mlsl.html"><a href="mlsl.html#caret-包"><i class="fa fa-check"></i><b>8.12</b> <code>caret</code> 包</a></li>
<li class="chapter" data-level="8.13" data-path="mlsl.html"><a href="mlsl.html#数据分割"><i class="fa fa-check"></i><b>8.13</b> 数据分割</a></li>
<li class="chapter" data-level="8.14" data-path="mlsl.html"><a href="mlsl.html#训练选项"><i class="fa fa-check"></i><b>8.14</b> 训练选项</a></li>
<li class="chapter" data-level="8.15" data-path="mlsl.html"><a href="mlsl.html#预测变量作图"><i class="fa fa-check"></i><b>8.15</b> 预测变量作图</a></li>
<li class="chapter" data-level="8.16" data-path="mlsl.html"><a href="mlsl.html#数据预处理"><i class="fa fa-check"></i><b>8.16</b> 数据预处理</a></li>
<li class="chapter" data-level="8.17" data-path="mlsl.html"><a href="mlsl.html#协变量生成"><i class="fa fa-check"></i><b>8.17</b> 协变量生成</a></li>
<li class="chapter" data-level="8.18" data-path="mlsl.html"><a href="mlsl.html#线性回归多元线性回归"><i class="fa fa-check"></i><b>8.18</b> 线性回归&amp;多元线性回归</a>
<ul>
<li class="chapter" data-level="8.18.1" data-path="mlsl.html"><a href="mlsl.html#简单线性回归"><i class="fa fa-check"></i><b>8.18.1</b> 简单线性回归</a></li>
<li class="chapter" data-level="8.18.2" data-path="mlsl.html"><a href="mlsl.html#多元线性回归"><i class="fa fa-check"></i><b>8.18.2</b> 多元线性回归</a></li>
<li class="chapter" data-level="8.18.3" data-path="mlsl.html"><a href="mlsl.html#线性模型延拓"><i class="fa fa-check"></i><b>8.18.3</b> 线性模型延拓</a></li>
<li class="chapter" data-level="8.18.4" data-path="mlsl.html"><a href="mlsl.html#常见问题-1"><i class="fa fa-check"></i><b>8.18.4</b> 常见问题</a></li>
<li class="chapter" data-level="8.18.5" data-path="mlsl.html"><a href="mlsl.html#线性回归与kmeans算法比较"><i class="fa fa-check"></i><b>8.18.5</b> 线性回归与kmeans算法比较</a></li>
<li class="chapter" data-level="8.18.6" data-path="mlsl.html"><a href="mlsl.html#logistic回归"><i class="fa fa-check"></i><b>8.18.6</b> logistic回归</a></li>
<li class="chapter" data-level="8.18.7" data-path="mlsl.html"><a href="mlsl.html#线性判别分析"><i class="fa fa-check"></i><b>8.18.7</b> 线性判别分析</a></li>
<li class="chapter" data-level="8.18.8" data-path="mlsl.html"><a href="mlsl.html#二次判别分析qda及其它"><i class="fa fa-check"></i><b>8.18.8</b> 二次判别分析（QDA）及其它</a></li>
<li class="chapter" data-level="8.18.9" data-path="mlsl.html"><a href="mlsl.html#线性模型选择与正则化"><i class="fa fa-check"></i><b>8.18.9</b> 线性模型选择与正则化</a></li>
</ul></li>
<li class="chapter" data-level="8.19" data-path="mlsl.html"><a href="mlsl.html#非线性"><i class="fa fa-check"></i><b>8.19</b> 非线性</a>
<ul>
<li class="chapter" data-level="8.19.1" data-path="mlsl.html"><a href="mlsl.html#多项式回归"><i class="fa fa-check"></i><b>8.19.1</b> 多项式回归</a></li>
<li class="chapter" data-level="8.19.2" data-path="mlsl.html"><a href="mlsl.html#阶梯函数"><i class="fa fa-check"></i><b>8.19.2</b> 阶梯函数</a></li>
<li class="chapter" data-level="8.19.3" data-path="mlsl.html"><a href="mlsl.html#基函数"><i class="fa fa-check"></i><b>8.19.3</b> 基函数</a></li>
<li class="chapter" data-level="8.19.4" data-path="mlsl.html"><a href="mlsl.html#回归样条"><i class="fa fa-check"></i><b>8.19.4</b> 回归样条</a></li>
<li class="chapter" data-level="8.19.5" data-path="mlsl.html"><a href="mlsl.html#平滑样条"><i class="fa fa-check"></i><b>8.19.5</b> 平滑样条</a></li>
<li class="chapter" data-level="8.19.6" data-path="mlsl.html"><a href="mlsl.html#本地回归"><i class="fa fa-check"></i><b>8.19.6</b> 本地回归</a></li>
<li class="chapter" data-level="8.19.7" data-path="mlsl.html"><a href="mlsl.html#广义加性模型"><i class="fa fa-check"></i><b>8.19.7</b> 广义加性模型</a></li>
</ul></li>
<li class="chapter" data-level="8.20" data-path="mlsl.html"><a href="mlsl.html#树"><i class="fa fa-check"></i><b>8.20</b> 树</a>
<ul>
<li class="chapter" data-level="8.20.1" data-path="mlsl.html"><a href="mlsl.html#回归树"><i class="fa fa-check"></i><b>8.20.1</b> 回归树</a></li>
<li class="chapter" data-level="8.20.2" data-path="mlsl.html"><a href="mlsl.html#分类树"><i class="fa fa-check"></i><b>8.20.2</b> 分类树</a></li>
<li class="chapter" data-level="8.20.3" data-path="mlsl.html"><a href="mlsl.html#bagging"><i class="fa fa-check"></i><b>8.20.3</b> Bagging</a></li>
<li class="chapter" data-level="8.20.4" data-path="mlsl.html"><a href="mlsl.html#随机森林"><i class="fa fa-check"></i><b>8.20.4</b> 随机森林</a></li>
<li class="chapter" data-level="8.20.5" data-path="mlsl.html"><a href="mlsl.html#boosting"><i class="fa fa-check"></i><b>8.20.5</b> Boosting</a></li>
</ul></li>
<li class="chapter" data-level="8.21" data-path="mlsl.html"><a href="mlsl.html#支持向量机"><i class="fa fa-check"></i><b>8.21</b> 支持向量机</a>
<ul>
<li class="chapter" data-level="8.21.1" data-path="mlsl.html"><a href="mlsl.html#最大边界分类器"><i class="fa fa-check"></i><b>8.21.1</b> 最大边界分类器</a></li>
<li class="chapter" data-level="8.21.2" data-path="mlsl.html"><a href="mlsl.html#支持向量分类器"><i class="fa fa-check"></i><b>8.21.2</b> 支持向量分类器</a></li>
<li class="chapter" data-level="8.21.3" data-path="mlsl.html"><a href="mlsl.html#支持向量机原理"><i class="fa fa-check"></i><b>8.21.3</b> 支持向量机原理</a></li>
<li class="chapter" data-level="8.21.4" data-path="mlsl.html"><a href="mlsl.html#svm与logistic回归关系"><i class="fa fa-check"></i><b>8.21.4</b> svm与logistic回归关系</a></li>
</ul></li>
<li class="chapter" data-level="8.22" data-path="mlsl.html"><a href="mlsl.html#无监督学习"><i class="fa fa-check"></i><b>8.22</b> 无监督学习</a>
<ul>
<li class="chapter" data-level="8.22.1" data-path="mlsl.html"><a href="mlsl.html#主成分分析"><i class="fa fa-check"></i><b>8.22.1</b> 主成分分析</a></li>
<li class="chapter" data-level="8.22.2" data-path="mlsl.html"><a href="mlsl.html#聚类方法"><i class="fa fa-check"></i><b>8.22.2</b> 聚类方法</a></li>
</ul></li>
<li class="chapter" data-level="8.23" data-path="mlsl.html"><a href="mlsl.html#人工神经网络"><i class="fa fa-check"></i><b>8.23</b> 人工神经网络</a></li>
<li class="chapter" data-level="8.24" data-path="mlsl.html"><a href="mlsl.html#模型联合"><i class="fa fa-check"></i><b>8.24</b> 模型联合</a></li>
<li class="chapter" data-level="8.25" data-path="mlsl.html"><a href="mlsl.html#无监督预测"><i class="fa fa-check"></i><b>8.25</b> 无监督预测</a></li>
<li class="chapter" data-level="8.26" data-path="mlsl.html"><a href="mlsl.html#模型预测"><i class="fa fa-check"></i><b>8.26</b> 模型预测</a></li>
<li class="chapter" data-level="8.27" data-path="mlsl.html"><a href="mlsl.html#模型可视化"><i class="fa fa-check"></i><b>8.27</b> 模型可视化</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="product.html"><a href="product.html"><i class="fa fa-check"></i><b>9</b> 开发数据产品</a>
<ul>
<li class="chapter" data-level="9.1" data-path="product.html"><a href="product.html#shiny"><i class="fa fa-check"></i><b>9.1</b> shiny</a></li>
<li class="chapter" data-level="9.2" data-path="product.html"><a href="product.html#rcharts"><i class="fa fa-check"></i><b>9.2</b> rCharts</a></li>
<li class="chapter" data-level="9.3" data-path="product.html"><a href="product.html#googlevis"><i class="fa fa-check"></i><b>9.3</b> GoogleVis</a></li>
<li class="chapter" data-level="9.4" data-path="product.html"><a href="product.html#slidify"><i class="fa fa-check"></i><b>9.4</b> Slidify</a></li>
<li class="chapter" data-level="9.5" data-path="product.html"><a href="product.html#yhat"><i class="fa fa-check"></i><b>9.5</b> yhat</a></li>
<li class="chapter" data-level="9.6" data-path="product.html"><a href="product.html#swagger"><i class="fa fa-check"></i><b>9.6</b> swagger</a></li>
<li class="chapter" data-level="9.7" data-path="product.html"><a href="product.html#案例"><i class="fa fa-check"></i><b>9.7</b> 案例</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="bayes.html"><a href="bayes.html"><i class="fa fa-check"></i><b>10</b> 贝叶斯统计</a>
<ul>
<li class="chapter" data-level="10.1" data-path="bayes.html"><a href="bayes.html#贝塔分布"><i class="fa fa-check"></i><b>10.1</b> 贝塔分布</a></li>
<li class="chapter" data-level="10.2" data-path="bayes.html"><a href="bayes.html#为什么击球的概率分布符合贝塔分布"><i class="fa fa-check"></i><b>10.2</b> 为什么击球的概率分布符合贝塔分布？</a></li>
<li class="chapter" data-level="10.3" data-path="bayes.html"><a href="bayes.html#先验与后验"><i class="fa fa-check"></i><b>10.3</b> 先验与后验</a></li>
<li class="chapter" data-level="10.4" data-path="bayes.html"><a href="bayes.html#经验贝叶斯"><i class="fa fa-check"></i><b>10.4</b> 经验贝叶斯</a></li>
<li class="chapter" data-level="10.5" data-path="bayes.html"><a href="bayes.html#从整体到个人"><i class="fa fa-check"></i><b>10.5</b> 从整体到个人</a></li>
<li class="chapter" data-level="10.6" data-path="bayes.html"><a href="bayes.html#可信区间与置信区间"><i class="fa fa-check"></i><b>10.6</b> 可信区间与置信区间</a></li>
<li class="chapter" data-level="10.7" data-path="bayes.html"><a href="bayes.html#后验错误率"><i class="fa fa-check"></i><b>10.7</b> 后验错误率</a></li>
<li class="chapter" data-level="10.8" data-path="bayes.html"><a href="bayes.html#错误发现率"><i class="fa fa-check"></i><b>10.8</b> 错误发现率</a></li>
<li class="chapter" data-level="10.9" data-path="bayes.html"><a href="bayes.html#q值"><i class="fa fa-check"></i><b>10.9</b> q值</a></li>
<li class="chapter" data-level="10.10" data-path="bayes.html"><a href="bayes.html#贝叶斯视角的假设检验"><i class="fa fa-check"></i><b>10.10</b> 贝叶斯视角的假设检验</a>
<ul>
<li class="chapter" data-level="10.10.1" data-path="bayes.html"><a href="bayes.html#模拟验证"><i class="fa fa-check"></i><b>10.10.1</b> 模拟验证</a></li>
<li class="chapter" data-level="10.10.2" data-path="bayes.html"><a href="bayes.html#数值积分"><i class="fa fa-check"></i><b>10.10.2</b> 数值积分</a></li>
<li class="chapter" data-level="10.10.3" data-path="bayes.html"><a href="bayes.html#解析解"><i class="fa fa-check"></i><b>10.10.3</b> 解析解</a></li>
<li class="chapter" data-level="10.10.4" data-path="bayes.html"><a href="bayes.html#正态近似求解"><i class="fa fa-check"></i><b>10.10.4</b> 正态近似求解</a></li>
</ul></li>
<li class="chapter" data-level="10.11" data-path="bayes.html"><a href="bayes.html#比例检验"><i class="fa fa-check"></i><b>10.11</b> 比例检验</a></li>
<li class="chapter" data-level="10.12" data-path="bayes.html"><a href="bayes.html#错误率控制"><i class="fa fa-check"></i><b>10.12</b> 错误率控制</a></li>
<li class="chapter" data-level="10.13" data-path="bayes.html"><a href="bayes.html#影响因子"><i class="fa fa-check"></i><b>10.13</b> 影响因子</a>
<ul>
<li class="chapter" data-level="10.13.1" data-path="bayes.html"><a href="bayes.html#拟合模型"><i class="fa fa-check"></i><b>10.13.1</b> 拟合模型</a></li>
<li class="chapter" data-level="10.13.2" data-path="bayes.html"><a href="bayes.html#求后验概率"><i class="fa fa-check"></i><b>10.13.2</b> 求后验概率</a></li>
<li class="chapter" data-level="10.13.3" data-path="bayes.html"><a href="bayes.html#考虑更多因素"><i class="fa fa-check"></i><b>10.13.3</b> 考虑更多因素</a></li>
</ul></li>
<li class="chapter" data-level="10.14" data-path="bayes.html"><a href="bayes.html#混合概率模型"><i class="fa fa-check"></i><b>10.14</b> 混合概率模型</a>
<ul>
<li class="chapter" data-level="10.14.1" data-path="bayes.html"><a href="bayes.html#期望最大算法"><i class="fa fa-check"></i><b>10.14.1</b> 期望最大算法</a></li>
<li class="chapter" data-level="10.14.2" data-path="bayes.html"><a href="bayes.html#分配"><i class="fa fa-check"></i><b>10.14.2</b> 分配</a></li>
<li class="chapter" data-level="10.14.3" data-path="bayes.html"><a href="bayes.html#经验贝叶斯收缩"><i class="fa fa-check"></i><b>10.14.3</b> 经验贝叶斯收缩</a></li>
</ul></li>
<li class="chapter" data-level="10.15" data-path="bayes.html"><a href="bayes.html#模拟验证结果"><i class="fa fa-check"></i><b>10.15</b> 模拟验证结果</a>
<ul>
<li class="chapter" data-level="10.15.1" data-path="bayes.html"><a href="bayes.html#模拟对分布参数的估计"><i class="fa fa-check"></i><b>10.15.1</b> 模拟对分布参数的估计</a></li>
<li class="chapter" data-level="10.15.2" data-path="bayes.html"><a href="bayes.html#区间估计"><i class="fa fa-check"></i><b>10.15.2</b> 区间估计</a></li>
<li class="chapter" data-level="10.15.3" data-path="bayes.html"><a href="bayes.html#错误发现率-1"><i class="fa fa-check"></i><b>10.15.3</b> 错误发现率</a></li>
<li class="chapter" data-level="10.15.4" data-path="bayes.html"><a href="bayes.html#重复模拟"><i class="fa fa-check"></i><b>10.15.4</b> 重复模拟</a></li>
</ul></li>
<li class="chapter" data-level="10.16" data-path="bayes.html"><a href="bayes.html#bayeslink"><i class="fa fa-check"></i><b>10.16</b> 网络资源</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="why.html"><a href="why.html"><i class="fa fa-check"></i><b>11</b> 因果分析</a>
<ul>
<li class="chapter" data-level="11.1" data-path="why.html"><a href="why.html#introduction"><i class="fa fa-check"></i><b>11.1</b> Introduction</a></li>
<li class="chapter" data-level="11.2" data-path="why.html"><a href="why.html#causal-information"><i class="fa fa-check"></i><b>11.2</b> Causal Information</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="why.html"><a href="why.html#target"><i class="fa fa-check"></i><b>11.2.1</b> Target</a></li>
<li class="chapter" data-level="11.2.2" data-path="why.html"><a href="why.html#causal-sources"><i class="fa fa-check"></i><b>11.2.2</b> Causal sources</a></li>
<li class="chapter" data-level="11.2.3" data-path="why.html"><a href="why.html#identification-and-estimation-process"><i class="fa fa-check"></i><b>11.2.3</b> Identification and Estimation Process</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="why.html"><a href="why.html#theoretical-background"><i class="fa fa-check"></i><b>11.3</b> Theoretical Background</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="why.html"><a href="why.html#potential-outcomes-framework"><i class="fa fa-check"></i><b>11.3.1</b> Potential Outcomes Framework</a></li>
<li class="chapter" data-level="11.3.2" data-path="why.html"><a href="why.html#causal-identification"><i class="fa fa-check"></i><b>11.3.2</b> Causal Identification</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="why.html"><a href="why.html#methods-for-identification-and-estimation"><i class="fa fa-check"></i><b>11.4</b> Methods for Identification and Estimation</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="why.html"><a href="why.html#directed-acyclic-graphsdag-for-identification"><i class="fa fa-check"></i><b>11.4.1</b> Directed Acyclic Graphs(DAG) for Identification</a></li>
<li class="chapter" data-level="11.4.2" data-path="why.html"><a href="why.html#indirect-connection"><i class="fa fa-check"></i><b>11.4.2</b> Indirect Connection</a></li>
<li class="chapter" data-level="11.4.3" data-path="why.html"><a href="why.html#common-cause"><i class="fa fa-check"></i><b>11.4.3</b> Common Cause</a></li>
<li class="chapter" data-level="11.4.4" data-path="why.html"><a href="why.html#common-effect"><i class="fa fa-check"></i><b>11.4.4</b> Common Effect</a></li>
<li class="chapter" data-level="11.4.5" data-path="why.html"><a href="why.html#example-simpsons-paradox"><i class="fa fa-check"></i><b>11.4.5</b> Example: Simpson’s Paradox</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="why.html"><a href="why.html#yinguolink"><i class="fa fa-check"></i><b>11.5</b> 链接</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="neta.html"><a href="neta.html"><i class="fa fa-check"></i><b>12</b> 网络分析</a>
<ul>
<li class="chapter" data-level="12.1" data-path="neta.html"><a href="neta.html#节点属性"><i class="fa fa-check"></i><b>12.1</b> 节点属性</a></li>
<li class="chapter" data-level="12.2" data-path="neta.html"><a href="neta.html#网络集群"><i class="fa fa-check"></i><b>12.2</b> 网络集群</a></li>
<li class="chapter" data-level="12.3" data-path="neta.html"><a href="neta.html#随机网络模型"><i class="fa fa-check"></i><b>12.3</b> 随机网络模型</a></li>
<li class="chapter" data-level="12.4" data-path="neta.html"><a href="neta.html#无尺度网络"><i class="fa fa-check"></i><b>12.4</b> 无尺度网络</a></li>
<li class="chapter" data-level="12.5" data-path="neta.html"><a href="neta.html#无尺度的生成---barabási-albert-模型"><i class="fa fa-check"></i><b>12.5</b> 无尺度的生成 - Barabási-Albert 模型</a></li>
<li class="chapter" data-level="12.6" data-path="neta.html"><a href="neta.html#网络的进化---bianconi-barabási-模型"><i class="fa fa-check"></i><b>12.6</b> 网络的进化 - Bianconi-Barabási 模型</a></li>
<li class="chapter" data-level="12.7" data-path="neta.html"><a href="neta.html#度相关现象"><i class="fa fa-check"></i><b>12.7</b> 度相关现象</a></li>
<li class="chapter" data-level="12.8" data-path="neta.html"><a href="neta.html#网络稳健性"><i class="fa fa-check"></i><b>12.8</b> 网络稳健性</a></li>
<li class="chapter" data-level="12.9" data-path="neta.html"><a href="neta.html#网络回归"><i class="fa fa-check"></i><b>12.9</b> 网络回归</a></li>
<li class="chapter" data-level="12.10" data-path="neta.html"><a href="neta.html#网络扩散行为"><i class="fa fa-check"></i><b>12.10</b> 网络扩散行为</a></li>
<li class="chapter" data-level="12.11" data-path="neta.html"><a href="neta.html#网络可视化"><i class="fa fa-check"></i><b>12.11</b> 网络可视化</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="game.html"><a href="game.html"><i class="fa fa-check"></i><b>13</b> 博弈论</a>
<ul>
<li class="chapter" data-level="13.1" data-path="game.html"><a href="game.html#术语-1"><i class="fa fa-check"></i><b>13.1</b> 术语</a></li>
<li class="chapter" data-level="13.2" data-path="game.html"><a href="game.html#支配策略dominate-strategy"><i class="fa fa-check"></i><b>13.2</b> 支配策略（dominate strategy）</a></li>
<li class="chapter" data-level="13.3" data-path="game.html"><a href="game.html#最佳回应best-respinse"><i class="fa fa-check"></i><b>13.3</b> 最佳回应（Best respinse）</a></li>
<li class="chapter" data-level="13.4" data-path="game.html"><a href="game.html#纳什均衡nash-equilibrium"><i class="fa fa-check"></i><b>13.4</b> 纳什均衡（Nash Equilibrium）</a></li>
<li class="chapter" data-level="13.5" data-path="game.html"><a href="game.html#帕累托最优pareto-optimality"><i class="fa fa-check"></i><b>13.5</b> 帕累托最优（Pareto Optimality）</a></li>
<li class="chapter" data-level="13.6" data-path="game.html"><a href="game.html#混合策略mixed-stratergies"><i class="fa fa-check"></i><b>13.6</b> 混合策略（Mixed stratergies）</a></li>
<li class="chapter" data-level="13.7" data-path="game.html"><a href="game.html#寻找纳什均衡"><i class="fa fa-check"></i><b>13.7</b> 寻找纳什均衡</a></li>
<li class="chapter" data-level="13.8" data-path="game.html"><a href="game.html#被支配策略dominated-strategy"><i class="fa fa-check"></i><b>13.8</b> 被支配策略（dominated strategy）</a></li>
<li class="chapter" data-level="13.9" data-path="game.html"><a href="game.html#最大最小策略maxmin-strategies"><i class="fa fa-check"></i><b>13.9</b> 最大最小策略（Maxmin strategies）</a></li>
<li class="chapter" data-level="13.10" data-path="game.html"><a href="game.html#扩展形式博弈"><i class="fa fa-check"></i><b>13.10</b> 扩展形式博弈</a></li>
<li class="chapter" data-level="13.11" data-path="game.html"><a href="game.html#完美子博弈"><i class="fa fa-check"></i><b>13.11</b> 完美子博弈</a></li>
<li class="chapter" data-level="13.12" data-path="game.html"><a href="game.html#信息不对称扩展形式博弈"><i class="fa fa-check"></i><b>13.12</b> 信息不对称扩展形式博弈</a></li>
<li class="chapter" data-level="13.13" data-path="game.html"><a href="game.html#混合与行为策略"><i class="fa fa-check"></i><b>13.13</b> 混合与行为策略</a></li>
<li class="chapter" data-level="13.14" data-path="game.html"><a href="game.html#重复博弈"><i class="fa fa-check"></i><b>13.14</b> 重复博弈</a></li>
<li class="chapter" data-level="13.15" data-path="game.html"><a href="game.html#随机博弈stochastic-game"><i class="fa fa-check"></i><b>13.15</b> 随机博弈（stochastic game）</a></li>
<li class="chapter" data-level="13.16" data-path="game.html"><a href="game.html#虚拟行动fictitious-play"><i class="fa fa-check"></i><b>13.16</b> 虚拟行动（fictitious play）</a></li>
<li class="chapter" data-level="13.17" data-path="game.html"><a href="game.html#无悔学习no-regret-learning"><i class="fa fa-check"></i><b>13.17</b> 无悔学习（No-regret learning）</a></li>
<li class="chapter" data-level="13.18" data-path="game.html"><a href="game.html#无限重复博弈的平衡"><i class="fa fa-check"></i><b>13.18</b> 无限重复博弈的平衡</a></li>
<li class="chapter" data-level="13.19" data-path="game.html"><a href="game.html#贝叶斯博弈"><i class="fa fa-check"></i><b>13.19</b> 贝叶斯博弈</a></li>
<li class="chapter" data-level="13.20" data-path="game.html"><a href="game.html#联盟博弈"><i class="fa fa-check"></i><b>13.20</b> 联盟博弈</a></li>
<li class="chapter" data-level="13.21" data-path="game.html"><a href="game.html#夏普利值shapley-value"><i class="fa fa-check"></i><b>13.21</b> 夏普利值（Shapley Value）</a></li>
<li class="chapter" data-level="13.22" data-path="game.html"><a href="game.html#核心"><i class="fa fa-check"></i><b>13.22</b> 核心</a></li>
<li class="chapter" data-level="13.23" data-path="game.html"><a href="game.html#选举"><i class="fa fa-check"></i><b>13.23</b> 选举</a></li>
<li class="chapter" data-level="13.24" data-path="game.html"><a href="game.html#机制设计"><i class="fa fa-check"></i><b>13.24</b> 机制设计</a></li>
<li class="chapter" data-level="13.25" data-path="game.html"><a href="game.html#vcg机制"><i class="fa fa-check"></i><b>13.25</b> VCG机制</a></li>
<li class="chapter" data-level="13.26" data-path="game.html"><a href="game.html#拍卖"><i class="fa fa-check"></i><b>13.26</b> 拍卖</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="bios.html"><a href="bios.html"><i class="fa fa-check"></i><b>14</b> 生物信息</a>
<ul>
<li class="chapter" data-level="14.1" data-path="bios.html"><a href="bios.html#数据结构"><i class="fa fa-check"></i><b>14.1</b> 数据结构</a></li>
<li class="chapter" data-level="14.2" data-path="bios.html"><a href="bios.html#pubmed-搜索"><i class="fa fa-check"></i><b>14.2</b> Pubmed 搜索</a></li>
<li class="chapter" data-level="14.3" data-path="bios.html"><a href="bios.html#动态规划"><i class="fa fa-check"></i><b>14.3</b> 动态规划</a></li>
<li class="chapter" data-level="14.4" data-path="bios.html"><a href="bios.html#得分矩阵"><i class="fa fa-check"></i><b>14.4</b> 得分矩阵</a></li>
<li class="chapter" data-level="14.5" data-path="bios.html"><a href="bios.html#e-值"><i class="fa fa-check"></i><b>14.5</b> E 值</a></li>
<li class="chapter" data-level="14.6" data-path="bios.html"><a href="bios.html#psi-blast"><i class="fa fa-check"></i><b>14.6</b> PSI-BLAST</a></li>
<li class="chapter" data-level="14.7" data-path="bios.html"><a href="bios.html#蛋白"><i class="fa fa-check"></i><b>14.7</b> 蛋白</a></li>
<li class="chapter" data-level="14.8" data-path="bios.html"><a href="bios.html#蛋白结构预测"><i class="fa fa-check"></i><b>14.8</b> 蛋白结构预测</a></li>
<li class="chapter" data-level="14.9" data-path="bios.html"><a href="bios.html#细菌基因组"><i class="fa fa-check"></i><b>14.9</b> 细菌基因组</a></li>
<li class="chapter" data-level="14.10" data-path="bios.html"><a href="bios.html#病毒"><i class="fa fa-check"></i><b>14.10</b> 病毒</a></li>
<li class="chapter" data-level="14.11" data-path="bios.html"><a href="bios.html#单核苷酸多态性snp"><i class="fa fa-check"></i><b>14.11</b> 单核苷酸多态性（SNP）</a></li>
<li class="chapter" data-level="14.12" data-path="bios.html"><a href="bios.html#真核基因预测"><i class="fa fa-check"></i><b>14.12</b> 真核基因预测</a></li>
<li class="chapter" data-level="14.13" data-path="bios.html"><a href="bios.html#dna指纹"><i class="fa fa-check"></i><b>14.13</b> DNA指纹</a></li>
<li class="chapter" data-level="14.14" data-path="bios.html"><a href="bios.html#ensembl"><i class="fa fa-check"></i><b>14.14</b> Ensembl</a></li>
<li class="chapter" data-level="14.15" data-path="bios.html"><a href="bios.html#基因组学数据分析"><i class="fa fa-check"></i><b>14.15</b> 基因组学数据分析</a>
<ul>
<li class="chapter" data-level="14.15.1" data-path="bios.html"><a href="bios.html#microarrays"><i class="fa fa-check"></i><b>14.15.1</b> microarrays</a></li>
<li class="chapter" data-level="14.15.2" data-path="bios.html"><a href="bios.html#ngs"><i class="fa fa-check"></i><b>14.15.2</b> NGS</a></li>
<li class="chapter" data-level="14.15.3" data-path="bios.html"><a href="bios.html#数据分析应用背景"><i class="fa fa-check"></i><b>14.15.3</b> 数据分析应用背景</a></li>
<li class="chapter" data-level="14.15.4" data-path="bios.html"><a href="bios.html#bioconductor"><i class="fa fa-check"></i><b>14.15.4</b> Bioconductor</a></li>
<li class="chapter" data-level="14.15.5" data-path="bios.html"><a href="bios.html#示例甲基化数据分析"><i class="fa fa-check"></i><b>14.15.5</b> 示例：甲基化数据分析</a></li>
</ul></li>
<li class="chapter" data-level="14.16" data-path="bios.html"><a href="bios.html#biolink"><i class="fa fa-check"></i><b>14.16</b> 链接</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="surv.html"><a href="surv.html"><i class="fa fa-check"></i><b>15</b> 生存分析</a>
<ul>
<li class="chapter" data-level="15.1" data-path="surv.html"><a href="surv.html#concepts"><i class="fa fa-check"></i><b>15.1</b> Concepts</a></li>
<li class="chapter" data-level="15.2" data-path="surv.html"><a href="surv.html#notation"><i class="fa fa-check"></i><b>15.2</b> Notation</a></li>
<li class="chapter" data-level="15.3" data-path="surv.html"><a href="surv.html#cox-proportional-hazards-regression-model"><i class="fa fa-check"></i><b>15.3</b> Cox proportional-hazards regression model</a></li>
<li class="chapter" data-level="15.4" data-path="surv.html"><a href="surv.html#case-recidivism"><i class="fa fa-check"></i><b>15.4</b> Case: Recidivism</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="surv.html"><a href="surv.html#result"><i class="fa fa-check"></i><b>15.4.1</b> result</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="surv.html"><a href="surv.html#further"><i class="fa fa-check"></i><b>15.5</b> further</a></li>
<li class="chapter" data-level="15.6" data-path="surv.html"><a href="surv.html#time-dependent-covariates"><i class="fa fa-check"></i><b>15.6</b> Time-Dependent Covariates</a></li>
<li class="chapter" data-level="15.7" data-path="surv.html"><a href="surv.html#model-diagnostics"><i class="fa fa-check"></i><b>15.7</b> Model Diagnostics</a></li>
<li class="chapter" data-level="15.8" data-path="surv.html"><a href="surv.html#reference"><i class="fa fa-check"></i><b>15.8</b> Reference</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="epid.html"><a href="epid.html"><i class="fa fa-check"></i><b>16</b> 流行病学</a>
<ul>
<li class="chapter" data-level="16.1" data-path="epid.html"><a href="epid.html#声明"><i class="fa fa-check"></i><b>16.1</b> 声明</a></li>
<li class="chapter" data-level="16.2" data-path="epid.html"><a href="epid.html#早期疾病的概念"><i class="fa fa-check"></i><b>16.2</b> 早期疾病的概念</a></li>
<li class="chapter" data-level="16.3" data-path="epid.html"><a href="epid.html#近代流行病学关键人物"><i class="fa fa-check"></i><b>16.3</b> 近代流行病学关键人物</a></li>
<li class="chapter" data-level="16.4" data-path="epid.html"><a href="epid.html#现代慢性病流行病学"><i class="fa fa-check"></i><b>16.4</b> 现代慢性病流行病学</a></li>
<li class="chapter" data-level="16.5" data-path="epid.html"><a href="epid.html#流行病学基本概念"><i class="fa fa-check"></i><b>16.5</b> 流行病学基本概念</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="epid.html"><a href="epid.html#基本假设"><i class="fa fa-check"></i><b>16.5.1</b> 基本假设</a></li>
<li class="chapter" data-level="16.5.2" data-path="epid.html"><a href="epid.html#定义"><i class="fa fa-check"></i><b>16.5.2</b> 定义</a></li>
</ul></li>
<li class="chapter" data-level="16.6" data-path="epid.html"><a href="epid.html#描述性流行病学"><i class="fa fa-check"></i><b>16.6</b> 描述性流行病学</a>
<ul>
<li class="chapter" data-level="16.6.1" data-path="epid.html"><a href="epid.html#疾病爆发的研究步骤"><i class="fa fa-check"></i><b>16.6.1</b> 疾病爆发的研究步骤</a></li>
<li class="chapter" data-level="16.6.2" data-path="epid.html"><a href="epid.html#慢性病的描述性流行病学"><i class="fa fa-check"></i><b>16.6.2</b> 慢性病的描述性流行病学</a></li>
<li class="chapter" data-level="16.6.3" data-path="epid.html"><a href="epid.html#描述流行病学分类"><i class="fa fa-check"></i><b>16.6.3</b> 描述流行病学分类</a></li>
</ul></li>
<li class="chapter" data-level="16.7" data-path="epid.html"><a href="epid.html#分析流行病学"><i class="fa fa-check"></i><b>16.7</b> 分析流行病学</a></li>
<li class="chapter" data-level="16.8" data-path="epid.html"><a href="epid.html#疾病监控"><i class="fa fa-check"></i><b>16.8</b> 疾病监控</a></li>
<li class="chapter" data-level="16.9" data-path="epid.html"><a href="epid.html#疾病频率的测量"><i class="fa fa-check"></i><b>16.9</b> 疾病频率的测量</a>
<ul>
<li class="chapter" data-level="16.9.1" data-path="epid.html"><a href="epid.html#人群"><i class="fa fa-check"></i><b>16.9.1</b> 人群</a></li>
<li class="chapter" data-level="16.9.2" data-path="epid.html"><a href="epid.html#患病率prevalence"><i class="fa fa-check"></i><b>16.9.2</b> 患病率（prevalence）</a></li>
<li class="chapter" data-level="16.9.3" data-path="epid.html"><a href="epid.html#风险risk"><i class="fa fa-check"></i><b>16.9.3</b> 风险（risk）</a></li>
<li class="chapter" data-level="16.9.4" data-path="epid.html"><a href="epid.html#比率rate"><i class="fa fa-check"></i><b>16.9.4</b> 比率（rate）</a></li>
<li class="chapter" data-level="16.9.5" data-path="epid.html"><a href="epid.html#其他频率测量"><i class="fa fa-check"></i><b>16.9.5</b> 其他频率测量</a></li>
</ul></li>
<li class="chapter" data-level="16.10" data-path="epid.html"><a href="epid.html#联系测量"><i class="fa fa-check"></i><b>16.10</b> 联系测量</a>
<ul>
<li class="chapter" data-level="16.10.1" data-path="epid.html"><a href="epid.html#风险比与比率比risk-ratio-rate-ratio"><i class="fa fa-check"></i><b>16.10.1</b> 风险比与比率比（risk ratio rate ratio）</a></li>
<li class="chapter" data-level="16.10.2" data-path="epid.html"><a href="epid.html#对照组"><i class="fa fa-check"></i><b>16.10.2</b> 对照组</a></li>
<li class="chapter" data-level="16.10.3" data-path="epid.html"><a href="epid.html#风险差risk-difference"><i class="fa fa-check"></i><b>16.10.3</b> 风险差（risk difference）</a></li>
<li class="chapter" data-level="16.10.4" data-path="epid.html"><a href="epid.html#归因比例attributable-proportion-among-the-exposed"><i class="fa fa-check"></i><b>16.10.4</b> 归因比例（Attributable Proportion Among the Exposed）</a></li>
<li class="chapter" data-level="16.10.5" data-path="epid.html"><a href="epid.html#人群归因比例population-attributable-fraction"><i class="fa fa-check"></i><b>16.10.5</b> 人群归因比例（Population Attributable Fraction）</a></li>
<li class="chapter" data-level="16.10.6" data-path="epid.html"><a href="epid.html#胜率比odds-ratio"><i class="fa fa-check"></i><b>16.10.6</b> 胜率比（odds ratio）</a></li>
</ul></li>
<li class="chapter" data-level="16.11" data-path="epid.html"><a href="epid.html#随机误差"><i class="fa fa-check"></i><b>16.11</b> 随机误差</a></li>
<li class="chapter" data-level="16.12" data-path="epid.html"><a href="epid.html#研究道德"><i class="fa fa-check"></i><b>16.12</b> 研究道德</a></li>
<li class="chapter" data-level="16.13" data-path="epid.html"><a href="epid.html#临床实验"><i class="fa fa-check"></i><b>16.13</b> 临床实验</a>
<ul>
<li class="chapter" data-level="16.13.1" data-path="epid.html"><a href="epid.html#研究对象"><i class="fa fa-check"></i><b>16.13.1</b> 研究对象</a></li>
<li class="chapter" data-level="16.13.2" data-path="epid.html"><a href="epid.html#对照组与控制组"><i class="fa fa-check"></i><b>16.13.2</b> 对照组与控制组</a></li>
<li class="chapter" data-level="16.13.3" data-path="epid.html"><a href="epid.html#临床分析中的问题"><i class="fa fa-check"></i><b>16.13.3</b> 临床分析中的问题</a></li>
</ul></li>
<li class="chapter" data-level="16.14" data-path="epid.html"><a href="epid.html#队列研究"><i class="fa fa-check"></i><b>16.14</b> 队列研究</a>
<ul>
<li class="chapter" data-level="16.14.1" data-path="epid.html"><a href="epid.html#前瞻性队列研究"><i class="fa fa-check"></i><b>16.14.1</b> 前瞻性队列研究</a></li>
<li class="chapter" data-level="16.14.2" data-path="epid.html"><a href="epid.html#回顾性队列研究"><i class="fa fa-check"></i><b>16.14.2</b> 回顾性队列研究</a></li>
<li class="chapter" data-level="16.14.3" data-path="epid.html"><a href="epid.html#双向队列研究"><i class="fa fa-check"></i><b>16.14.3</b> 双向队列研究</a></li>
<li class="chapter" data-level="16.14.4" data-path="epid.html"><a href="epid.html#固定队列与开放队列"><i class="fa fa-check"></i><b>16.14.4</b> 固定队列与开放队列</a></li>
<li class="chapter" data-level="16.14.5" data-path="epid.html"><a href="epid.html#研究对象-1"><i class="fa fa-check"></i><b>16.14.5</b> 研究对象</a></li>
<li class="chapter" data-level="16.14.6" data-path="epid.html"><a href="epid.html#队列追踪"><i class="fa fa-check"></i><b>16.14.6</b> 队列追踪</a></li>
<li class="chapter" data-level="16.14.7" data-path="epid.html"><a href="epid.html#优点"><i class="fa fa-check"></i><b>16.14.7</b> 优点</a></li>
<li class="chapter" data-level="16.14.8" data-path="epid.html"><a href="epid.html#前瞻性队列研究缺点"><i class="fa fa-check"></i><b>16.14.8</b> 前瞻性队列研究缺点</a></li>
<li class="chapter" data-level="16.14.9" data-path="epid.html"><a href="epid.html#回顾性队列研究缺点"><i class="fa fa-check"></i><b>16.14.9</b> 回顾性队列研究缺点</a></li>
<li class="chapter" data-level="16.14.10" data-path="epid.html"><a href="epid.html#偏误"><i class="fa fa-check"></i><b>16.14.10</b> 偏误</a></li>
</ul></li>
<li class="chapter" data-level="16.15" data-path="epid.html"><a href="epid.html#病例对照研究"><i class="fa fa-check"></i><b>16.15</b> 病例对照研究</a></li>
<li class="chapter" data-level="16.16" data-path="epid.html"><a href="epid.html#标准化"><i class="fa fa-check"></i><b>16.16</b> 标准化</a></li>
<li class="chapter" data-level="16.17" data-path="epid.html"><a href="epid.html#混杂"><i class="fa fa-check"></i><b>16.17</b> 混杂</a></li>
<li class="chapter" data-level="16.18" data-path="epid.html"><a href="epid.html#效应修饰emm"><i class="fa fa-check"></i><b>16.18</b> 效应修饰（EMM）</a></li>
<li class="chapter" data-level="16.19" data-path="epid.html"><a href="epid.html#多变量方法"><i class="fa fa-check"></i><b>16.19</b> 多变量方法</a></li>
<li class="chapter" data-level="16.20" data-path="epid.html"><a href="epid.html#筛选"><i class="fa fa-check"></i><b>16.20</b> 筛选</a></li>
<li class="chapter" data-level="16.21" data-path="epid.html"><a href="epid.html#因果推断"><i class="fa fa-check"></i><b>16.21</b> 因果推断</a>
<ul>
<li class="chapter" data-level="16.21.1" data-path="epid.html"><a href="epid.html#hill-因果标准"><i class="fa fa-check"></i><b>16.21.1</b> Hill 因果标准</a></li>
<li class="chapter" data-level="16.21.2" data-path="epid.html"><a href="epid.html#部分原因理论"><i class="fa fa-check"></i><b>16.21.2</b> 部分原因理论</a></li>
<li class="chapter" data-level="16.21.3" data-path="epid.html"><a href="epid.html#逆向模型counterfactual-models"><i class="fa fa-check"></i><b>16.21.3</b> 逆向模型（Counterfactual models）</a></li>
<li class="chapter" data-level="16.21.4" data-path="epid.html"><a href="epid.html#有向无环图dags"><i class="fa fa-check"></i><b>16.21.4</b> 有向无环图（DAGs）</a></li>
</ul></li>
<li class="chapter" data-level="16.22" data-path="epid.html"><a href="epid.html#论文研读"><i class="fa fa-check"></i><b>16.22</b> 论文研读</a>
<ul>
<li class="chapter" data-level="16.22.1" data-path="epid.html"><a href="epid.html#introduction-1"><i class="fa fa-check"></i><b>16.22.1</b> Introduction</a></li>
<li class="chapter" data-level="16.22.2" data-path="epid.html"><a href="epid.html#methods"><i class="fa fa-check"></i><b>16.22.2</b> Methods</a></li>
<li class="chapter" data-level="16.22.3" data-path="epid.html"><a href="epid.html#results"><i class="fa fa-check"></i><b>16.22.3</b> Results</a></li>
<li class="chapter" data-level="16.22.4" data-path="epid.html"><a href="epid.html#discussion"><i class="fa fa-check"></i><b>16.22.4</b> Discussion</a></li>
<li class="chapter" data-level="16.22.5" data-path="epid.html"><a href="epid.html#conclusion"><i class="fa fa-check"></i><b>16.22.5</b> Conclusion</a></li>
<li class="chapter" data-level="16.22.6" data-path="epid.html"><a href="epid.html#clinical-trial"><i class="fa fa-check"></i><b>16.22.6</b> Clinical Trial</a></li>
<li class="chapter" data-level="16.22.7" data-path="epid.html"><a href="epid.html#cohort-study"><i class="fa fa-check"></i><b>16.22.7</b> Cohort Study</a></li>
<li class="chapter" data-level="16.22.8" data-path="epid.html"><a href="epid.html#case-control-study"><i class="fa fa-check"></i><b>16.22.8</b> Case-Control Study</a></li>
<li class="chapter" data-level="16.22.9" data-path="epid.html"><a href="epid.html#screening-test"><i class="fa fa-check"></i><b>16.22.9</b> Screening Test</a></li>
<li class="chapter" data-level="16.22.10" data-path="epid.html"><a href="epid.html#additional-considerations"><i class="fa fa-check"></i><b>16.22.10</b> Additional Considerations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="nlp.html"><a href="nlp.html"><i class="fa fa-check"></i><b>17</b> 自然语言处理</a></li>
<li class="chapter" data-level="18" data-path="qi.html"><a href="qi.html"><i class="fa fa-check"></i><b>18</b> 量化投资</a>
<ul>
<li class="chapter" data-level="18.1" data-path="qi.html"><a href="qi.html#股票收益模型"><i class="fa fa-check"></i><b>18.1</b> 股票收益模型</a></li>
<li class="chapter" data-level="18.2" data-path="qi.html"><a href="qi.html#风险"><i class="fa fa-check"></i><b>18.2</b> 风险</a></li>
<li class="chapter" data-level="18.3" data-path="qi.html"><a href="qi.html#收益"><i class="fa fa-check"></i><b>18.3</b> 收益</a></li>
<li class="chapter" data-level="18.4" data-path="qi.html"><a href="qi.html#一般性投资"><i class="fa fa-check"></i><b>18.4</b> 一般性投资</a></li>
<li class="chapter" data-level="18.5" data-path="qi.html"><a href="qi.html#风险管理原理"><i class="fa fa-check"></i><b>18.5</b> 风险管理原理</a></li>
<li class="chapter" data-level="18.6" data-path="qi.html"><a href="qi.html#金融技术与发明"><i class="fa fa-check"></i><b>18.6</b> 金融技术与发明</a></li>
<li class="chapter" data-level="18.7" data-path="qi.html"><a href="qi.html#投资组合"><i class="fa fa-check"></i><b>18.7</b> 投资组合</a></li>
<li class="chapter" data-level="18.8" data-path="qi.html"><a href="qi.html#保险"><i class="fa fa-check"></i><b>18.8</b> 保险</a></li>
<li class="chapter" data-level="18.9" data-path="qi.html"><a href="qi.html#有效市场假说"><i class="fa fa-check"></i><b>18.9</b> 有效市场假说</a></li>
<li class="chapter" data-level="18.10" data-path="qi.html"><a href="qi.html#行为经济学"><i class="fa fa-check"></i><b>18.10</b> 行为经济学</a></li>
<li class="chapter" data-level="18.11" data-path="qi.html"><a href="qi.html#债券"><i class="fa fa-check"></i><b>18.11</b> 债券</a></li>
<li class="chapter" data-level="18.12" data-path="qi.html"><a href="qi.html#银行"><i class="fa fa-check"></i><b>18.12</b> 银行</a></li>
<li class="chapter" data-level="18.13" data-path="qi.html"><a href="qi.html#金融监管"><i class="fa fa-check"></i><b>18.13</b> 金融监管</a></li>
<li class="chapter" data-level="18.14" data-path="qi.html"><a href="qi.html#信用评级"><i class="fa fa-check"></i><b>18.14</b> 信用评级</a></li>
<li class="chapter" data-level="18.15" data-path="qi.html"><a href="qi.html#投行"><i class="fa fa-check"></i><b>18.15</b> 投行</a></li>
<li class="chapter" data-level="18.16" data-path="qi.html"><a href="qi.html#股票"><i class="fa fa-check"></i><b>18.16</b> 股票</a></li>
<li class="chapter" data-level="18.17" data-path="qi.html"><a href="qi.html#房产"><i class="fa fa-check"></i><b>18.17</b> 房产</a></li>
<li class="chapter" data-level="18.18" data-path="qi.html"><a href="qi.html#期货"><i class="fa fa-check"></i><b>18.18</b> 期货</a></li>
<li class="chapter" data-level="18.19" data-path="qi.html"><a href="qi.html#期权"><i class="fa fa-check"></i><b>18.19</b> 期权</a></li>
<li class="chapter" data-level="18.20" data-path="qi.html"><a href="qi.html#金融民主化"><i class="fa fa-check"></i><b>18.20</b> 金融民主化</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/yufree/datadown" target="blank">Github Repo</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">数据分析残卷</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="mlsl" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">第8章</span> 统计模型<a href="mlsl.html#mlsl" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="统计学习概论" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> 统计学习概论<a href="mlsl.html#统计学习概论" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>统计学习：理解数据的工具集</li>
<li>监督学习：有因变量，根据自变量预测估计因变量</li>
<li>非监督学习：无因变量，探索自变量间的关系与结构</li>
</ul>
</div>
<div id="统计学习简史" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> 统计学习简史<a href="mlsl.html#统计学习简史" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>19世纪初，Legendre 与 Gauss 发表了最小二乘法的论文，该方法首先应用在天文学领域</li>
<li>1936年，Fisher 提出线性判别分析来解决定性分析问题</li>
<li>1940s，logistic回归提出</li>
<li>1970s，Nelder 与 Wedderburn 提出广义线性模型，将线性回归与logistic回归统一到一个体系</li>
<li>1980s，计算机技术进步，非线性问题开始得到解决</li>
<li>Breiman，Friedman，Olshen 与 Stone 提出回归树与聚类，提供交叉检验方法</li>
<li>1986年，Hastie 与 Tibshirani 提出广义加性模型，将广义线性模型与一些非线性模型同一到一个体系</li>
<li>伴随软件，机器学习与其他理论的发展，统计学习作为统计学子学科快速发展</li>
</ul>
</div>
<div id="统计学习定义" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> 统计学习定义<a href="mlsl.html#统计学习定义" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><span class="math inline">\(Y = f(X) + \epsilon\)</span></li>
<li>统计学习本质上是在寻找最合适的f来进行<strong>预测</strong>与<strong>推断</strong></li>
</ul>
</div>
<div id="预测" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> 预测<a href="mlsl.html#预测" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><span class="math inline">\(\hat Y = \hat f(X)\)</span>，<span class="math inline">\(\hat f(X)\)</span> 通常看作黑箱</li>
<li><span class="math inline">\(\hat Y\)</span>预测<span class="math inline">\(Y\)</span>需要考虑两部分误差：可约误差与不可约误差</li>
<li>可约误差指<span class="math inline">\(\hat f\)</span>推断<span class="math inline">\(f\)</span>上的偏差</li>
<li>不可约误差指由<span class="math inline">\(\epsilon\)</span>引入的误差</li>
<li>误差的期望 <span class="math inline">\(E(Y - \hat Y)^2 = [f(x) - \hat f(x)]^2 + Var(\epsilon)\)</span> (证明用到<span class="math inline">\(E(Y)\)</span>)</li>
</ul>
</div>
<div id="推断" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> 推断<a href="mlsl.html#推断" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>关注X与Y的关系，<span class="math inline">\(\hat f(X)\)</span> 通常有明确的形式</li>
<li>自变量因变量是否相关</li>
<li>如何相关</li>
<li>关系的数学描述</li>
</ul>
</div>
<div id="估计模型" class="section level2 hasAnchor" number="8.6">
<h2><span class="header-section-number">8.6</span> 估计模型<a href="mlsl.html#估计模型" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>使用训练集与验证集</li>
<li>参数方法与非参数方法</li>
<li>模型的欠拟合与过拟合，回归模型低方差高偏差，邻近聚类高方差低偏差</li>
<li>权衡模型的准确性（预测）与可解释性（推断）</li>
<li>模型的奥卡姆剃刀与黑箱</li>
</ul>
</div>
<div id="评价模型" class="section level2 hasAnchor" number="8.7">
<h2><span class="header-section-number">8.7</span> 评价模型<a href="mlsl.html#评价模型" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="拟合质量测量" class="section level3 hasAnchor" number="8.7.1">
<h3><span class="header-section-number">8.7.1</span> 拟合质量测量<a href="mlsl.html#拟合质量测量" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>训练集均方误 <span class="math inline">\(MSE_{Tr} = Ave_{i \in Tr}[y_{i} − \hat f(x_i)]^2\)</span></li>
<li>测试集均方误 <span class="math inline">\(MSE_{Te} = Ave_{i \in Te}[y_{i} − \hat f(x_i)]^2\)</span></li>
<li>测试集均方误源于训练集拟合模型的方差，误差项<span class="math inline">\(\epsilon\)</span>的方差及模型误差的平方三部分</li>
</ul>
</div>
<div id="聚类评价" class="section level3 hasAnchor" number="8.7.2">
<h3><span class="header-section-number">8.7.2</span> 聚类评价<a href="mlsl.html#聚类评价" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>错误率 <span class="math inline">\(Err_{Te} = Ave_{i \in Te}I[y_i \neq \hat C(x_i)]\)</span></p></li>
<li><p>贝叶斯分类器：错误率最小的分类器，使x属于某个分类的概率最大</p></li>
<li><p>k临近值聚类：距离最小的k个为一类所产生的分类器</p></li>
<li><p>问题 -&gt; 数据 -&gt; 特征 -&gt; 算法 -&gt; 参数 -&gt; 评价</p></li>
</ul>
<blockquote>
<p>The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. John Tukey</p>
</blockquote>
<ul>
<li>数据质量优先于模型</li>
<li>不要自动特征选择</li>
<li>算法的可扩展性与计算性能要考虑</li>
<li>数据过拟合问题 数据总是由信号与噪音组成 但会被算法无差别对待</li>
<li>数据要与问题相关 低相关度的组合可能产生高相关度</li>
</ul>
</div>
</div>
<div id="研究设计" class="section level2 hasAnchor" number="8.8">
<h2><span class="header-section-number">8.8</span> 研究设计<a href="mlsl.html#研究设计" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>定义错误率</li>
<li>将数据分割为训练集 预测集 验证集</li>
<li>在训练集上使用交叉检验选择特征与预测算法</li>
<li>在预测集或验证集上使用一次数据</li>
<li>预测效果起码要优于瞎猜</li>
<li>避免使用小样本</li>
<li>比例为 60% 训练集 20% 预测集 20% 验证集 或 60% 训练集 40% 预测集 或小样本交叉检验</li>
<li>注意数据结构 时序分析要对数据分段采样</li>
</ul>
</div>
<div id="错误率" class="section level2 hasAnchor" number="8.9">
<h2><span class="header-section-number">8.9</span> 错误率<a href="mlsl.html#错误率" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>真阳性 真的是对的 TP</li>
<li>假阳性 真的是错的 FP Type I</li>
<li>真阴性 假的是错的 TN</li>
<li>假阴性 假的是对的 FN Type II</li>
<li>灵敏度 TP/(TP+FP)</li>
<li>特异性 TN/(TN+FN)</li>
<li>均方差 MSE <span class="math inline">\(\frac{1}{n} \sum_{i=1}^n (Prediction_i - Truth_i)^2\)</span></li>
<li>均方误 RMSE <span class="math inline">\(\sqrt{\frac{1}{n} \sum_{i=1}^n(Prediction_i - Truth_i)^2}\)</span></li>
<li>中位差 Median absolute deviation</li>
<li>准确性 (TP+TN)/(TP+FP+TN+FP)</li>
<li>一致性 <a href="https://en.wikipedia.org/wiki/Cohen%27s_kappa">kappa值</a></li>
</ul>
</div>
<div id="roc-曲线" class="section level2 hasAnchor" number="8.10">
<h2><span class="header-section-number">8.10</span> ROC 曲线<a href="mlsl.html#roc-曲线" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>分类问题寻找判别阈值 满足一定TP下最小FP的模型</li>
<li>FP v.s.TP 作图</li>
<li>AUC 曲线下面积表示选择标准 一般超过80%</li>
<li>对角线是随机猜的结果</li>
</ul>
</div>
<div id="重采样技术" class="section level2 hasAnchor" number="8.11">
<h2><span class="header-section-number">8.11</span> 重采样技术<a href="mlsl.html#重采样技术" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="交叉检验" class="section level3 hasAnchor" number="8.11.1">
<h3><span class="header-section-number">8.11.1</span> 交叉检验<a href="mlsl.html#交叉检验" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>训练集上的操作</p></li>
<li><p>训练集上再分为训练集与测试集</p></li>
<li><p>在测试集上评价 重复并平均化测试集错误</p></li>
<li><p>用来进行变量 模型 参数选择</p></li>
<li><p>随机 分组 留一</p></li>
<li><p>分组多方差大 分组少有偏差</p></li>
<li><p>有放回的为bootstrap 不建议用</p></li>
<li><p>核心思想：通过保留一部份训练集数据作为检验集来估计真实检验集的错误率与模型拟合效果</p></li>
<li><p>验证集方法：将训练集数据分为两部分，一部份拟合模型，一部份检验模型，这样得到的错误率为真实检验集的一个估计，选取错误率较低的模型建模</p></li>
<li><p>验证集方法缺点：错误率依赖于采样变动较大，训练集少，高估了错误率</p></li>
<li><p>留一法(LOOCV)：每次建模留一个数据点作为验证集，<span class="math inline">\(MSE_i = (y_i - \hat y_i)^2\)</span>重复n次，得到一个CV值作为对错误率的估计:<span class="math inline">\(CV_{(n)} = \frac{1}{n} \sum_{i = 1}^{n} MSE_i\)</span></p></li>
<li><p>留一法优点：使用数据量大，偏差小；结果唯一，不受随机化影响</p></li>
<li><p>留一法缺点：计算量大，公式插入杠杆统计量调节杠杆点对方程拟合的影响，得到<span class="math inline">\(CV_{(n)} = \frac{1}{n} \sum_{i = 1}^{n} (\frac{y_i - \hat y_i}{1 - h_i})^2\)</span></p></li>
<li><p>k叠交叉检验：将训练集分为k叠，每次建模用(k-1)叠，用1叠检验</p></li>
<li><p>k叠交叉检验优点：计算量小，结果与留一法相差不多- 交叉检验的结果用来寻找<span class="math inline">\(CV\)</span>值最小的点来选择模型，通常与真实检验集最小点结果相差不大乎，但交叉检验给出的<span class="math inline">\(MSE\)</span>会偏低</p></li>
<li><p>偏差方差权衡：使用的训练集数据越多，估计偏差越小，方差越大（相关性越高的方差越大）</p></li>
<li><p>分类问题使用错误率计算<span class="math inline">\(CV\)</span>：<span class="math inline">\(CV{(n)} = \frac{1}{n} \sum_{i = 1}^{n} Err_{i}\)</span></p></li>
<li><p><em>少n多p问题上使用交叉检验，不可先进行全模型变量选择再交叉检验，应该对整个过程交叉检验</em></p></li>
</ul>
</div>
<div id="bootstrap" class="section level3 hasAnchor" number="8.11.2">
<h3><span class="header-section-number">8.11.2</span> bootstrap<a href="mlsl.html#bootstrap" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>在训练集里有放回的重采样等长的数据形成新的数据集并计算相关参数，重复n次得到对参数的估计，计算标准误</li>
<li>生成Bootstrap Percentile置信区间</li>
<li>适用于独立样本，样本间有相关如时间序列数据可采用block法分组屏蔽掉进行bootstrap</li>
<li>因为存在重复，使用bootstrap建立训练集与预测集会有非独立样本，造成检验集模型方差的低估，去掉重复使模型复杂，不如交叉检验对检验集误差估计的准</li>
<li><a href="https://github.com/jtleek/slipper">slipper 包</a></li>
</ul>
</div>
</div>
<div id="caret-包" class="section level2 hasAnchor" number="8.12">
<h2><span class="header-section-number">8.12</span> <code>caret</code> 包<a href="mlsl.html#caret-包" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>数据清洗 预处理</li>
<li>数据分割 <code>createDataPartition</code> 数据比例 重采样 产生时间片段</li>
<li>训练检验整合函数 <code>train</code> <code>predict</code></li>
<li>模型对比</li>
<li>算法整合为选项 线性判别 回归 朴素贝叶斯 支持向量机 分类与回归树 随机森林 Boosting 等</li>
</ul>
</div>
<div id="数据分割" class="section level2 hasAnchor" number="8.13">
<h2><span class="header-section-number">8.13</span> 数据分割<a href="mlsl.html#数据分割" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><code>train &lt;- createDataPartition(y=spam$type,p=0.75, list=FALSE)</code> 数据三一分 得到index</li>
<li><code>folds &lt;- createFolds(y=spam$type,k=10,list=TRUE,returnTrain=TRUE)</code> 数据分10份 返回每一份列表</li>
<li><code>folds &lt;- createResample(y=spam$type,times=10,list=TRUE)</code> 数据bootstrap重采样 返回每一份列表</li>
<li><code>folds &lt;- createTimeSlices(y=tme,initialWindow=20,horizon=10)</code> 时序数据重采样 产生20为窗口时序片段的训练集与预测集</li>
</ul>
</div>
<div id="训练选项" class="section level2 hasAnchor" number="8.14">
<h2><span class="header-section-number">8.14</span> 训练选项<a href="mlsl.html#训练选项" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><code>args(train.default)</code> 通过 <code>method</code> 控制算法 <code>metric</code> 控制算法评价 <code>trainControl</code> 控制训练方法</li>
<li><code>trainControl</code>中 <code>method</code>选择模型选择方法 如bootstrap 交叉检验 留一法 <code>number</code> 控制次数 <code>repeats</code> 控制重采样次数 <code>seed</code> 控制可重复性 总体设置一个 具体每一次用列表设置控制具体过程 特别是并行模型</li>
</ul>
</div>
<div id="预测变量作图" class="section level2 hasAnchor" number="8.15">
<h2><span class="header-section-number">8.15</span> 预测变量作图<a href="mlsl.html#预测变量作图" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><code>featurePlot</code></li>
<li><code>ggplot2</code></li>
</ul>
</div>
<div id="数据预处理" class="section level2 hasAnchor" number="8.16">
<h2><span class="header-section-number">8.16</span> 数据预处理<a href="mlsl.html#数据预处理" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><code>train</code> 中的 <code>preProcess=c("center","scale")</code> 标准化</li>
<li><code>spatialSign</code> 该转化可提高计算效率 有偏</li>
<li><code>preProcess(training[,-58],method=c("BoxCox"))</code> 正态化转化</li>
<li><code>method="knnImpute"</code> 用最小邻近法填补缺失值</li>
<li><code>nearZeroVar</code> 去除零方差变量</li>
<li><code>findCorrelation</code> 去除相关变量</li>
<li><code>findLinearCombos</code> 去除线性组合变量</li>
<li><code>classDist</code> 测定分类变量的距离 生成新变量</li>
<li>测试集也要预处理</li>
</ul>
</div>
<div id="协变量生成" class="section level2 hasAnchor" number="8.17">
<h2><span class="header-section-number">8.17</span> 协变量生成<a href="mlsl.html#协变量生成" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>原始数据提取特征</li>
<li>提取特征后生成新变量</li>
<li>因子变量要转为虚拟变量</li>
<li>样条基变量 <code>splines</code> 包中的 <code>bs</code></li>
<li>数据压缩 <code>preProcess</code> 中 <code>method</code> 设置为 <code>pca</code> <code>pcaComp</code> 指定主成分个数</li>
</ul>
</div>
<div id="线性回归多元线性回归" class="section level2 hasAnchor" number="8.18">
<h2><span class="header-section-number">8.18</span> 线性回归&amp;多元线性回归<a href="mlsl.html#线性回归多元线性回归" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><span class="math inline">\(ED_i = b_0 + b_1 WT_i + e_i\)</span> 基本模型</li>
<li>参见前面回归部分</li>
</ul>
<div id="简单线性回归" class="section level3 hasAnchor" number="8.18.1">
<h3><span class="header-section-number">8.18.1</span> 简单线性回归<a href="mlsl.html#简单线性回归" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><span class="math inline">\(Y \approx \beta_0 + \beta_1 X\)</span></li>
<li>用最小二乘法估计<span class="math inline">\(\beta_0\)</span>与<span class="math inline">\(\beta_1\)</span>得到估计值<span class="math inline">\(\hat \beta_0\)</span>与<span class="math inline">\(\hat \beta_1\)</span>，代入<span class="math inline">\(X\)</span>，得到模型估计值<span class="math inline">\(\hat Y\)</span></li>
<li>残差平方和：<span class="math inline">\(RSS = e_1^2 + e_2^2 + ... + e_n^2\)</span>，使RSS最小，求导可得参数</li>
<li>回归线不等于最小二乘线，最小二乘线是通过采样对回归线的估计</li>
<li>估计会存在偏差，均值的偏差用标准误来描述<span class="math inline">\(Var(\hat \mu) = SE(\mu)^2 = \frac{\sigma^2}{n}\)</span></li>
<li>回归参数的估计也涉及标准误的计算<span class="math inline">\(Var(\beta_{1}) = \frac{\sigma^2}{\sum_{i=1}^n{(x_i - \bar{x})^2}}\)</span></li>
<li><span class="math inline">\(\sigma^2\)</span>可用残差标准误RSE(<span class="math inline">\(RSE = RSS/(n − 2)\)</span>)来估计<span class="math inline">\(\qquad\hat\sigma^2 = \frac{n-p}{n}\;s^2\)</span></li>
<li>据此可得回归参数的95%置信区间<span class="math inline">\(\hat \beta_1 ± 2 \cdot SE(\hat \beta_1)\)</span></li>
<li>参数的评价可通过假设检验进行，零假设为<span class="math inline">\(\beta_1\)</span>为0，也就是自变量对因变量无影响，构建t统计量<span class="math inline">\(t = \frac{\hat \beta_1 - 0}{\hat {SE}(\hat \beta_1)}\)</span>，然后可根据p值判断参数的显著性</li>
<li>评价参数后需要评价模型，主要通过<span class="math inline">\(RSE\)</span>与<span class="math inline">\(R^2\)</span>来进行</li>
<li><span class="math inline">\(R^2\)</span>表示模型所解释总体方差的比例，与<span class="math inline">\(RSE\)</span>不同，独立于Y，<span class="math inline">\(R^2 = \frac{TSS - RSS}{TSS}\)</span></li>
<li><span class="math inline">\(R^2\)</span>与两变量间的相关系数是一致的，但<span class="math inline">\(R^2\)</span>统计量的应用面要广于相关系数</li>
<li>相关系数也可进行假设检验进而判断相关的显著性</li>
</ul>
</div>
<div id="多元线性回归" class="section level3 hasAnchor" number="8.18.2">
<h3><span class="header-section-number">8.18.2</span> 多元线性回归<a href="mlsl.html#多元线性回归" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>通过统计量F检验确定回归是否显著，零假设为所有自变量系数为0 <span class="math inline">\(F = \frac{(TSS - RSS)/p}{RSS/(n-p-1)}\)</span></li>
<li>变量选择：向前选择（从0个到p个，显著则包含），向后选择（从p个到0个，不显著则剔除），混合选择（通过p的阈值调节）</li>
<li>因为RSS会减少，<span class="math inline">\(R^2\)</span>会伴随自变量数目的增加而增加</li>
<li><span class="math inline">\(RSE\)</span>在多元线性线性回归中为<span class="math inline">\(RSE = RSS/(n − p - 1)\)</span>，伴随自变量个数增加影响超过<span class="math inline">\(RSS\)</span>减少的影响，<span class="math inline">\(RSE\)</span>会增大</li>
<li>自变量间的影响会导致相比单一变量预测更容易出现不显著，这说明自变量间有可能可相互解释</li>
<li>预测的置信区间与预测区间，前者指模型的变动范围，后者指某个预测值的变动范围，考虑真值本身的变动，后者大于前者</li>
<li>因子变量通过对每个水平添加系数0，1来回归，也可根据需要赋值</li>
</ul>
</div>
<div id="线性模型延拓" class="section level3 hasAnchor" number="8.18.3">
<h3><span class="header-section-number">8.18.3</span> 线性模型延拓<a href="mlsl.html#线性模型延拓" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>线性模型基本假设：可加性与线性</li>
<li>去掉可加性：考虑交互作用</li>
<li>层级原理：交互作用项显著而主作用不显著时不可去掉主作用项</li>
<li>去掉线性：多项式回归</li>
</ul>
</div>
<div id="常见问题-1" class="section level3 hasAnchor" number="8.18.4">
<h3><span class="header-section-number">8.18.4</span> 常见问题<a href="mlsl.html#常见问题-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>关系非线性：残差图判断</li>
<li>误差项共相关：误差项的相关会导致标准误估计偏低，低估参数的区间使不显著差异变得显著，考虑时间序列数据，观察误差项轨迹判断</li>
<li>误差项方差非常数：喇叭状残差图，通过对因变量进行对数或开方来收敛方差，或者用加权最小二乘</li>
<li>异常值：通过标准化残差图判断</li>
<li>杠杆点：加入后会影响模型拟合，通过杠杆统计量判断： <span class="math inline">\(h_i = \frac{1}{n} + \frac{(x_i - \bar x)^2}{\sum_{i&#39; = 1}^{n} (x_i&#39; - \bar x)^2}\)</span> 多元回归中该统计量均值为<span class="math inline">\((p+1)/n\)</span>，超过很多则可能为杠杆点</li>
<li>在标准残差-杠杆值图中，右上或右下方为危险值，左方数值对回归影响不大</li>
<li>共线性：共线性的变量相互可替代，取值范围扩大，标准误加大，对因变量影响相互抵消，降低参数假设检验的功效</li>
<li>多重共线性：引入方差膨胀因子，自变量引入全模型与单一模型方差的比值，超过5或10说明存在共相关，<span class="math inline">\(VIF(\hat \beta_j) = \frac{1}{1 - R^2_{X_j|X_{-j}}}\)</span></li>
<li>解决共线性：丢弃变量或合并变量</li>
<li>共线性不同于交互作用</li>
</ul>
</div>
<div id="线性回归与kmeans算法比较" class="section level3 hasAnchor" number="8.18.5">
<h3><span class="header-section-number">8.18.5</span> 线性回归与kmeans算法比较<a href="mlsl.html#线性回归与kmeans算法比较" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>k临近算法：<span class="math inline">\(\hat f(x_0) = \frac{1}{K} \sum_{x_i \in N_0} y_i\)</span> 核心是选择k</li>
<li>KNN算法在解决非线性问题上有优势，但一样的面对高维诅咒</li>
<li>线性回归可给出可解释的形式与简单的描述</li>
</ul>
</div>
<div id="logistic回归" class="section level3 hasAnchor" number="8.18.6">
<h3><span class="header-section-number">8.18.6</span> logistic回归<a href="mlsl.html#logistic回归" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>因变量以概率形式出现</li>
<li><span class="math inline">\(p(X) = \frac {e^{\beta_0 + \beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}}\)</span></li>
<li>变形后<span class="math inline">\(\frac {p(X)}{1 - p(X)}\)</span> 为胜率，比概率应用更实际些，去对数后为对数胜率（logit）</li>
<li>因变量<span class="math inline">\(p(X)\)</span>与自变量间关系非线性</li>
<li>用极大似然估计确定参数，似然函数为<span class="math inline">\(l(\beta_0, \beta_1) = \prod_{i:y_i = 1} p(x_i)\prod_{i&#39;:y_{i&#39;} = 0} (1 - p(x_{i&#39;}))\)</span>，该函数取最大值</li>
<li>线性回归中，最小二乘法为极大似然估计的特例</li>
<li>混杂因素的解释上要考虑单因素回归与多元回归</li>
<li>多响应logistic回归一般被判别分析取代</li>
</ul>
</div>
<div id="线性判别分析" class="section level3 hasAnchor" number="8.18.7">
<h3><span class="header-section-number">8.18.7</span> 线性判别分析<a href="mlsl.html#线性判别分析" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>使用原因：分类离散时logistic回归不稳定，n小X正态时更稳定，适用于多响应</li>
<li>贝页斯理论：<span class="math inline">\(Pr(Y = k|X = x) = \frac{\pi_k f_k(x)}{\sum_{l = 1}^K \pi_lf_l(x)}\)</span> 其中<span class="math inline">\(\pi\)</span> 代表先验概率，估计<span class="math inline">\(f_k(X)\)</span>需要对<span class="math inline">\(x\)</span>的分布作出假设</li>
<li>自变量为1时，假定<span class="math inline">\(f_k(x)\)</span>分布为正态的，有<span class="math inline">\(f_k(x) = \frac{1}{\sqrt{2 \pi} \sigma_k} exp(- \frac{1}{2 \sigma_k^2} (x - \mu_k)^2)\)</span>，代入可得<span class="math inline">\(p_k(x)\)</span>，取对数有<span class="math inline">\(\sigma_k(x) = x \cdot \frac{\mu_k}{\sigma^2} - \frac{\mu_k^2}{2\sigma^2} + log(\pi_k)\)</span>，使<span class="math inline">\(\sigma_k(x)\)</span>最大的分类方法为判定边界</li>
<li>贝页斯分类器需要知道所有分布参数，实际中会采用线性判别分析（LDA），通过以下训练集估计方法来插入贝页斯分类器：<span class="math inline">\(\hat \pi_k = n_k/n\)</span>、<span class="math inline">\(\hat \mu_k = \frac{1}{n_k} \sum_{i:y_i = k} x_i\)</span> 与 <span class="math inline">\(\hat \sigma^2 = \frac{1}{n - K} \sum_{k = 1}^K \sum_{i:y_i = k} (x_i - \hat \mu_k)^2\)</span></li>
<li>线性体现在判别函数<span class="math inline">\(\hat \sigma_k(x)\)</span>的形式是线性的</li>
<li>自变量多于1时，假设自变量均来自多元正态分布的分类</li>
<li>列连表，表示假阳性，假阴性，可计算灵敏度与特异性</li>
<li>LDA是对贝页斯分类的模拟，旨在降低总错误率，因此灵敏度与特异性区分并不明显，可根据实际需要调节</li>
<li>ROC曲线用来展示两种错误，横坐标假阳性，纵坐标真阳性</li>
</ul>
</div>
<div id="二次判别分析qda及其它" class="section level3 hasAnchor" number="8.18.8">
<h3><span class="header-section-number">8.18.8</span> 二次判别分析（QDA）及其它<a href="mlsl.html#二次判别分析qda及其它" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>不同于LDA，二次判别分析考虑各分类参数中方差不同而不是相同，引入了二次项</li>
<li>对分类描述更为精细，但容易过拟合，样本较少，LDA优先</li>
<li>对比logistic回归，两者数学形式相近，取值上logistic回归使用极大似然法，LDA使用共方差的高斯分布假设，结论多数条件一致，但随假设不同而不同</li>
<li>KNN更适用于非线性关系，标准化很有必要，QDA相对温和</li>
</ul>
</div>
<div id="线性模型选择与正则化" class="section level3 hasAnchor" number="8.18.9">
<h3><span class="header-section-number">8.18.9</span> 线性模型选择与正则化<a href="mlsl.html#线性模型选择与正则化" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>最小二乘法（OLS）容易解释，预测性能好，但不万能</li>
<li>预测准确性上，当p&gt;n时，模型方差变大</li>
<li>模型解释上，p过多需要去除，进行模型选择</li>
</ul>
<div id="子集选择" class="section level4 hasAnchor" number="8.18.9.1">
<h4><span class="header-section-number">8.18.9.1</span> 子集选择<a href="mlsl.html#子集选择" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>从p个自变量中选出与模型响应相关的进行建模</li>
<li>使用devianc，最大化为最优子集</li>
<li>最佳子集选择：p个自变量<span class="math inline">\(p \choose k\)</span> ，计算<span class="math inline">\(RSS\)</span>与<span class="math inline">\(R^2\)</span>，<span class="math inline">\(RSS\)</span>要小，<span class="math inline">\(R^2\)</span>要大，选择最佳的</li>
<li>步进法：p值过大，计算负担重，采用逐步改进法进行模型选择</li>
<li>向前步进选择：从0个自变量开始加，第k个自变量选择p-k个模型，如果<span class="math inline">\(RSS\)</span>与<span class="math inline">\(R^2\)</span>表现好就保留，递近选择变量，不保证选择最佳模型，p值较大优先考虑</li>
<li>向后步进选择：从p个自变量开始减，如果第k个自变量在模型<span class="math inline">\(RSS\)</span>与<span class="math inline">\(R^2\)</span>中没表现，就剔除进行变量选择，不保证选择最佳模型，适用于p值较小的情况(较大可能无法拟合)</li>
<li>步进选择构建<span class="math inline">\(1 + p(p+1)/2\)</span>个模型，最佳子集法需要构建<span class="math inline">\(2^p\)</span>个模型</li>
<li>混合模型:向前选择，之后向后验证，剔除不再提高效果的模型</li>
</ul>
</div>
<div id="测试集误差估计" class="section level4 hasAnchor" number="8.18.9.2">
<h4><span class="header-section-number">8.18.9.2</span> 测试集误差估计<a href="mlsl.html#测试集误差估计" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><span class="math inline">\(RSS\)</span>与<span class="math inline">\(R^2\)</span>评价的是训练集拟合状况，不适用于估计测试集误差</li>
<li>估计测试集误差可以构建统计量调节训练集误差或直接通过验证集来估计</li>
<li>Mallow’s <span class="math inline">\(C_p\)</span>：<span class="math inline">\(C_p = \frac{1}{n} (RSS + 2d\hat \sigma^2)\)</span> <span class="math inline">\(d\)</span>代表使用的变量数，<span class="math inline">\(\hat \sigma^2\)</span>是对模型方差的估计</li>
<li>AIC：<span class="math inline">\(AIC = -2logL + 2 \cdot d\)</span> 极大似然估计，线性模型下<span class="math inline">\(C_p\)</span>与AIC实质等同</li>
<li>BIC：<span class="math inline">\(BIC = \frac{1}{n}(RSS + log(n)d\hat \sigma^2)\)</span> n是样本数，大于7时BIC会比<span class="math inline">\(C_p\)</span>选择更轻量的模型</li>
<li>调节<span class="math inline">\(R^2\)</span>：<span class="math inline">\(Adjusted\)</span> <span class="math inline">\(R^2 = 1 - \frac{RSS/n-d-1}{TSS/(n - 1)}\)</span> 值越大，测试集误差越小</li>
<li>不同于<span class="math inline">\(C_p\)</span>，AIC，BIC有严格的统计学意义，调节<span class="math inline">\(R^2\)</span>虽然直观，但理论基础相对薄弱，单纯考虑了对无关变量的惩罚</li>
<li>验证与交叉验证：直接估计测试集误差而不用估计模型方差</li>
<li>单标准误原则：先计算不同规模测试集<span class="math inline">\(MSE\)</span>的标准差，选择曲线中最小测试集误差一个标准误内最简单的模型</li>
</ul>
</div>
<div id="收缩" class="section level4 hasAnchor" number="8.18.9.3">
<h4><span class="header-section-number">8.18.9.3</span> 收缩<a href="mlsl.html#收缩" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>对系数估计进行收缩，接近0或等于0进行变量选择</li>
</ul>
<div id="岭回归" class="section level5 hasAnchor" number="8.18.9.3.1">
<h5><span class="header-section-number">8.18.9.3.1</span> 岭回归<a href="mlsl.html#岭回归" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>不同于最小二乘估计对<span class="math inline">\(RSS\)</span>的最小化，岭回归最小化<span class="math inline">\(RSS + \lambda \sum_{j = 1}^{p} \beta_j^2\)</span>，其中<span class="math inline">\(\lambda\)</span>为调谐参数，后面一项为收缩惩罚，是个<span class="math inline">\(l_2\)</span>范数，使参数估计逼近0，选择合适<span class="math inline">\(\lambda\)</span>很重要，可用交叉检验来实现</li>
<li>因为范数大小影响模型惩罚项，所以进行岭回归前要做标准化处理<span class="math display">\[\bar x_{ij} = \frac{x_{ij}}{\sqrt{\frac{1}{n} \sum_{i = 1}^n (x_{ij} - \bar x_j)^2}}\]</span></li>
<li>岭回归的参数<span class="math inline">\(\lambda\)</span>与范数收缩状况可看作最小<span class="math inline">\(MSE\)</span>的函数来表现偏差-误差均衡</li>
<li>岭回归适用于最小二乘回归产生方差较大的情况，同时，计算负担较小，只伴随<span class="math inline">\(\lambda\)</span>取值范围变化而变化</li>
</ul>
</div>
<div id="lasso" class="section level5 hasAnchor" number="8.18.9.3.2">
<h5><span class="header-section-number">8.18.9.3.2</span> Lasso<a href="mlsl.html#lasso" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<ul>
<li>形式与岭回归一致，最小化<span class="math inline">\(RSS + \lambda \sum_{j = 1}^{p} |\beta_j|\)</span>，使用<span class="math inline">\(l_1\)</span>范数</li>
<li>岭回归参数同步收缩接近0，Lasso可以通过软边界直接收缩到0实现变量选择，产生稀疏模型，想像超球体与超多面体与超球面的接触</li>
<li>贝页斯视角下，岭回归与lasso关于线性模型系数的先验分布是不同的：前者为高斯分布，接近0时平坦，后验概率等同最优解；后者为拉普拉斯分布，接近0时尖锐，先验概率系数接近0，后验概率不一定为稀疏向量</li>
<li>岭回归与Lasso分别适用于真实模型自变量多或少的情况，并不广谱，考虑交叉检验来进行选择</li>
<li>交叉检验也可用来选择<span class="math inline">\(\lambda\)</span>, 通过选择的自变量参与建模</li>
</ul>
</div>
</div>
<div id="降维" class="section level4 hasAnchor" number="8.18.9.4">
<h4><span class="header-section-number">8.18.9.4</span> 降维<a href="mlsl.html#降维" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>前提是自变量间不独立，将p个自变量向量投影到M维空间(M &lt; p)，使用投影M拟合线性回归模型 <span class="math inline">\(\sum_{m = 1}^{M}\theta_m z_{im} = \sum_{m = 1}^{M} \theta_m \sum_{j = 1}^{p} \phi_{jm}x_{ij} = \sum_{j = 1}^p \sum_{m = 1}^{M} \theta_m \phi_{jm} x_{ij} = \sum_{j = 1}^{p} \beta_j x_{ij}\)</span></li>
<li>主成分：各自变量在主成分方向上方差最大</li>
<li>主成分回归(PCA)：实际为无监督算法，得到主成分后作为新变量进行最小二乘回归，认为因变量与自变量变异最大的方向一致，需要仔细检验这个假设，主成分个数的选择影响模型效果</li>
<li>岭回归疑似为主成分回归的连续版，两者都需要标准化，效果也相近</li>
<li>偏最小二乘(PLA)：第一个投影方向为因变量与自变量回归方向，后续投影是对残差投影方向的回归，重复得到监督学习的效果</li>
<li>PLA通常并不比PCA更好，引入了监督算法提高了偏差</li>
</ul>
</div>
<div id="高维数据" class="section level4 hasAnchor" number="8.18.9.5">
<h4><span class="header-section-number">8.18.9.5</span> 高维数据<a href="mlsl.html#高维数据" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>n远远少于p或接近的数据</li>
<li>最小二乘估计在n小于p时残差为0，太过精细</li>
<li><span class="math inline">\(C_p\)</span>，AIC，BIC方法因为有参数<span class="math inline">\(\hat \sigma^2\)</span>需要估计，而这个参数会在高维数据下变成0，调节<span class="math inline">\(R^2\)</span>也会变成1</li>
<li>高维诅咒：正则化或收缩对高维方法产生影响，合适调谐参数十分重要，测试集误差必然增长</li>
<li>引入新变量会对预测产生不可知影响，选出的自变量并非不可替代，结果用独立验证集误差或交叉检验误差描述</li>
</ul>
</div>
</div>
</div>
<div id="非线性" class="section level2 hasAnchor" number="8.19">
<h2><span class="header-section-number">8.19</span> 非线性<a href="mlsl.html#非线性" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="多项式回归" class="section level3 hasAnchor" number="8.19.1">
<h3><span class="header-section-number">8.19.1</span> 多项式回归<a href="mlsl.html#多项式回归" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>模型基本形式为单一自变量在不同幂指数下的多项式，最小二乘拟合</li>
<li>模型在特定点的方差受系数方差与协方差影响，幂越高，模型越精细，方差越大</li>
<li>幂次一般不超过3或4</li>
<li>可进行logistic回归</li>
</ul>
</div>
<div id="阶梯函数" class="section level3 hasAnchor" number="8.19.2">
<h3><span class="header-section-number">8.19.2</span> 阶梯函数<a href="mlsl.html#阶梯函数" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>阶梯函数将自变量由连续变成有序分类变量</li>
<li>函数形式为引入指标函数<span class="math inline">\(C_K(x)\)</span>进行自变量分段，然后进行最小二乘拟合</li>
<li>依赖找间隔点</li>
<li>可进行logistic回归</li>
</ul>
</div>
<div id="基函数" class="section level3 hasAnchor" number="8.19.3">
<h3><span class="header-section-number">8.19.3</span> 基函数<a href="mlsl.html#基函数" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>固定线性系数<span class="math inline">\(\beta\)</span>,自变量的形式由<span class="math inline">\(b(x)\)</span>决定，<span class="math inline">\(b(x)\)</span>为基函数</li>
<li>多项式回归与阶梯函数均为基函数的特例</li>
</ul>
</div>
<div id="回归样条" class="section level3 hasAnchor" number="8.19.4">
<h3><span class="header-section-number">8.19.4</span> 回归样条<a href="mlsl.html#回归样条" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>设定分段点，分段点前后进行多项式回归</li>
<li>K个点分割(K+1)段，存在(K+1)个多项式回归，自由度过高</li>
<li>进行边界约束，对n次方程而言，约束分段点0阶，1阶，2阶导数连续，减少3个自由度，共有K个点，则有<span class="math inline">\((n+1-3)k + n + 1\)</span>个自由度，相比无约束的<span class="math inline">\((n+1)k\)</span>，自由度减少，更稳健</li>
<li>一般而言约束限制为(自由度-1)阶连续，这样自由度比分界点略多些，够用</li>
<li>分段样条最好在两端加入线性限制，收敛自由度，这样在边界稳健，为自然样条</li>
<li>分段点位置一般均匀分布，个数（本质上是自由度）通过交叉检验来确定</li>
<li>分段多项式回归限定了自由度，因此结果一般比多项式回归更稳定</li>
</ul>
</div>
<div id="平滑样条" class="section level3 hasAnchor" number="8.19.5">
<h3><span class="header-section-number">8.19.5</span> 平滑样条<a href="mlsl.html#平滑样条" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>如果以RSS衡量不加入限制，很容易产生过拟合，因此考虑加入平滑项</li>
<li>最小化 <span class="math display">\[ \sum_{i = 1}^n (y_{i} - g(x_i))^2 + \lambda \int g&#39;&#39;(t)^2 dt \]</span> 其中，<span class="math inline">\(g(x)\)</span>为平滑样条，由损失函数与惩罚项组成，二次导数表示在t处的平坦度，越平坦，惩罚越小，越崎岖，惩罚越大，因而平滑</li>
<li>对三次函数而言，平滑样条会将函数两端收敛的跟自然样条一样，实际上，平滑样条是自然样条的收缩版</li>
<li>参数<span class="math inline">\(\lambda\)</span>也影响平滑效果，越大越平滑，因为k固定，只涉及<span class="math inline">\(\lambda\)</span>的选择</li>
<li>参数<span class="math inline">\(\lambda\)</span>的选择基于有效自由度，可以用留一法进行估计，形式与杠杆点统计量差不多，可以很方便的进行数值求解</li>
<li>平滑样条的自由度比多项式要小，更稳健</li>
</ul>
</div>
<div id="本地回归" class="section level3 hasAnchor" number="8.19.6">
<h3><span class="header-section-number">8.19.6</span> 本地回归<a href="mlsl.html#本地回归" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>首先分段，然后分段内进行加权回归，离某点越近，权重越高，进行最小二乘拟合，得到每个点的函数，联合模型拟合</li>
<li>自变量较多，可考虑本地有选择的选取自变量进行本地回归</li>
<li>同样遭受高维诅咒带来的临近值少或稀疏问题</li>
</ul>
</div>
<div id="广义加性模型" class="section level3 hasAnchor" number="8.19.7">
<h3><span class="header-section-number">8.19.7</span> 广义加性模型<a href="mlsl.html#广义加性模型" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><span class="math display">\[y_i = \beta_0 + \sum_{i = 1}^n f_j(x_{ij}) + \epsilon\]</span> 每个自变量都有自己的函数形式，加合求解</li>
<li>每个自变量影响都可以展示</li>
<li>可分段，也可使用平滑，平滑方法中使用了反馈拟合策略对不易用最小二乘拟合求解的问题进行求解，效果差不多，分段不必要</li>
<li>可用于分类回归问题，解释性好</li>
<li>优点：非线性，更准确，易解释，可进行统计推断，可用自由度衡量平滑性</li>
<li>缺点：不易考虑交互影响</li>
</ul>
</div>
</div>
<div id="树" class="section level2 hasAnchor" number="8.20">
<h2><span class="header-section-number">8.20</span> 树<a href="mlsl.html#树" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="回归树" class="section level3 hasAnchor" number="8.20.1">
<h3><span class="header-section-number">8.20.1</span> 回归树<a href="mlsl.html#回归树" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>将因变量按自变量分区间，每个区间内预测值一致，直观易解释</li>
<li><span class="math inline">\(\sum_{j = 1}^J\sum_{i \in R_J}(y_i - \hat y_{R_j})^2\)</span></li>
<li>计算困难，使用自上而下的贪心算法</li>
<li>递归二元分割：构建树过程每个节点都选最佳分割点，也就是分割后残差最小的变量与数值</li>
<li>算法在叶样本数为5时结束</li>
<li>树修剪，选择训练集误差最小的子树，引入调谐因子<span class="math inline">\(\alpha\)</span></li>
<li>最小化<span class="math inline">\(\sum_{m = 1}^{|T|} \sum_{i:x_i \in R_m} (y_i - \hat y_{R_m})^2 + \alpha|T|\)</span> 类似lasso算法</li>
<li>确定<span class="math inline">\(\alpha\)</span>要用交叉检验，之后选出特定模型</li>
</ul>
</div>
<div id="分类树" class="section level3 hasAnchor" number="8.20.2">
<h3><span class="header-section-number">8.20.2</span> 分类树<a href="mlsl.html#分类树" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>因变量为分类变量，RSS用分类错误率代替</li>
<li><span class="math inline">\(E = 1 - max_k(\hat p_{mk})\)</span>但分类错误率对树生长并不敏感，应采用其他指标</li>
<li>Gini系数：<span class="math inline">\(G = \sum_{k = 1}^K\hat p_{mk}(1 - \hat p_{mk})\)</span>，分类越准，值越小，衡量端纯度</li>
<li>cross-entropy：<span class="math inline">\(D = - \sum_{k = 1}^K\hat p_{mk} log\hat p_{mk}\)</span>，与Gini系数相似，描述一致</li>
<li>如果以修剪树为目标，指标应选择分类错误率</li>
<li>节点产生相同预测说明预测纯度不同，可靠性不同</li>
<li>与线性模型相比，适用数据种类不同，借助可视化判断</li>
<li>优点：容易解释，适用于决策，容易出图，处理分类问题简单</li>
<li>缺点：预测准确率低于其他常见回归与分类方法</li>
</ul>
</div>
<div id="bagging" class="section level3 hasAnchor" number="8.20.3">
<h3><span class="header-section-number">8.20.3</span> Bagging<a href="mlsl.html#bagging" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>决策树方法相比线性回归模型方差很大</p></li>
<li><p>引入Bootstrap，通过平均构建低方差模型</p></li>
<li><p><span class="math inline">\(\hat f_{avg}(x) = \frac{1}{B} \sum_{b = 1}^B \hat f^{*b}(x)\)</span></p></li>
<li><p>不修剪，通过平均降低方差</p></li>
<li><p>对于分类变量，通过投票，少数服从多数得到答案</p></li>
<li><p>误差估计通过包外样本（OOB）进行交叉检验并进行树的选择，降低计算成本</p></li>
<li><p>变量权重在Bagging中不易衡量，可通过衡量每棵树的RSS或者Gini系数在进行一次变量分割后RSS下降程度并进行排序取得</p></li>
<li><p>该方法可应用于其他统计模型</p></li>
<li><p>重采样 重新计算预测值</p></li>
<li><p>平均或投票给出结果</p></li>
<li><p>减少方差 偏差类似 适用于非线性过程</p></li>
<li><p>bagged trees</p>
<ul>
<li>重采样</li>
<li>重建树</li>
<li>结果重评价</li>
<li>更稳健 效果不如RF</li>
</ul></li>
<li><p>Bagged loess 可用来处理细节</p></li>
</ul>
</div>
<div id="随机森林" class="section level3 hasAnchor" number="8.20.4">
<h3><span class="header-section-number">8.20.4</span> 随机森林<a href="mlsl.html#随机森林" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>bagging中使用所有的变量进行选择，但是会更易出现共相关变量，方差降低不多</li>
<li>随机森林的核心在于强制使用较少的自变量，为其他自变量提供预测空间进而提高模型表现</li>
<li>变量数一般选择为<span class="math inline">\(\sqrt p\)</span></li>
<li>表现会比bagging好一些</li>
<li>bootstrap采样</li>
<li>每一个节点bootstrap选取变量</li>
<li>多棵树投票</li>
<li>准确度高 速度慢 不好解释 容易过拟合</li>
</ul>
</div>
<div id="boosting" class="section level3 hasAnchor" number="8.20.5">
<h3><span class="header-section-number">8.20.5</span> Boosting<a href="mlsl.html#boosting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>通用的统计学习方法</p></li>
<li><p>树生长基于先前的树，不使用bootstrap，使用修改过的原始数据</p></li>
<li><p>先生成有d个节点的树，之后通过加入收缩的新树来拟合残差，收缩因子为<span class="math inline">\(\lambda\)</span>，呈现层级模式，最后模型为<span class="math inline">\(\hat f(x) = \sum_{b = 1}^B \lambda \hat f^b(x)\)</span></p></li>
<li><p>boosting学习缓慢，一般学习较慢的学习效果更好</p></li>
<li><p>三个参数：树个数B（交叉检验），收缩因子<span class="math inline">\(\lambda\)</span>（控制学习速率），树节点数（一般为1，为交互作用深度，控制涉及变量）</p></li>
<li><p>深度d为1时是加性模型</p></li>
<li><p>随机森林与Boosting产生的模型都不好解释</p></li>
<li><p>迭代分割变量</p></li>
<li><p>在最大化预测时分割</p></li>
<li><p>评估分支的同质性</p></li>
<li><p>多个树的预测更好</p>
<ul>
<li>优点 容易解释应用 可用在神经网络上</li>
<li>缺点 不容易交叉验证 不确定性不宜估计 结果可能变化
-算法</li>
<li>先在一个组里用所有的变量计算</li>
<li>寻找最容易分离结果的变量</li>
<li>把数据按照该变量节点分为两组</li>
<li>在每一个组中寻找最好的分离变量</li>
<li>迭代直到过程结束<br />
</li>
<li>节点纯度用 Gini 系数或 交叉墒来衡量</li>
</ul></li>
<li><p><code>rattle</code> 包的 <code>fancyRpartPlot</code> 出图漂亮</p></li>
<li><p>可用来处理非线性模型与变量选择</p></li>
<li><p>弱预测变量加权后构建强预测变量</p></li>
<li><p>从一组预测变量开始</p></li>
<li><p>添加有惩罚项的预测变量来训练模型</p></li>
<li><p>以降低训练集误差为目的</p></li>
<li><p>通用方法</p></li>
</ul>
</div>
</div>
<div id="支持向量机" class="section level2 hasAnchor" number="8.21">
<h2><span class="header-section-number">8.21</span> 支持向量机<a href="mlsl.html#支持向量机" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="最大边界分类器" class="section level3 hasAnchor" number="8.21.1">
<h3><span class="header-section-number">8.21.1</span> 最大边界分类器<a href="mlsl.html#最大边界分类器" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="超平面" class="section level4 hasAnchor" number="8.21.1.1">
<h4><span class="header-section-number">8.21.1.1</span> 超平面<a href="mlsl.html#超平面" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>p维空间里(p-1)维子空间</li>
<li><span class="math inline">\(\beta_0 + \beta_1 X_1 + \beta_2 X_2 + ... + \beta_p X_p = 0\)</span> 定义一个p维超平面，X落在超平面上</li>
<li>p维空间中点X不在超平面上就在其两侧</li>
</ul>
</div>
<div id="超平面分类" class="section level4 hasAnchor" number="8.21.1.2">
<h4><span class="header-section-number">8.21.1.2</span> 超平面分类<a href="mlsl.html#超平面分类" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>n*p矩阵X分为两类Y-1或1</li>
<li>代入超平面大于0为1，小于0为-1，有<span class="math inline">\(Y*\beta*X &gt; 0\)</span> 表示分类正确</li>
<li>构建训练函数<span class="math inline">\(f(x^*) = \beta_0 + \beta_1 X_1^* + \beta_2 X_2^* + ... + \beta_p X_p^*\)</span> 正数表示为1，负数为-1，距离0越远表示距离超平面越远，越近表示分类越不确定，判定边界为线性</li>
</ul>
</div>
<div id="最大边界分类器-1" class="section level4 hasAnchor" number="8.21.1.3">
<h4><span class="header-section-number">8.21.1.3</span> 最大边界分类器<a href="mlsl.html#最大边界分类器-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>最大边界超平面：距离边界最近的距离的所有超平面中距离边界点最远的那个超平面</li>
<li>分类良好但容易在p大时过拟合</li>
<li>形成最大边界分类器所需要的边界点为支持向量，用以支持最大边界超平面</li>
<li><span class="math inline">\(f(x^*)*y_i\)</span>在系数平方和为1时为点到平面的垂直距离，最小化后最大化这个距离是求最大边界超平面的关键</li>
</ul>
</div>
</div>
<div id="支持向量分类器" class="section level3 hasAnchor" number="8.21.2">
<h3><span class="header-section-number">8.21.2</span> 支持向量分类器<a href="mlsl.html#支持向量分类器" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>有些情况不存在超平面，需要求一个软边界来适配最多的分类，这就是支持向量分类器</li>
<li>因为是软边界所以允许在超平面或边界一边出现误判</li>
<li>计算上还是为最小化最大化距离，但分类上距离要乘以<span class="math inline">\(1 - \epsilon_i\)</span>项，也就是松弛变量</li>
<li>松弛变量大于0表示边界误判，大于1表示超平面误判，总和为C，表示边界的容忍度，越大分类越模糊</li>
<li>C可通过交叉检验获得，控制bias-variance权衡</li>
<li>只有边界内观察点影响超平面的选择，这些点为支持向量，是形成模型的关键</li>
<li>与LDA不同，使用部分数据，与logistic回归类似</li>
</ul>
</div>
<div id="支持向量机原理" class="section level3 hasAnchor" number="8.21.3">
<h3><span class="header-section-number">8.21.3</span> 支持向量机原理<a href="mlsl.html#支持向量机原理" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>非线性条件下可以考虑将超平面理解为非线性超平面，提高样本维度换取分类效果</li>
<li>加入多项式等非线性描述后计算量不可控</li>
<li>支持向量机通过核来控制非线性边界</li>
<li>通过样本内积来解决支持向量分类问题</li>
<li>线性支持向量分类器<span class="math inline">\(f(x) = \beta_0 + \sum_{i = 1}^{n} \alpha_i &lt; x,x_i &gt;\)</span> 只有支持向量在解中非0，现在只需要支持向量的内积就可以求解</li>
<li>内积可以推广为核函数，核函数可以采用非线性模式</li>
<li><span class="math inline">\(f(x) = \beta_0 + \sum_{i = 1}^{n} \alpha_i K( x,x_i )\)</span> 径向基核函数较为常用</li>
<li>使用内积的核函数计算上简单且等价与高维空间超平面分类</li>
</ul>
<div id="多于二分类" class="section level4 hasAnchor" number="8.21.3.1">
<h4><span class="header-section-number">8.21.3.1</span> 多于二分类<a href="mlsl.html#多于二分类" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>一对一分类：对比<span class="math inline">\(K \choose 2\)</span>个分类器在检验集中的效果，通过计数来选择分类结果</li>
<li>一对多分类：对比K个与剩下的K-1个分类，分类结果最远的认为属于那个分类</li>
</ul>
</div>
</div>
<div id="svm与logistic回归关系" class="section level3 hasAnchor" number="8.21.4">
<h3><span class="header-section-number">8.21.4</span> svm与logistic回归关系<a href="mlsl.html#svm与logistic回归关系" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>中枢损失，对关键点敏感</li>
<li>传统方法也可以借鉴核函数观点视同</li>
<li>支持向量无法提供参数概率信息，采用核函数的logistic回归可以，计算量大</li>
<li>分类距离较远，支持向量机会比logistic回归好一点</li>
<li>支持向量机是计算机背景，logistic回归是概率背景</li>
</ul>
</div>
</div>
<div id="无监督学习" class="section level2 hasAnchor" number="8.22">
<h2><span class="header-section-number">8.22</span> 无监督学习<a href="mlsl.html#无监督学习" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="主成分分析" class="section level3 hasAnchor" number="8.22.1">
<h3><span class="header-section-number">8.22.1</span> 主成分分析<a href="mlsl.html#主成分分析" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>用较少的变量代表较多的变量，方便可视化与理解数据</li>
<li>第一主成分<span class="math inline">\(Z_1 = \phi_{11} X_1 + \phi_{21}X_2 + ... + \phi_{p1} X_p\)</span> 方差最大， 正则化后有<span class="math inline">\(\sum_{j = 1}^p \phi_{j1}^2 = 1\)</span>，则<span class="math inline">\(\phi\)</span>为变量在第一主成分上的载荷</li>
<li>求解上第一主成分最大化<span class="math inline">\(\frac{1}{n} \sum_{i = 1}^{n} z_{i1}^2\)</span> 求解载荷值，<span class="math inline">\(z_{ni}\)</span>是第一个样本在第一个主成分上的得分</li>
<li>载荷表示变量重要程度，得分表示样本重要程度</li>
<li>第二主成分与第一主成分正交求解</li>
<li>biplot 同时表示载荷与得分，载荷向量接近表示有相关性，方向不一表示相关性弱，变量在主成分得分差异表示其状态</li>
<li>第一个主成分表示在p维空间里距离n个观察最近的超平面，因此具备代表性</li>
<li>取M个主成分可代表所有数据<span class="math inline">\(x_{ij} \approx \sum_{m = 1}^M z_{im} \phi_{jm}\)</span></li>
<li>变量单位要统一，已经统一就不要标准化了</li>
<li>主成分是唯一的，符号可能有变化，载荷与得分值也唯一</li>
<li>主成分的重要性通过方差解释比例(PVE)来衡量，用碎石图来可视化<span class="math display">\[\frac{\sum_{i = 1}^n (\sum_{j =1}^p \phi_{jm} x_{ij})^2}{\sum_{j =1}^p x_{ij}^2}\]</span></li>
<li>寻找碎石图的肘部来确定选取主成分的个数，方法不固定</li>
<li>可用来进行M小于p的主成分回归</li>
<li><a href="https://github.com/j2kun/svd">SVD 算法</a></li>
</ul>
</div>
<div id="聚类方法" class="section level3 hasAnchor" number="8.22.2">
<h3><span class="header-section-number">8.22.2</span> 聚类方法<a href="mlsl.html#聚类方法" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>寻找子分类或簇的方法，从异质性寻找同质性</li>
</ul>
<div id="k均值聚类" class="section level4 hasAnchor" number="8.22.2.1">
<h4><span class="header-section-number">8.22.2.1</span> k均值聚类<a href="mlsl.html#k均值聚类" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>子类中方差小，子类间方差大</li>
<li>事先指定子类个数</li>
<li>最小化所有K个平均欧式距离<span class="math inline">\(W(C_k) = \frac{1}{|C_k|} \sum_{i,i&#39; \in C_k} \sum_{j = 1}^{p} (x_{ij} - x_{i&#39;j})^2\)</span></li>
<li>先对所有样本随机分类，然后每种分类取中心，选取里中心距离最近的点重新分类，重新计算中心，迭代得到聚类结果</li>
</ul>
</div>
<div id="分层聚类-1" class="section level4 hasAnchor" number="8.22.2.2">
<h4><span class="header-section-number">8.22.2.2</span> 分层聚类<a href="mlsl.html#分层聚类-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>不需要指定先前聚类数，形成冰柱图</li>
<li>冰柱图要垂直分层解释，水平解释容易出现误导- 修剪冰柱图可给出聚类数</li>
<li>计算所有样本间距离，越相近就融合为一类，重新计算距离，反复这一过程</li>
<li>计算两者间相似度是很关键的，不同场景应用不同算法</li>
<li>变量的标准化处理上也很重要，考虑实际场景</li>
</ul>
</div>
</div>
</div>
<div id="人工神经网络" class="section level2 hasAnchor" number="8.23">
<h2><span class="header-section-number">8.23</span> 人工神经网络<a href="mlsl.html#人工神经网络" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">RNN神经网络算法</a></li>
<li><a href="http://livefreeordichotomize.com/2017/11/08/lstm-neural-nets-as-told-by-baseball/">LSTM神经网络算法</a></li>
<li><a href="https://rstd.io/ml-with-tensorflow-and-r/">tensorflow keras与深度学习</a></li>
<li><a href="http://blog.fastforwardlabs.com/2017/03/09/fairml-auditing-black-box-predictive-models.html">通过正交变量监督黑箱模型的敏感度</a></li>
</ul>
</div>
<div id="模型联合" class="section level2 hasAnchor" number="8.24">
<h2><span class="header-section-number">8.24</span> 模型联合<a href="mlsl.html#模型联合" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>通过平均与投票结合模型</li>
<li>联合分类器提高准确率</li>
<li><code>caretEnsemble</code> 包</li>
<li>案例 广义加性模型</li>
</ul>
<pre><code>library(ISLR); data(Wage); library(ggplot2); library(caret);
Wage &lt;- subset(Wage,select=-c(logwage))
# Create a building data set and validation set
inBuild &lt;- createDataPartition(y=Wage$wage,p=0.7, list=FALSE)
validation &lt;- Wage[-inBuild,]; buildData &lt;- Wage[inBuild,]
inTrain &lt;- createDataPartition(y=buildData$wage,p=0.7, list=FALSE)
training &lt;- buildData[inTrain,]; testing &lt;- buildData[-inTrain,]
mod1 &lt;- train(wage ~.,method=&quot;glm&quot;,data=training)
mod2 &lt;- train(wage ~.,method=&quot;rf&quot;,data=training,trControl = trainControl(method=&quot;cv&quot;),number=3)
pred1 &lt;- predict(mod1,testing); pred2 &lt;- predict(mod2,testing)
qplot(pred1,pred2,colour=wage,data=testing)
predDF &lt;- data.frame(pred1,pred2,wage=testing$wage)
combModFit &lt;- train(wage ~.,method=&quot;gam&quot;,data=predDF)
combPred &lt;- predict(combModFit,predDF)
sqrt(sum((pred1-testing$wage)^2))
sqrt(sum((pred2-testing$wage)^2))
sqrt(sum((combPred-testing$wage)^2))</code></pre>
</div>
<div id="无监督预测" class="section level2 hasAnchor" number="8.25">
<h2><span class="header-section-number">8.25</span> 无监督预测<a href="mlsl.html#无监督预测" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>先聚类 后预测</li>
<li><code>clue</code> 包 <code>cl_predict</code> 函数</li>
<li>推荐系统</li>
</ul>
</div>
<div id="模型预测" class="section level2 hasAnchor" number="8.26">
<h2><span class="header-section-number">8.26</span> 模型预测<a href="mlsl.html#模型预测" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li>时序数据 包含趋势 季节变化 循环
<ul>
<li>效应分解 <code>decompose</code></li>
<li><code>window</code> 窗口</li>
<li><code>ma</code> 平滑</li>
<li><code>ets</code> 指数平滑</li>
<li><code>forecast</code> 预测</li>
</ul></li>
<li>空间数据同样有这种问题 临近依赖 地域效应</li>
<li><code>quantmod</code> 包 或 <code>quandl</code> 包处理金融数据</li>
<li>外推要谨慎</li>
</ul>
</div>
<div id="模型可视化" class="section level2 hasAnchor" number="8.27">
<h2><span class="header-section-number">8.27</span> 模型可视化<a href="mlsl.html#模型可视化" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><a href="http://mfviz.com/hierarchical-models/">统计模型可视化</a></li>
</ul>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="opt.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="product.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": true,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/yufree/datadown/edit/master/08-jiqixuexi.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["datadown.pdf", "datadown.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
