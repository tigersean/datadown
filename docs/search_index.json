[["index.html", "数据分析残卷 序", " 数据分析残卷 于淼 2022-07-09 序 学习都是从模仿开始的，而模仿则意味着不加区别的接受，若是混口饭吃，自然也就够了，但模仿多了便能看到这知识表象下的东西。如果还能提炼一下，变成了自己的经验，各种经验互相联系影响，便有了理论。所以学习大都从知识点开始，而以形成一家之言为终，倘若这一家之言可以得到别人的认可，知识就开始传承了。且不论有多少东西会被反复发现发明出来，但是世界在某种程度上是可知的便是智慧生物生存的福利。 就数据分析而言，我自学过很多教材，可以说不同门派间手段差异非常大，但总又妄想一统江湖，所以便有了这份笔记来整合。不论最终的完成度如何，这都只会是一本残卷，因为这世界总有未知，也因此总有希望。 本书以bookdown写作，感谢相关工具开发者的努力，站在前人肩上看世界确实视角要开阔。 "],["intro.html", "第1章 导论 1.1 数据科学 1.2 基本问题 1.3 工作流程 1.4 概率与分布 1.5 统计量 1.6 统计推断 1.7 统计模型 1.8 其他主题 1.9 应用 1.10 链接", " 第1章 导论 1.1 数据科学 核心：数据处理 研究对象：实际问题（跨学科） 方法：统计学 计算机科学 专业领域 数据科学家： 统计学水平高的程序员 编程水平高的统计学家 学术好奇心 沟通交流能力 产品经理 数据次于问题 大数据依赖科学而不是数据 实验设计 重视可重复性随机与分组 预测与推断不同 不要选数据 1.2 基本问题 描述分析：对数据进行描述但不解释 探索分析：寻找未知的变量间关系 （相关不代表因果） 推断分析：用小样本推断总体 统计模型的目标 强依赖采样过程 预测分析：用一组变量预测另一变量 不一定有因果关系 因果分析：改变一个变量引发另一个变量变化的分析 随机实验 平均效果 机理分析：对个体改变一个变量所导致另一个变量的精确变化 公式模拟与参数拟合 1.3 工作流程 数据收集 数据整理 数据探索 数据建模 模型评价 结果交流 1.4 概率与分布 概率与分布是统计的基本世界观，当我们用概率来理解世界时，所有事物便不仅仅是此时此刻的事，而是可能性中的一种。这种全局观好比从上帝视角开启有限平行宇宙，即使你知道每种状态及其概率，最后结果也无法预判。 从可能性到独立事件概率计算 从联合概率到条件概率到贝叶斯公式 事件的发生空间到分布 多事件发生概率比较到标准化分布-z值 正态分布评价拟合 贝努利分布 二项分布，固定总数，成功概率，二项分布可用正态分布近似求值，也可用二项分布取精确值，求区间概率要扩大 负二项分布，固定成功次数概率 几何分布，最后一次成功概率 超几何分布，不放回抽样，成功概率 泊松分布，实验次数多，概率小，发生概率，泊松过程 1.5 统计量 统计量是对样本性质的一种描述或简化，用来提取设计者所关注的信号并尽可能排除掉噪音。 总体到样本 多个事件的描述到众数 中位数 再到期望 描述多个事件的变动到方差 取样方法：随机，分层，分类 样本独立性:简单随机取样，样本数少于10%的总体可认为独立样本 估计的偏差为标准误 点估计到区间估计 标准误只针对样本均值，理解为样本均值的估计标准差 置信区间为对所有样本进行区间估计，95%的区间包含真值，是对总体参数的估计，近似认为样本符合某分布 中心极限法则：样本均值的分布为正态分布 1.6 统计推断 统计推断基于构建的统计量来进行决策，这个决策过程涉及空假设、备择假设与p值。 假设检验 不拒绝H0不代表H0是对的，拒绝H0代表HA可能正确，观察数值的区间重叠状况 使用双重否定进行描述 type I 假阳性 type II 假阴性 置信水平反映两种错误的可能性 p值描述某数值在H0（一般为等式）中出现的可能性，通常与置信水平对比，两边与单边 构建符合某分布的统计量进行参数估计，通过标准误计算p值，进行假设检验过程 功效表示HA拒绝H0的可能性，功效高，检验可靠 统计差异显著不代表实际差异显著，甚至没有实际意义 均值比较（连续） 配对数据 均值比较 t分布与自由度及小样本均值的标准误估计 置信区间与p值 样本均值的t检验 多组数据均值的方差分析与F检验 多重比较的假阳性问题 样本数足够可用统计模拟的方法进行检验，数据存在层级结构则不可直接模拟 比例比较（计数） 比例检验，计算基于H0的标准误，计算z值，计算p值，可反推样品量 比例差异检验，H0为比例相等，估计混合概率，计算标准误进行检验 记分检验与Wald检验 优度拟合 分布检验到卡方检验 独立性检验 精确检验 1.7 统计模型 统计模型是基于统计量的对事物的抽象，借助模型可以简化事物的复杂性或从某个角度更好理解事物。 变量关系到线性回归到线性诊断 参数估计到关系解释及误差分析 多元回归 模型选择 方差分析 非线性模型与平滑 logistic模型到广义线性模型 线性混合模型 主成分分析与因子分析 1.8 其他主题 非参数统计 贝叶斯统计 判别分析 岭回归与lasso 广义加性模型 鲁棒模型 决策树到随机森林 人工神经网络 支持向量机 蒙特卡洛分析到统计模拟 网络分析 因果分析 数据库 软件构架 服务器与前端设计 并行与分布式计算 容器化技术 博弈论 1.9 应用 工具 实验设计 模式识别 流行病学 生物信息学 化学信息学 心理学 空间数据分析 时间序列分析与信号处理 量化投资 自然语言处理 1.10 链接 统计问题 R问题 R mailling ist 数据分享 命令行数据科学 最流行的程序包 数据科学资料合集 peerj 实用数据分析技巧特刊 "],["tool.html", "第2章 数据分析工具 2.1 基础知识 2.2 命令行基础 2.3 版本控制 2.4 数据获取 2.5 远程控制 2.6 高级命令 2.7 R 2.8 Python 2.9 Tex", " 第2章 数据分析工具 2.1 基础知识 层次：操作系统 - shell - 终端 - 命令行工具 分类：可执行文件、shell 内置命令、脚本、shell 函数、宏 2.2 命令行基础 name of root is represented by a slash: / home directory is represented by a tilde: ~ pwd print working directory recipe: command -flags arguments clear: clear out the commands in your current CLI window ls lists files and folders in the current directory -a lists hidden and unhidden files and folders al lists details for hidden and unhidden files and folders cd stands for “change directory” cd takes as an argument the directory you want to visit cd with no argument takes you to your home directory cd .. allows you to chnage directory to one level above your current directory mkdir stands for “make directory” touch creates an empty file cp stands for “copy” cp takes as its first argument a file, and as its second argument the path to where you want the file to be copied cp can also be used for copying the contents of directories, but you must use the -r flag rm stands for “remove” use rm to delete entire directories and their contents by using the -r flag mv stands for “move” move files between directories use mv to rename files echo will print whatever arguments you provide date will print today’s date 2.3 版本控制 $ git config --global user.name &quot;Your Name Here&quot; # 输入用户名 $ git config --global user.email &quot;your_email@example.com&quot; # 输入邮箱 $ git config --list # 检查 $ git init # 初始化目录 $ git add . # 添加新文件 $ git add -u # 更新改名或删除的文件 $ git add -A|git add --all # 添加所有改动 $ git commit -m &quot;your message goes here&quot; # 描述并缓存本地工作区改动到上一次commit $ git log # 查看commit记录 用Q退出 $ git status # 查看状态 $ git remote add # 添加服务器端地址 $ git remote -v # 查看远端状态 $ git push # 将本地commit推送到github服务器端 $ git pull|fetch|merge|clone # 本地获取远端repo $ exit # 退出 Git = Local (on your computer); GitHub = Remote (on the web) 2.4 数据获取 复制：cp 或 scp（安全复制） &gt; scp -i mykey.pem ~/Desktop/logs.csv ubuntu@ec2-184-73-72-150.compute-1.amazonaws.com:data 解压：unpack &gt; unpack logs.tar.gz 转化 excel 为csv：in2csv、csvcut、csvlook &gt; in2csv data/imdb-250.xlsx | head | csvcut -c Title,Year,Rating | csvlook 查询关系数据库：sql2csv &gt; sql2csv –db ‘sqlite:///data/iris.db’ –query ‘SELECT * FROM iris’ ‘WHERE sepal_length &gt; 7.5’ 互联网下载：curl -u 登录 -L 链接跳转 -I http头文件 &gt; curl -s http://www.gutenberg.org/cache/epub/76/pg76.txt | head -n 10 &gt; curl -u username:password ftp://host/file &gt; curl -L j.mp/locatbbar API：curlicue 来进行认证 2.5 远程控制 ssh 远程登录22端口 scp 对服务器拷贝 scp -r local/data host:/data/ screen 远程登陆时防止长时间操作断连 c+a d 断开 c+a k 中止 screen -r 续连 df 查看磁盘分区使用状况 df -h du 查看磁盘使用状况 du -h 2.6 高级命令 !! 可重复上次命令 chmod 增加权限 #!/usr/bin/env bash 增加状况说明 NUM_WORDS=“$1” 增加参数 2.7 R 2.7.1 语言导论 R语言是S语言的一种方言 1976年S是John Chambers等在贝尔实验室作为Fortran的扩展库开发出来的 1988年用C语言重写 S3方法 白皮书 1993年StatSci从贝尔实验室获得S语言的独家开发售卖许可 1998年S4方法 绿皮书 之后S语言稳定 获得Association for Computing Machinery’s Software System Award 2004年Insightful（原StatSci）从Lucent收购了S语言 2006年Alcatel收购了Lucent成立Alcatel-Lucent 2008年TIBCO收购Insightful 之前Insightful开发并售卖S-PLUS 1991年Ross Ihaka与Robert GentlemanNew在Zealand开发了R 1993年发布R第一份许可 1995年R作为自由软件发放GUN许可 1996年R邮件列表创立 1997年R Core成立 控制R源码 2000年R version 1.0.0 放出 2013年R version 3.0.2 放出 R由CRAN掌控的base包与其他包组成 其余参考R主页 出色的R包 过时的R包 2.7.2 获得帮助 help() ?command 给出版本号与平台 给一个简短的重现例子 2.7.3 数据类型及基本运算 所有数据都是对象 所有对象都有类型 基本类型包括：字符“” 数字 整数L 复数(Re实部 Im虚部) 逻辑 向量储存同一类型数据 list存储不同类型数据 [[*]]引用相应向量 unlist 可用做紧凑输出 对象可以有属性attributes 对象赋值符号为 &lt;- 赋值同时展示加括号或直接输入对象名 可累加赋值 a &lt;- b &lt;- c #表示注释 不执行 : 用来产生整数序列 也可以用seq生成 向量用c产生 空向量用vector()函数建立 向量中类型不同的对象元素会被强制转换为同一类型 字符优先级最高 其次数字 其次逻辑(0 or 1) 也可以用来串联字符 可使用as.*来强制转化数据类型 对象可以用names命名 变量名开头不能是数字和. 大小写敏感 下划线不要出现在名字里 分割用. 变量名中不能有空格 保留字符 FALSE Inf NA NaN NULL TRUE break else for function if in next repeat while 清空rm(list = ls()) 矩阵 带有dimension属性的向量为矩阵 矩阵的生成次序为upper-left matrix(1:6,nrow=2,ncol=3)表示建一个2行3列矩阵 从1到6 先列后行赋值 可用 byrow = T 来更改 可用c给dim赋值行和列数 这样可把一个向量转为一个矩阵 m&lt;-1:6;dim(m)&lt;-c(2,3) 矩阵可以用rbind或cbind生成 t对矩阵转置 因子变量表示分类数据 用标签名区分 用level来命名排序 默认是字母排序 有些函数对顺序敏感可用 levels = c() 来命名 ( 例如低中高的排序 ) 数字表示 drop = T 表示显示截取数据的水平 nlevels给出个数 NaN表未定义或缺失值 NA表示无意义转换或缺失值 NaN可以是NA反之不可以 NA有数据类型 is.NaN与is.NA 可用来检验 数据框 特殊list 每个元素长度相等 每一列类型相同 矩阵所有数据类型相同 特殊属性row.names 转为矩阵data.matrix 变量名自动转化 可以不同 因子变量保持为字符可以用 I data.frame(x,y,I(c)) 数组 表示更高维度的数据 dim() = c(x,y,z) 三维数组表示一组数 dimnames 给数组命名 数组调用如果只有一行 需要drop = F 否则 不会按照数组分类 ts 产生时间序列对象 .Last.value 引用前一个数值 取整数 用round(x,n) n表示保留几位小数 截取整数 trunc 开平方 sqrt 绝对值 abs 指数函数 exp 自然对数函数 log 以 10 为底的对数函数 log10 三角函数 sin cos tan asin acos atan 常用的逻辑运算符有: 大于 &gt; 小于 &lt; 等于 == 小于或等于 &lt;= 大于或等于 &gt;= 与 &amp; 非 ! 或| 判断向量x中是否与y中元素相等 x %in% y 结果返回逻辑值 sum 求和 prod 求连乘 range 给极值范围 duplicated 给出有重复的值 unique 给出无重复的值 向量操作 union 并集 intersect 交集 setdiff 除了交集的部分 rep 用向量循环生成向量 整型变量后面加上L x&lt;-10L Inf代表1/0 同样1/Inf运算结果为0 2.7.4 环境／文件操作 getwd() setwd() 设置工作目录 ls() 列举环境中bianliang list.files() 或 dir() 列举当前目录下文件 args() 列举函数默认变量 dir.create() 创建文件目录 加上recursive=T可创建多级目录 file.create() 创建文件 file.exists() 检查文件是否存在 file.info() 检查文件信息 file.rename() 文件重命名 file.copy() 文件复制 file.path() 文件路径 多个文件组成多级路径 unlink() 删除文件 2.7.5 下载 设定工作目录与数据存储目录 # if (!file.exists(&quot;data&quot;)) { # dir.create(&quot;data&quot;) # } url下载与时间记录 # fileUrl &lt;- &quot;yoururl&quot; # download.file(fileUrl, destfile = &quot;./data/XXX.csv&quot;, method = &quot;curl&quot;) # list.files(&quot;./data&quot;) # dateDownloaded &lt;- date() 2.7.6 截取数据 可以用[x,y]提取特定数值 [-1,-2]可剔除第一行第二列 [[]]用来从list或者frame里提取元素 类型固定 可提取序列x[[1]][[3]] 可部分匹配 exact=FALSE $用名字提取元素 可部分匹配 提取矩阵时默认只能提取向量 但可以提取1*1矩阵x[1,2,drop=FALSE] 先用is.NA()提取 用!排除 缺失值可用is.element(x,y)来处理很多表示NA值的数字 返回x %in% y的逻辑值 用complete.cases()提取有效数据用[]提取可用数据 head(x,n) n表示从头截取多少行 tail(x,n) n表示从尾截取多少行 subset(x,f) x表示数据 f表示表达式 条件筛选中获得一个变量多个数值的数据使用 [is.element(x,c(' ',' ',' ')),] 或者[x%in%c(' ',' ',' '),] 使用x == c( ' ' , ' ' , ' ' ) 会报错 循环查找三个变量 x!='t' 可能会把空白值输入 应该使用is.element(x,'t') ifelse(con,yes,no) 利用条件筛选 返回yes 或者no 的值 支持正则表达式 增加行直接$ seq产生序列 通过[按行 列或条件截取 which返回行号 排序向量用sort 排序数据框(多向量)用order plyl包排序 library(plyr) arrange(X,var1) arrange(X,desc(var1)) 2.7.7 读取数据 read.table read.csv 读取表格 反之write.table readLines 读取文本行 反之writeLines source 读取R代码 反之dump dget 读取多个R代码 反之dput load 读取保存的工作区 反之save unserialize 读取二进制R对象 反之serialize ?read.table 大数据读取提速 计算内存 comment.char = \"\" 不扫描注释 设定nrows 设定colClasses initial &lt;- read.table(&quot;datatable.txt&quot;, nrows = 100) classes &lt;- sapply(initial, class) tabAll &lt;- read.table(&quot;datatable.txt&quot;, colClasses = classes) 使用connections与file等保存外部文件指向 2.7.7.1 读取本地文件 read.table read.csv 默认sep=\",\", header=TRUE quote 设定引用 na.strings 设定缺失值字符 nrows 设定读取字段 skip 跳过开始行数 2.7.7.2 读取excle文件 xlsx包 library(xlsx) cameraData &lt;- read.xlsx(&quot;./data/cameras.xlsx&quot;,sheetIndex=1,header=TRUE) head(cameraData) # read.xlsx2更快不过选行读取时会不稳定 # 支持底层读取 如字体等 XLConnect包 library(XLConnect) wb &lt;- loadWorkbook(&quot;XLConnectExample1.xlsx&quot;, create = TRUE) createSheet(wb, name = &quot;chickSheet&quot;) writeWorksheet(wb, ChickWeight, sheet = &quot;chickSheet&quot;, startRow = 3, startCol = 4) saveWorkbook(wb) # 支持区域操作 生成报告 图片等 2.7.7.3 读取XML文件 网页常用格式 形式与内容分开 形式包括标签 元素 属性等 XML包 library(XML) fileUrl &lt;- &quot;http://www.w3schools.com/xml/simple.xml&quot; # 读取xml结构 doc &lt;- xmlTreeParse(fileUrl,useInternal=TRUE) # 提取节点 rootNode &lt;- xmlRoot(doc) # 提取根节点名 xmlName(rootNode) # 提取子节点名 names(rootNode) # 提取节点数值 xmlSApply(rootNode,xmlValue) XPath XML的一种查询语法 /node 顶级节点 //node 所有子节点 node[@attr-name] 带属性名的节点 node[@attr-name='bob'] 属性名为bob的节点 # 提取节点下属性名为name的数值 xpathSApply(rootNode,&quot;//name&quot;,xmlValue) 2.7.7.4 读取json文件 js对象符号 结构化 常作为API输出格式 jsonlite包 library(jsonlite) # 读取json文件 jsonData &lt;- fromJSON(&quot;https://api.github.com/users/jtleek/repos&quot;) # 列出文件名 names(jsonData) # 可嵌套截取 jsonData$owner$login # 可将R对象写成json文件 myjson &lt;- toJSON(iris, pretty=TRUE) 2.7.7.5 读取MySQL数据库 网络应用常见数据库软件 一行一记录 数据库表间有index向量 常见命令 指南 RMySQL包 library(RMySQL) # 读取数据库 ucscDb &lt;- dbConnect(MySQL(),user=&quot;genome&quot;, host=&quot;genome-mysql.cse.ucsc.edu&quot;) result &lt;- dbGetQuery(ucscDb,&quot;show databases;&quot;); # 断开链接 dbDisconnect(ucscDb); # 读取指定数据库 hg19 &lt;- dbConnect(MySQL(),user=&quot;genome&quot;, db=&quot;hg19&quot;, host=&quot;genome-mysql.cse.ucsc.edu&quot;) allTables &lt;- dbListTables(hg19) length(allTables) # mysql语句查询 dbGetQuery(hg19, &quot;select count(*) from affyU133Plus2&quot;) # 选择子集 query &lt;- dbSendQuery(hg19, &quot;select * from affyU133Plus2 where misMatches between 1 and 3&quot;) affyMis &lt;- fetch(query); quantile(affyMis$misMatches) 2.7.7.6 读取HDF5数据 分层分组读取大量数据的格式 rhdf5包 library(rhdf5) created = h5createFile(&quot;example.h5&quot;) created = h5createGroup(&quot;example.h5&quot;,&quot;foo&quot;) created = h5createGroup(&quot;example.h5&quot;,&quot;baa&quot;) created = h5createGroup(&quot;example.h5&quot;,&quot;foo/foobaa&quot;) h5ls(&quot;example.h5&quot;) A = matrix(1:10,nr=5,nc=2) h5write(A, &quot;example.h5&quot;,&quot;foo/A&quot;) B = array(seq(0.1,2.0,by=0.1),dim=c(5,2,2)) attr(B, &quot;scale&quot;) &lt;- &quot;liter&quot; h5write(B, &quot;example.h5&quot;,&quot;foo/foobaa/B&quot;) h5ls(&quot;example.h5&quot;) df = data.frame(1L:5L,seq(0,1,length.out=5), c(&quot;ab&quot;,&quot;cde&quot;,&quot;fghi&quot;,&quot;a&quot;,&quot;s&quot;), stringsAsFactors=FALSE) h5write(df, &quot;example.h5&quot;,&quot;df&quot;) h5ls(&quot;example.h5&quot;) readA = h5read(&quot;example.h5&quot;,&quot;foo/A&quot;) readB = h5read(&quot;example.h5&quot;,&quot;foo/foobaa/B&quot;) readdf= h5read(&quot;example.h5&quot;,&quot;df&quot;) 2.7.7.7 读取网页数据 网页抓取HTML数据 读完了一定关链接 httr包 con = url(&quot;http://scholar.google.com/citations?user=HI-I6C0AAAAJ&amp;hl=en&quot;) htmlCode = readLines(con) close(con) htmlCode library(XML) url &lt;- &quot;http://scholar.google.com/citations?user=HI-I6C0AAAAJ&amp;hl=en&quot; html &lt;- htmlTreeParse(url, useInternalNodes=T) xpathSApply(html, &quot;//title&quot;, xmlValue) library(httr) html2 = GET(url) content2 = content(html2,as=&quot;text&quot;) parsedHtml = htmlParse(content2,asText=TRUE) xpathSApply(parsedHtml, &quot;//title&quot;, xmlValue) GET(&quot;http://httpbin.org/basic-auth/user/passwd&quot;) GET(&quot;http://httpbin.org/basic-auth/user/passwd&quot;, authenticate(&quot;user&quot;,&quot;passwd&quot;)) google = handle(&quot;http://google.com&quot;) pg1 = GET(handle=google,path=&quot;/&quot;) pg2 = GET(handle=google,path=&quot;search&quot;) 2.7.7.8 读取API 通过接口授权后调用数据 httr包 myapp = oauth_app(&quot;twitter&quot;, key=&quot;yourConsumerKeyHere&quot;,secret=&quot;yourConsumerSecretHere&quot;) sig = sign_oauth1.0(myapp, token = &quot;yourTokenHere&quot;, token_secret = &quot;yourTokenSecretHere&quot;) homeTL = GET(&quot;https://api.twitter.com/1.1/statuses/home_timeline.json&quot;, sig) json1 = content(homeTL) json2 = jsonlite::fromJSON(toJSON(json1)) 2.7.7.9 读取其他资源 图片 jpeg readbitmap png EBImage (Bioconductor) GIS rdgal rgeos raster 声音 tuneR seewave 2.7.8 数据总结 head tail查看数据 summary str总结数据 quantile 按分位数总结向量 table 按向量元素频数总结 sum(is.na(data)) any(is.na(data)) all(data$x &gt; 0) 异常值总结 colSums(is.na(data)) 行列求和 table(data$x %in% c(\"21212\"))特定数值计数总结 xtabs ftable 创建列联表 print(object.size(fakeData),units=\"Mb\") 现实数据大小 cut 通过设置breaks产生分类变量 Hmisc包 library(Hmisc) data$zipGroups = cut2(data$zipCode,g=4) table(data$zipGroups) library(plyr) # mutate进行数据替换或生成 data2 = mutate(data,zipGroups=cut2(zipCode,g=4)) table(data2$zipGroups) 2.7.9 数据整理 Raw data -&gt; Processing script -&gt; tidy data 前期需求 原始数据 干净数据 code book 详尽的处理步骤记录 原始数据要求 未经处理 未经修改 未经去除异常值 未经总结 干净数据 每个变量一列 同一变量不同样本不在一行 一种变量一个表 多张表要有一列可以相互链接 有表头 变量名要有意义 一个文件一张表 code book 变量信息 总结方式 实验设计 文本文件 包含研究设计与变量信息的章节 处理步骤记录 脚本文件 输入为原始数据 输出为处理过数据 脚本中无特定参数 每一列一个变量 每一行一个样本 每个文件存储一类样本 melt进行数据融合 reshape2包 dcast分组汇总数据框 acast分组汇总向量数组 arrange指定变量名排序 merge按照指定向量合并数据 plyr包的join函数也可实现合并 2.7.10 数据操作data.table包 基本兼容data.frame 速度更快 通过key可指定因子变量并快速提取分组的行 可在第二个参数是R表达式 DT[,list(mean(x),sum(z))] DT[,table(y)] 可用:生成新变量 进行简单计算 DT[,w:=z^2] DT[,m:= {tmp &lt;- (x+z); log2(tmp+5)}] 进行数据条件截取 DT[,a:=x&gt;0] DT[,b:= mean(x+w),by=a] 进行计数 DT &lt;- data.table(x=sample(letters[1:3], 1E5, TRUE)) DT[, .N, by=x] 2.7.11 文本处理 处理大小写tolower toupper 处理变量名strsplit firstElement &lt;- function(x){x[1]} sapply(splitNames,firstElement) 字符替换sub gsub 寻找变量grep(返回行号) grepl(返回逻辑值) stringr包 stringr paste0 不带空格 str_trim 去除空格 命名原则 变量名小写 描述性 无重复 变量名不要符号分割 Names of variables should be 正则表达式 文字处理格式 ^ 匹配开头 $ 匹配结尾 [] 匹配大小写 ^在开头表示非 . 匹配任意字符 | 匹配或 () 匹配与 ? 匹配可选择 * 匹配任意 + 匹配至少一个 {} 匹配其中最小最大 一个值表示精确匹配 m,表示至少m次匹配 \\1 匹配前面指代 2.7.12 控制结构 if else 条件 if(&lt;condition&gt;) { ## do something } else { ## do something else } if(&lt;condition1&gt;) { ## do something } else if(&lt;condition2&gt;) { ## do something different } else { ## do something different } `for‵ 执行固定次数的循环 嵌套不超过2层 for(i in 1:10) { print(i) } while 条件为真执行循环 条件从左到右执行 count &lt;- 0 while(count &lt; 10) { print(count) count &lt;- count + 1 } repeat 执行无限循环 配合break 中断并跳出循环 next 跳出当前循环继续执行 for(i in 1:100) { if(i &lt;= 20) { ## Skip the first 20 iterations next } ## Do something here } return 退出函数 避免使用无限循环 可用apply替代 2.7.13 函数 f &lt;- function(&lt;arguments&gt;) { ## Do something interesting } 函数中参数默认值可用formals()显示 参数匹配 先检查命名参数 然后检查部分匹配 最后检查位置匹配 定义函数时可以定义默认值或者设为NULL 懒惰执行：只执行需要执行的语句 ... 向其他函数传参 之后参数不可部分匹配 2.7.14 编程标准 使用文本文档与文本编辑器 使用缩进 限制代码行宽 80为宜 限制单个函数长度 2.7.15 范围规则 自由变量采用静态搜索 环境是由数值符号对组成 每个环境都有母环境 函数与环境组成环境闭包 首先从函数环境中寻找变量 之后搜索母环境 最高层为工作区 之后按搜寻列表从扩展包中寻找变量 最后为空环境 之后报错 可以函数内定义函数 S都存在工作区 函数定义一致 R存在内存 可根据需要调用函数环境 2.7.16 向量化操作 向量操作针对元素 矩阵操作也针对元素 %*% 表示矩阵操作 2.7.17 绘图系统 2.7.17.1 基础绘图 艺术家绘画模式 graphics 包括基础包的绘图函数如plot, hist, boxplot grDevices 包括执行调用绘图设备函数如X11, PDF, PostScript, PNG 叠加函数 高度自由度 初始化新图 然后标注 以下命令熟记 pch: the plotting symbol (default is open circle) lty: the line type (default is solid line), can be dashed, dotted, etc. lwd: the line width, specified as an integer multiple col: the plotting color, specified as a number, string, or hex code; the colors() function gives you a vector of colors by name xlab: character string for the x-axis label ylab: character string for the y-axis label par():查找做图的画布参数 具体如下 las: the orientation of the axis labels on the plot bg: the background color mar: the margin size oma: the outer margin size (default is 0 for all sides) mfrow: number of plots per row, column (plots are filled row-wise) mfcol: number of plots per row, column (plots are filled column-wise) plot: make a scatterplot, or other type of plot depending on the class of the object being plotted lines: add lines to a plot, given a vector x values and a corresponding vector of y values (or a 2-column matrix); this function just connects the dots points: add points to a plot text: add text labels to a plot using specified x, y coordinates title: add annotations to x, y axis labels, title, subtitle, outer margin mtext: add arbitrary text to the margins (inner or outer) of the plot axis: adding axis ticks/labels 图形设备 图像一定要有设备 屏幕设备 Mac quartz() windows windows() Unix/linux x11() 先调用后用dev.off()关闭设备 矢量图设备 保真放大 元素过多体积庞大 pdf() svg() winmetafile() postscript() 位图设备 放大失真 基于像素 png() jpeg() tiff() bmp() 当前设备dev.cur() 设置设备dev.set(&lt;integer&gt;) 设备转移dev.copy dev.copy2pdf 2.7.17.2 lattice 一站式解决 lattice 包括框架图函数如xyplot, bwplot, levelplot grid 包括独立于基础绘图系统的网格绘图系统 一个函数解决问题 默认自定义空间少 返回trellis类型对象 可单独存储 界面调整使用panel选项 以下为常见函数 xyplot: this is the main function for creating scatterplots bwplot: box-and-whiskers plots (“boxplots”) histogram: histograms stripplot: like a boxplot but with actual points dotplot: plot dots on “violin strings” splom: scatterplot matrix; like pairs in base plotting system levelplot, contourplot: for plotting “image” data 基本格式 xyplot(y ~ x | f * g, data) 可同时展示分组信息及交互作用 2.7.17.3 ggplot2 基于图形语法理念 图形属性映射数据问题 自动处理界面 允许后期添加 结合base与lattice 默认友好 基础绘图qplot() ggplot() 通过叠加元素出图 细节调整xlab(), ylab(), labs(), ggtitle() 主题调整theme() 做图需求 数据框 data.frame 属性映射 asethetic mappling 几何对象 geoms 条件 facets 统计转换 stats 范围量表 scales 坐标轴系统 coordinate system 2.7.17.4 数学绘图 Tex语法 使用expression() ?plotmath 2.7.17.5 色彩管理 colorRamp 返回01间数值 表示颜色过度 colorRampPalette 返回8位颜色代码调色盘 colors 返回可用颜色 RColorBrewer包 含有预先配色信息 序列 无序 两级 rgb产生三原色颜色 alpha 控制透明度 绘图时用col调用调色盘颜色 pal &lt;- colorRamp(c(&quot;red&quot;, &quot;blue&quot;)) pal(0) ## [,1] [,2] [,3] ## [1,] 255 0 0 pal(1) ## [,1] [,2] [,3] ## [1,] 0 0 255 pal(0.5) ## [,1] [,2] [,3] ## [1,] 128 0 128 ##### pal &lt;- colorRampPalette(c(&quot;red&quot;, &quot;yellow&quot;)) pal(2) ## [1] &quot;#FF0000&quot; &quot;#FFFF00&quot; pal(10) ## [1] &quot;#FF0000&quot; &quot;#FF1C00&quot; &quot;#FF3800&quot; &quot;#FF5500&quot; &quot;#FF7100&quot; &quot;#FF8D00&quot; &quot;#FFAA00&quot; ## [8] &quot;#FFC600&quot; &quot;#FFE200&quot; &quot;#FFFF00&quot; ##### library(RColorBrewer) cols &lt;- brewer.pal(3, &quot;BuGn&quot;) 2.7.18 日期与时间 日期以data类型存储 时间以POSIXct 或 POSIXlt 类型存储 数字上是从1970-01-01以来的天数或秒数 POSIXct以整数存储时间 POSIXlt以年月日时分秒等信息存储时间 strptime as.Date as.POSIXlt as.POSIXct用来更改字符为时间 formate处理日期格式 %d 日 %a 周缩写 %A 周 %m 月 %b 月缩写 %B 月全名 %y 2位年 %Y 4位年 weekdays 显示星期 months 显示月份 julian 显示70年以来的日期 lubridate包 ymd mdy dmy ymd_hms Sys.timezone 2.7.19 循环 2.7.19.1 lapply 对列表对象元素应用函数 可配合匿名函数使用 x &lt;- list(a = 1:5, b = rnorm(10)) lapply(x, mean) ## $a ## [1] 3 ## ## $b ## [1] 0.082 x &lt;- 1:4 lapply(x, runif, min = 0, max = 10) ## [[1]] ## [1] 1.34 ## ## [[2]] ## [1] 6.22 7.50 ## ## [[3]] ## [1] 6.53 2.18 6.25 ## ## [[4]] ## [1] 0.657 5.213 0.635 9.137 x &lt;- list(a = matrix(1:4, 2, 2), b = matrix(1:6, 3, 2)) lapply(x, function(elt) elt[,1]) ## $a ## [1] 1 2 ## ## $b ## [1] 1 2 3 2.7.19.2 sapply lapply的精简版 如果结果是单元素列表 转化为向量 如果结果是等长向量 转化为矩阵 否则输出依旧为列表 x &lt;- list(a = 1:4, b = rnorm(10), c = rnorm(20, 1), d = rnorm(100, 5)) sapply(x, mean) ## a b c d ## 2.500 0.133 0.863 4.963 2.7.19.3 vapply 类似lapply可用更复杂函数 返回矩阵 2.7.19.4 replicate 用于将函数循环使用 如返回随机矩阵 2.7.19.5 rapply 用how来调整输出方法 如选取某列表中类型数据进行迭代 2.7.19.6 apply 数组边际函数 常用于矩阵的行列处理 行为1，列为2 可用rowSums rowMeans colSums colMeans 来替代 大数据量更快 x &lt;- matrix(rnorm(50), 10, 5) apply(x, 1, quantile, probs = c(0.25, 0.75)) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] ## 25% -0.732 -0.366 -1.078 -0.592 -0.252 -0.515 -1.112 -0.279 -0.362 -0.551 ## 75% -0.247 0.535 0.353 0.399 1.335 0.592 -0.617 0.640 0.171 0.318 a &lt;- array(rnorm(2 * 2 * 10), c(2, 2, 10)) apply(a, c(1, 2), mean) ## [,1] [,2] ## [1,] 0.0731 -0.314 ## [2,] -0.5797 0.202 2.7.19.7 tapply 对数据子集（因子变量区分）向量应用函数 x &lt;- c(rnorm(10), runif(10), rnorm(10, 1)) f &lt;- gl(3, 10) tapply(x, f, mean) ## 1 2 3 ## 0.886 0.469 0.989 2.7.19.8 by 对数据按照因子变量应用函数 类似tapply 按照某个分类变量a分类求均值 by(x[,-a],a,mean) 2.7.19.9 split 将数据按因子分割为列表 常配合lapply使用 类似tapply 可用来生成分组 用drop来删除空分组 x &lt;- c(rnorm(10), runif(10), rnorm(10, 1)) f &lt;- gl(3, 10) lapply(split(x, f), mean) ## $`1` ## [1] -0.122 ## ## $`2` ## [1] 0.382 ## ## $`3` ## [1] 1.61 x &lt;- rnorm(10) f1 &lt;- gl(2, 5) f2 &lt;- gl(5, 2) str(split(x, list(f1, f2), drop = TRUE)) ## List of 6 ## $ 1.1: num [1:2] 1.68 -1.56 ## $ 1.2: num [1:2] 1.023 0.372 ## $ 1.3: num -0.131 ## $ 2.3: num 1.69 ## $ 2.4: num [1:2] 0.998 0.501 ## $ 2.5: num [1:2] -0.628 -1.332 2.7.19.10 mapply 多变量版apply 从多个参数范围取值 并用函数得到结果 noise &lt;- function(n, mean, sd) { rnorm(n, mean, sd) } mapply(noise, 1:5, 1:5, 2) ## [[1]] ## [1] 0.803 ## ## [[2]] ## [1] -2.29 2.69 ## ## [[3]] ## [1] 3.21 4.85 1.47 ## ## [[4]] ## [1] 4.37 2.19 4.64 6.99 ## ## [[5]] ## [1] 3.09 1.48 4.56 2.24 5.08 #等同于如下循环 #list(noise(1, 1, 2), noise(2, 2, 2), # noise(3, 3, 2), noise(4, 4, 2), # noise(5, 5, 2)) 2.7.19.11 eapply 对环境变量应用函数 用于包 2.7.20 模拟 在某分布下产生随机数 d 分布概率密度 r 分布随机数 p 分布累计概率 q 分布分位数 dnorm(x, mean = 0, sd = 1, log = FALSE) pnorm(q, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) qnorm(p, mean = 0, sd = 1, lower.tail = TRUE, log.p = FALSE) rnorm(n, mean = 0, sd = 1) set.seed保证重现性 sample对数据采样 2.7.21 调试 三种提示 message warning error 只有error致命 关注重现性 调试工具 traceback debug browser trace recover 三思而行 2.7.22 分析代码 先设计 后优化 system.time 计算代码运行时间 返回对象类型proc_time ‵user time` 执行代码用时 system time CPU时间 elapsed time 实际用时 在多核或并行条件下实际用时可以短于执行代码用时 明确知道耗时较长的函数时使用 Rprof R代码要支持分析函数 summaryRprof可使结果易读 不要与system.time混用 0.02s记录一次执行函数 by.total 记录单个函数用时 by.self 记录函数执行时被调用函数用时 2.7.23 包开发 DESCRIPTION 指明包内容 Package 包名字 Title 全名 Description 一句话描述 Version 版本号 Author 作者 Maintainer 维护者 License 许可协议 Depends 依赖 Suggests 建议 Date 发布日期 YYYY-MM-DD 格式 URL 项目主页 R 源码 Documentation 文档 Rd文件 NAMESPACE 关键词 输入输出的函数及类型 R CMD build/check newpackage 构建 检查包 roxygen2 源文件注释文档 2.7.24 方法与类型 R 面向对象编程 对象用setClass指定类型 用setMethod指定处理类型的方法 对象一般指新的数据类型 S3函数对象不算严格 generic处理对象 开放 没有指定类型就用通用方法 S4函数对象定义严格 只处理指定类型对象 不可直接调用方法 针对性强 stats4 有很多针对性的极大似然估计的对象定义与方法 2.7.25 并行计算 任务切分后多线程/多核/多机同时执行，然后汇总，需要调用配置管理 并行计算的优势在于利用独立计算单元同时计算汇总 单机可以多核或多进程，例如OpenMP 也可以GPU加速，例如CUDA 集群可在应用层定义后交给后端做分发例如snow 有些函数已经进行了并行化优化可直接调用，有些需要声明用法才能调用 多机器临时集群可以跨主机分布或进行云计算，需要指定名称，可通过 传统 socket 或符合MPI标准的方式来组建 BiocParallel包封装了常见并行函数方便编程 bplapply 对每个x进行函数计算，同lapply bpmapply 对多个函数参数并行运行函数，同mapply bpiterate 对迭代出得数据反复运行函数 bpvec 向量化运算，这样切分更快 bpaggregate 聚合运算 2.7.26 分布式计算 Sparkly 2.7.27 异常值监测 twitter的断点检测 2.7.28 图片处理 imager 2.8 Python 基础数据类型 NULL 数值类型 int float bool(逻辑运算) 列表 从0开始 元素可变 ()赋值为Tuples类型 元素不可变 字符串 文本处理 python专长 字典 {}包含 : 指定属性值 python中对象均有类型 可自定义 2.8.1 工具包 Numpy 数值计算包 Pandas 数据清洗 缺失值 切分 MatPlotLib 数据可视化 sklearn 机器学习包 2.9 Tex 2.9.1 语言基础 作者 Donald Knuth tex 排版引擎 圆周率 metafont 处理字体 自然对数的底数 控制序列 钩子为\\ 宏包 对控制序列打包 钩子为\\ Lamport latex 宏包 分部分处理文档 打包了大量命令 latex 2e 后基本停止 Hans 对 latex 不满 认为可定制性不够 遂进行二次开发 有了 context 引擎 处理控制序列 进行排版 pdftex 可解决文档直接输出为PDF的问题 避免产生dvi 早期不支持unicode 对多国语言只能通过调用宏包来实现字符与图形对应 cjk ctt ctex 等都是此类宏包 需要安装字体 xetex 可原生支持unicode的引擎并调用系统字体 支持plain tex xelatex 可支持latex宏包 luatex 合并metapost 可直接绘图 可直接调用字体 可脱离宏包调用程序 现与 context 结合紧密 tex格式 Knuth为原始300个控制序列写的宏包 有600命令 这900个合称plain tex 将引擎 宏包 格式 辅助程序等打包即为发行版 miktex texlive mactex context minimals 只有自己的引擎与宏包 字体 最早是栅格 后来是矢量 type I 是最早的矢量 truetype 是type I 的竞争对手 opentype 是基于truetype的进化版 最早格式为DVI 为字体准备了字形盒子 可通过上面编码调用字库显示 之后出现了PS与PDF 原来要编译多次 现在只需要用xetex或luatex引擎就可以了 他们内置了库来实现字形盒子与字体的联系 这个库有cache功能 字体分类 衬线体 起笔落笔有差异 横竖粗细各不同 易于识别 宋体 非衬线体 笔画粗细一致 无装饰 醒目 黑体 等宽体 每个字宽窄相同 汉字 编程 2.9.2 关于xetex xeCJK 使用xelatex引擎的中文宏包 纠正了xelatex一些缩进等的不美观 ctex 包含早期CTT CJK 及 xeCJK 可用\\setCJKmainfont{SimSun} 来调用系统字体 下面是底层调用中英文混排 2.9.2.1 实例讲解 \\documentclass[12pt,a4paper]{article} \\usepackage{xltxtra,fontspec,xunicode} \\usepackage[slantfont,boldfont]{xeCJK} % 允许斜体和粗体 \\setCJKmainfont{FZJingLeiS-R-GB} % 设置缺省中文字体 \\setCJKmonofont{SimSun} % 设置等宽字体 \\setmainfont{TeX Gyre Pagella} % 英文衬线字体 \\setmonofont{Monaco} % 英文等宽字体 \\setsansfont{Trebuchet MS} % 英文无衬线字体 2.9.3 常见问题 空白 tab与多个空白认为是一个空白 空行表示段落结束 保留字符 # $ % ^ &amp; _ { } ~ \\ 可使用\\# \\$ \\% \\^{} \\&amp; \\_ \\{ \\} \\~{} 来表示 \\\\ 表示断行 $\\backslash$生成反斜杠 latex命令 \\tex{} 后面加空格防止命令延长 {}中为命令参数 % 表示注释掉一行 也可使用\\usepackage{verbatim} 中的comment环境 源文件结构 \\documentclass[]{...} 声明文档类型[]中为选项 包括字体 纸张 公式对齐 等文档格式 \\usepackage[]{...} 加入需要的宏包[]中为触发功能的关键词 以上为导言区 \\begin{document}开始正文 \\end{document}结束文档 页面样式\\pagestyle{style} 不同页眉页脚样式 \\include{ﬁlename} 用来包含文档 多用于大型文档 在新页包含 连续可用\\input{ﬁlename} \\includeonly{ﬁlename,ﬁlename,. . .} 导言区包含文档 在所有\\include文档中 只有\\includeonly中的会被处理 语法检查\\usepackage{syntonly} \\syntaxonly \\hyphenation{word list} 给出断字列表 完整的不允许断 有-的表示允许的唯一断字点 在文档中-表示唯一允许断字的地方 mbox fbox 不允许断字的地方 后者给出一个方框 mbox可用来分割连字 特殊字符 ‘输入两个表示双引号 -输入1个连字号 2个短破折 3个长破折 网址中波浪号用$\\sim$ 而不是\\~表示 摄氏度用$-30\\,^{\\circ}\\mathrm{C}$表示 \\ldots表示省略号 bable宏包可处理多种非中文语言 ~用来强制取消大写字母后空格多出的一点 \\@用来表示大写字母作为最后一个词后句号的处理 一般latex不会处理大写字母后的句号（加入多一点空格）认为是缩写 \\frontmatter 应接着命令 \\begin{document} 使用 它把页码更换为罗马数字 正文前的内容普遍使用带星的命令（例如，\\chapter*{Preface}） 以阻止 latex 对它们排序 \\mainmatter 应出现在书的第一章紧前面 它打开阿拉伯页码计数器并对页码从新计数 \\appendix 标志书中附录材料的开始 该命令后的各章序号改用字母标记 \\backmatter 应该插入与书中最后一部分内容的紧前面 如参考文献和索引 在标准文档类型中它对页面没有什么效果 交叉引用 \\label{marker}引用点 \\ref{marker}引用 \\pageref{marker} 引用点页码交叉引用 产生脚注 \\footnote{footnote text} 强调 \\underline{text} 下划线 \\emph{text} 斜体 强调中强调会切换字体 环境 itemize 环境用于简单的列表 enumerate 环境用于带序号的列表 description 环境用于带描述的列表 flushleft 和 flushright 环境分别产生靠左排列和靠右排列的段落 center 环境产生居中的文本 如果你不输入命令 \\\\ 指定断行点 latex 将自行决定 quote 环境对重要断语和例子的引用很重要 quotation 环境用于超过几段的较长引用，因为它对段落进行缩进 verse 环境用于诗歌，在诗歌中断行很重要。在一行的末尾用 \\\\ 断行，在每一段后留一空行 verbatim 环境直接输出其中内容 可用断字表示 可表示空格 较短的用\\verb*|like this :-) | \\begin{tabular}{table spec} 用来生成表格 \\begin{figure}[placement speciﬁer] or \\begin{table}[placement speciﬁer] 表示浮动体 \\caption{caption text} 给浮动体加标签 \\listoffigures 与 \\listoftables 生成图表目录 数学公式 段落中放于 \\( 和 \\) $ 和 $ 或者 \\begin{math} 和 \\end{math} 单独一行可放于 \\[ 和 \\] 或 \\begin{displaymath} 和 \\end{displaymath} 带编号可放于equation数学环境中 空格和分行都将被忽略 所有的空格或是由数学表达式逻辑的衍生 或是由特殊的命令如 \\ \\quad 或 \\qquad 来得到 不允许有空行 每个公式中只能有一个段落 每个字符都将被看作是一个变量名并以此来排版 如果你希望在公式中出现普通的文本（使用正体字并可以有空格），那么你必须使用命令 \\textrm{...} 来输入这些文本 \\newtheorem{name}[counter]{text}[section]定理环境 name 是短关键字，用于标识“定理”。text 定义“定理”的真实名称，会在最终文件中打印出来。 建立新命令 \\newcommand{name}[num]{deﬁnition} 第一个参数 name 是你想要建立的命令的名称 第二个参数 deﬁnition 是命令的定义 第三个参数 num 是可选的 用于指定命令所需的参数数目（命令最多可以有9个参数）如果不给出这个参数 那么新建的命令将不接受任何参数 num 可用来传参，\\renewcommand 可用来建立与原命令名称相同的命令 建立新环境 \\newenvironment{name}[num]{before}{after} 建立新宏包 \\ProvidesPackage{package name}命令环境打包起名字保存为sty 可直接调用 其实就是打包导言区 行距\\linespread{factor} 首行缩进与段落间距 \\setlength{\\parindent}{0pt} \\setlength{\\parskip}{1ex plus 0.5ex minus 0.2ex} 水平距离\\hspace{length} 橡皮擦 \\stretch{n} x\\hspace{\\stretch{3}}x 垂直距离\\vspace{length} \\sum\\limits_{k=1}^n k^2 使求和符号上下标真正出现在上下位 "],["repro.html", "第3章 可复算性研究 3.1 Replication 3.2 Reproducible 3.3 研究流程 3.4 数据分析步骤 3.5 数据分析文件结构 3.6 文本化统计编程-Knitr 3.7 结果通讯 3.8 检查列表 3.9 基于证据的数据分析 3.10 结果可解释 3.11 数据分析的理论", " 第3章 可复算性研究 3.1 Replication 科学研究的的终极标准是研究证据可独立发现与验证 并非所有结果都可以重复 3.2 Reproducible 可重复的数据分析过程与代码 数据维度增高 现有数据可被整合入更大的数据集 计算机条件允许 3.3 研究流程 3.4 数据分析步骤 定义问题 背后要有科学假设或问题 从大到小 具体定义 定义理想数据 描述性的 &lt;- 总体数据 探索性的 &lt;- 有属性测量的样本数据 推断性的 &lt;- 合适的总体 随机采样 预测性的 &lt;- 来自同一总体 有训练集与测试集的样本 因果性的 &lt;- 随机性研究 机械性的 &lt;- 系统中所有组成部分的数据 决定可获取数据 网络免费数据 购买数据 注意使用条款 数据不存在 自己创造 &lt;- 实验 获取数据 原始数据 引用来源 网络数据注明数据来源URL与获取时间 整理数据 原始数据需要整理 如果事先处理过要搞清楚如何处理的 了解数据来源 需要重新格式化 采样 &lt;- 记录步骤 判断数据是否合适 不合适重新获取 探索性数据分析 描述性总结数据 检查缺失值 绘制探索性图 尝试探索性分析 例如聚类 统计预测/建模 基于探索性分析 根据问题确定方法 数据转换要解释 测定的不确定性要考虑 解释结果 描述 相关 推断 预测 质疑结果 问题 数据源 处理过程 分析 结论 整合写出结果 从问题角度出发 形成一个故事 不要包含分析过程除非用来说明问题 消除质疑 以故事而不是时间顺序描述 图片要漂亮 写出可重复的R代码 Rmarkdown文件 3.5 数据分析文件结构 Data Raw data 来自网络在Readme里注明url 描述 日期 Processed data 命名体现处理过程 Readme里注明处理过程 Figures Exploratory figures 不必考虑装饰 Final figures 只考虑装饰 R code Raw scripts 不必过分注释 版本控制 不一定用得上 Final scripts 注释清晰 包括处理细节 只包括文章需要费分析 R Markdown files (optional) Text Readme files 按步骤记录清晰 Text of analysis 包括前言 方法 结果 结论 讲故事 有引用 3.6 文本化统计编程-Knitr markdown是轻量化结构语言 R markdown 是轻量化统计结构语言 文本+代码块 逻辑清晰 文本语言可用latex markdown 代码块可用R 不用保存输出 可缓存结果 cacher包 3.7 结果通讯 研究论文的信息层级 题目/作者名单 摘要 主体/结果 支持材料/细节 代码/数据 邮件汇报的信息层级 题目最好一行一句 描述问题 如何实验 总结发现 简明扼要 如果有问题 写成yes/no形式 附件齐全严谨 3.8 检查列表 数据选取得当 问题简单专一 队友靠谱 兴趣驱动 不要手动处理数据 全部交给计算机 少用交互界面 用命令行界面并记录历史 使用版本控制 处理降速而冷静 记录软件操作环境 sessionInfo() 不保存结果保证数据可重复 使用随机数要说明种子 原始数据-处理数据-分析-报告 考虑从哪一步开始数据重复性变差 3.9 基于证据的数据分析 可重复性研究不保证结果是对的 发表后研究存在动因 应关注数据生成前的过程 设定基于证据研究的路线图 减少研究人员的自由度 提出区域研究范式 3.10 结果可解释 结果可解释模型 3.11 数据分析的理论 数据分析的核心应该是可重复性 "],["exp.html", "第4章 探索性数据分析 4.1 ACES 模型 4.2 探索绘图原则 4.3 探索性绘图 4.4 分层聚类 4.5 k-means聚类 4.6 维度还原 4.7 可视化图形", " 第4章 探索性数据分析 4.1 ACES 模型 Letter Step Notes A Acquire the data and Assemble the data frame Find data and import C Clean the data frame Identify and limit columns, rows, indices, dates, etc. E Explore global properties Visualize! Basic plots and stats appropriate to the data set S Subset comparisons Look at (visualize!) initial emergenet variable relationships and subsets 4.2 探索绘图原则 表示可比的对比 表示因果 解释 机制 系统结构 表示多元变量（超过2） 证据整合 目的驱动非工具驱动 证据描述要标注限定恰当 内容为王 4.3 探索性绘图 个人理解用 不用过分关注细节 基于问题或假设出发 4.4 分层聚类 找到最近的 聚到一起 找下个最近的 给出距离范围与距离计算方法 欧氏距离 多维空间点距 开平方 manhattan距离 出租车距离 绝对值 给出变量间或样本间的关系 图形可能不稳定 多少样本多少类 结果是确定的 选定cut点并不明显 应该首先用来探索 4.5 k-means聚类 固定聚类数 给出聚类中心 寻找最近的点 循环 需要聚类数与聚类距离范围 需要大量聚类 通过眼睛 交叉检验 k的经验数值\\(\\sqrt{n/2}\\) 或者根据解释的变量变化多少来选取 结果不确定 根据聚类数与迭代次数而变化 4.6 维度还原 找到最不相关的数来解释整体方差（统计）在这些数中选取个数最少的来解释原始数据（压缩） 不一定是真实向量的叠加 SVD是PCA的一种解法 UDV三个向量 其中U表示行变化模式 D表示方差 V表示列变换模式 这样有助于解释主成分变化 标准化与否影响结果 计算量大 类似探索分析还有因子分析 独立成分分析 潜在语义分析 impute包可补充缺失值 t-sne 4.7 可视化图形 动态可视化 弦图 示意地图 变形地图绘制 重复模式可视化 不确定性可视化 周期性作图需要画两个周期来观察其变化 相关 生物数据可视化 "],["infer.html", "第5章 统计推断 5.1 导论 5.2 概率 5.3 期望 5.4 方差 5.5 独立性 5.6 条件概率 5.7 贝叶斯定理 5.8 常见分布 5.9 渐进 5.10 置信区间 5.11 似然函数 5.12 贝叶斯推断 5.13 两独立样本t检验 5.14 假设检验 5.15 P值 5.16 功效 5.17 多重比较 5.18 重采样推断 5.19 概念可视化", " 第5章 统计推断 5.1 导论 定义 用需要考虑不确定度的含噪音的统计学数据推断事实 工具 随机化 随机采样 采样模型 假设检验 置信区间 概率模型 实验设计 bootstraping 排列交换随机 类型 频率派 使用概率的频率解释来控制错误率 贝叶斯派 给定概率与数据概率哪个靠谱 5.2 概率 术语 样本空间 Ω 事件 样本空间子集 E 单独事件 ω 空事件 ∅ \\(ω∈E\\) ω发生E发生 \\(ω∉E\\) ω发生E不发生 \\(E⊂F\\) E发生则F发生 \\(E∩F\\) EF一起发生 \\(E∪F\\) EF中至少一个发生 \\(E∩F=∅\\) EF互斥 \\(E^c\\) 或 \\(\\bar E\\) E不发生 概率 对事件 \\(E\\subset \\Omega\\), \\(0 \\leq P(E) \\leq 1\\) \\(P(\\Omega) = 1\\) 如果 \\(E_1\\) 与 \\(E_2\\) 互斥 有\\(P(E_1 \\cup E_2) = P(E_1) + P(E_2)\\). 概率无限可加性 \\(P(\\cup_{i=1}^n A_i) = \\sum_{i=1}^n P(A_i)\\) \\(P(\\emptyset) = 0\\) \\(P(E) = 1 - P(E^c)\\) \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) 如果 \\(A \\subset B\\) 则 \\(P(A) \\leq P(B)\\) \\(P\\left(A \\cup B\\right) = 1 - P(A^c \\cap B^c)\\) \\(P(A \\cap B^c) = P(A) - P(A \\cap B)\\) \\(P(\\cup_{i=1}^n E_i) \\leq \\sum_{i=1}^n P(E_i)\\) \\(P(\\cup_{i=1}^n E_i) \\geq \\max_i P(E_i)\\) 随机变量 实验的数值输出 离散随机变量取可数的概率 \\(P(X = k)\\) 连续随机变量取连续区间子集概率 \\(P(X \\in A)\\) 概率质量函数（PMF）&lt;- 离散随机变量 对于所有 \\(x\\) \\(p(x) \\geq 0\\) \\(\\sum_{x} p(x) = 1\\) 概率密度函数（PDF）&lt;- 连续随机变量 对于所有 \\(x\\) \\(f(x) \\geq 0\\) \\(f(x)\\) 下面积为1 累计概率函数（CDF） 定义 \\(F(x) = P(X \\leq x)\\) 生存函数 \\(S(x) = P(X &gt; x)\\) \\(S(x) = 1 - F(x)\\) 对于连续函数 CDF是PDF的积分 分位数 \\(\\alpha^{th}\\) \\(F(x_\\alpha) = \\alpha\\) \\(50^{th}\\) 分位数是中位数 5.3 期望 离散随机变量均值 \\(E[X] = \\sum_x xp(x)\\) \\(E[X]\\) 代表质量与位置的中心 \\(\\{x, p(x)\\}\\) 连续随机变量均值 \\(E[X] = \\mbox{the area under the function}~~~ t f(t)\\) 期望值是线性可加的 如果 \\(a\\) 与 \\(b\\) 不随机 \\(X\\) 与 \\(Y\\) 是随机变量 \\(E[aX + b] = a E[X] + b\\) \\(E[X + Y] = E[X] + E[Y]\\) 样本均值是总体均值\\(\\mu\\)的无偏估计的证明 \\[\\begin{eqnarray*} E\\left[ \\frac{1}{n}\\sum_{i=1}^n X_i\\right] &amp; = &amp; \\frac{1}{n} E\\left[\\sum_{i=1}^n X_i\\right] \\\\ &amp; = &amp; \\frac{1}{n} \\sum_{i=1}^n E\\left[X_i\\right] \\\\ &amp; = &amp; \\frac{1}{n} \\sum_{i=1}^n \\mu = \\mu. \\end{eqnarray*}\\] 5.4 方差 描述随机变量的离散情况 如果 \\(X\\) 是均值 \\(\\mu\\) 的随机变量 其方差为\\(Var(X) = E[(X - \\mu)^2]\\) 离开均值距离期望的平方 计算公式 \\(Var(X) = E[X^2] - E[X]^2\\) 如果 \\(a\\) 是常数有 \\(Var(aX) = a^2 Var(X)\\) 方差的开方是标准差 单位与 \\(X\\) 一致 车比雪夫不等式（Chebyshev’s inequality）边界极为保守 \\[ P(|X - \\mu| \\geq k\\sigma) \\leq \\frac{1}{k^2} \\] 5.5 独立性 独立事件 两事件 \\(A\\) 与 \\(B\\) 在 \\(P(A \\cap B) = P(A)P(B)\\) 下独立 在 \\(P([X \\in A] \\cap [Y \\in B]) = P(X\\in A)P(Y\\in B)\\) 下两随机变量 \\(X\\) 与 \\(Y\\) 独立 对于一组随机独立变量\\(X_1, X_2, \\ldots, X_n\\)有 \\(f(x_1,\\ldots, x_n) = \\prod_{i=1}^n f_i(x_i)\\) iid随机变量（independent and identically distributed） 来自同一分布相互独立的随机变量 协方差（covariance） \\(Cov(X, Y) = E[(X - \\mu_x)(Y - \\mu_y)] = E[X Y] - E[X]E[Y]\\) \\(Cov(X, Y) = Cov(Y, X)\\) \\(Cov(X, Y)\\) 可以有正负 \\(|Cov(X, Y)| \\leq \\sqrt{Var(X) Var(y)}\\) 相关性（correlation） \\(X\\) 与 \\(Y\\) 的相关性 \\(Cor(X, Y) = Cov(X, Y) / \\sqrt{Var(X) Var(y)}\\) \\(-1 \\leq Cor(X, Y) \\leq 1\\) 只有对常数 \\(a\\) 与 \\(b\\)满足 \\(X = a + bY\\) 时\\(Cor(X, Y) = \\pm 1\\) \\(Cor(X, Y)\\) 无单位 \\(Cor(X, Y) = 0\\) 时 \\(X\\) 与 \\(Y\\) 不相关 \\(Cor(X,Y)\\) 越接近1 \\(X\\) 与 \\(Y\\) 越正相关 反之接近-1 负相关 \\(\\{X_i\\}_{i=1}^n\\) 是一组随机变量 当 \\(\\{X_i\\}\\) 不相关时 \\(Var\\left(\\sum_{i=1}^n a_i X_i + b\\right) = \\sum_{i=1}^n a_i^2 Var(X_i)\\) 如果一组随机变量\\(\\{X_i\\}\\)不相关 方差的和等于和的方差 非标准差 样本均值方差的推导 \\[\\begin{eqnarray*} Var(\\bar X) &amp; = &amp; Var \\left( \\frac{1}{n}\\sum_{i=1}^n X_i \\right)\\\\ \\\\ &amp; = &amp; \\frac{1}{n^2} Var\\left(\\sum_{i=1}^n X_i \\right)\\\\ \\\\ &amp; = &amp; \\frac{1}{n^2} \\sum_{i=1}^n Var(X_i) \\\\ \\\\ &amp; = &amp; \\frac{1}{n^2} \\times n\\sigma^2 \\\\ \\\\ &amp; = &amp; \\frac{\\sigma^2}{n} \\end{eqnarray*}\\] 当 \\(X_i\\) 独立且方差为 \\(Var(\\bar X) = \\frac{\\sigma^2}{n}\\) \\(\\sigma/\\sqrt{n}\\) 为样本均值的标准误 样本均值的标准误就是样本均值分布的标准差 \\(\\sigma\\) 是一次观察分布的标准差 样本均值要比一次观察变化小 因此除以\\(\\sqrt{n}\\) 样本方差 \\(S^2 = \\frac{\\sum_{i=1}^n (X_i - \\bar X)^2}{n-1}\\) 总体方差 \\(\\sigma^2\\)的估计 计算 \\(\\sum_{i=1}^n (X_i - \\bar X)^2 = \\sum_{i=1}^n X_i^2 - n \\bar X^2\\) 均值偏差平方的均值 样本方差是总体方差的无偏估计 \\[\\begin{eqnarray*} E\\left[\\sum_{i=1}^n (X_i - \\bar X)^2\\right] &amp; = &amp; \\sum_{i=1}^n E\\left[X_i^2\\right] - n E\\left[\\bar X^2\\right] \\\\ \\\\ &amp; = &amp; \\sum_{i=1}^n \\left\\{Var(X_i) + \\mu^2\\right\\} - n \\left\\{Var(\\bar X) + \\mu^2\\right\\} \\\\ \\\\ &amp; = &amp; \\sum_{i=1}^n \\left\\{\\sigma^2 + \\mu^2\\right\\} - n \\left\\{\\sigma^2 / n + \\mu^2\\right\\} \\\\ \\\\ &amp; = &amp; n \\sigma^2 + n \\mu ^ 2 - \\sigma^2 - n \\mu^2 \\\\ \\\\ &amp; = &amp; (n - 1) \\sigma^2 \\end{eqnarray*}\\] 澄清 假定 \\(X_i\\) 是 iid 均值 \\(\\mu\\) 方差 \\(\\sigma^2\\) \\(S^2\\) 估计 \\(\\sigma^2\\) \\(S^2\\) 的计算涉及除 \\(n-1\\) \\(S / \\sqrt{n}\\) 估计 \\(\\sigma / \\sqrt{n}\\) 是均值的标准误 5.6 条件概率 \\(B\\) 为一个事件 有 \\(P(B) &gt; 0\\) \\(B\\) 出现条件下 \\(A\\) 的条件概率为 \\(P(A ~|~ B) = \\frac{P(A \\cap B)}{P(B)}\\) 如果 \\(A\\) 与 \\(B\\) 独立 有 \\(P(A ~|~ B) = \\frac{P(A) P(B)}{P(B)} = P(A)\\) 5.7 贝叶斯定理 \\[ P(B ~|~ A) = \\frac{P(A ~|~ B) P(B)}{P(A ~|~ B) P(B) + P(A ~|~ B^c)P(B^c)}. \\] 2*2 列联表 - 诊断测试 5.8 常见分布 贝努力分布 二元输出变量 数值为0或1 概率\\(p\\) 与 \\(1-p\\) \\(X\\)的PMF是\\(P(X = x) = p^x (1 - p)^{1 - x}\\) 均值 \\(p\\) 方差 \\(p(1 - p)\\) 如果有iid的贝努力观察\\(x_1,\\ldots, x_n\\) 似然函数 \\(\\prod_{i=1}^n p^{x_i} (1 - p)^{1 - x_i} = p^{\\sum x_i} (1 - p)^{n - \\sum x_i}\\) 似然函数依赖\\(x_i\\)的和 \\(\\sum_i x_i / n\\) 包含了所有 \\(p\\) 的可能性 最大化似然函数可以得到 \\(p\\) 的估计 二项分布 PMF \\[ P(X = x) = \\left( \\begin{array}{c} n \\\\ x \\end{array} \\right) p^x(1 - p)^{n-x} \\] 对于 \\(x=0,\\ldots,n\\) 正态分布 PDF \\((2\\pi \\sigma^2)^{-1/2}e^{-(x - \\mu)^2/2\\sigma^2}\\) \\(X\\) 为均值 \\(E[X] = \\mu\\) 方差 \\(Var(X) = \\sigma^2\\) 的iid随机变量 写作\\(X\\sim \\mbox{N}(\\mu, \\sigma^2)\\) 均值 \\(\\mu = 0\\) 方差 \\(\\sigma = 1\\) 是标准正态分布 标准正态函数写作 \\(\\phi\\) 标准正态随机变量用 \\(Z\\) 表示 如果 \\(X \\sim \\mbox{N}(\\mu,\\sigma^2)\\) 并且 \\(Z = \\frac{X -\\mu}{\\sigma}\\) 是标准正态函数 如果 \\(Z\\) 是标准正态函数 \\(X = \\mu + \\sigma Z \\sim \\mbox{N}(\\mu, \\sigma^2)\\) 非标准正态密度函数 \\(\\phi\\{(x - \\mu) / \\sigma\\}/\\sigma\\) 正态似然函数对方差的估计是有偏的 正态的和是正态 样本均值正态 正态的平方是卡方 正态分布 泊松分布 PMF \\(P(X = x; \\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!}\\) 均值方差均为 \\(\\lambda\\) 可看做很短时间间隔中发生事件的概率 模拟速率 其中\\(\\lambda * h\\)小于1 则各时间段独立 \\(X \\sim Poisson(\\lambda t)\\) \\(\\lambda = E[X / t]\\)是速率 \\(t\\) 是总时间 \\(n\\) 大 \\(p\\) 小是对二项分布的模拟 \\(X \\sim \\mbox{Binomial}(n, p)\\), \\(\\lambda = n p\\) 5.9 渐进 样本接近无穷大时统计量的行为 频率派的基石 大数理论（LLN） 样本数量越多 均值接近期望 中心极限理论 (CLT) iid 变量均值的分布标准化后随样本数增加接近标准正态分布 \\[ \\frac{\\bar X_n - \\mu}{\\sigma / \\sqrt{n}} = \\frac{\\mbox{Estimate} - \\mbox{Mean of estimate}}{\\mbox{Std. Err. of estimate}} \\] 可根据变量分布来 知道均值 方差 计算出样本均值标准误 就可以根据CLT计算逼近的统计量 置信区间 根据CLT随机区间\\(\\bar X_n \\pm z_{1-\\alpha/2}\\sigma / \\sqrt{n}\\) 包括 \\(\\mu\\) 的概率逼近于 100\\((1-\\alpha)\\)% \\(z_{1-\\alpha/2}\\)为标准正态分布\\(1-\\alpha/2\\)的分位数 \\(100(1 - \\alpha)\\)% 为置信区间 \\(\\sigma\\) 可用样本估计 \\(s\\) 来近似 估计是基于分布假设的 如果分布有解析解 则置信区间可以更准确的得到估计 先生成不依赖参数的统计量 根据统计量的概率分布计算参数的边界 5.10 置信区间 卡方分布 假定 \\(S^2\\) 是来自\\(n\\)个 iid \\(N(\\mu,\\sigma^2)\\) 数据样本的方差 有\\(\\frac{(n - 1) S^2}{\\sigma^2} \\sim \\chi^2_{n-1}\\) 符合自由度\\(n-1\\)的卡方分布 不对称分布 均值是自由度 方差是两倍的自由度 方差的置信区间 \\[\\begin{eqnarray*} 1 - \\alpha &amp; = &amp; P \\left( \\chi^2_{n-1, \\alpha/2} \\leq \\frac{(n - 1) S^2}{\\sigma^2} \\leq \\chi^2_{n-1,1 - \\alpha/2} \\right) \\\\ \\\\ &amp; = &amp; P\\left(\\frac{(n-1)S^2}{\\chi^2_{n-1,1-\\alpha/2}} \\leq \\sigma^2 \\leq \\frac{(n-1)S^2}{\\chi^2_{n-1,\\alpha/2}} \\right) \\\\ \\end{eqnarray*}\\] \\(\\left[\\frac{(n-1)S^2}{\\chi^2_{n-1,1-\\alpha/2}}, \\frac{(n-1)S^2}{\\chi^2_{n-1,\\alpha/2}}\\right]\\) 是 \\(\\sigma^2\\) 的 \\(100(1-\\alpha)\\%\\) 置信区间 依赖正态性假设 开方后得到 \\(\\sigma\\) 的置信区间 Gosset的 t 分布 比正态分布尾厚 考虑自由度 自由度大时接近正态分布 \\(\\frac{Z}{\\sqrt{\\frac{\\chi^2}{df}}}\\) 假定 \\((X_1,\\ldots,X_n)\\) 是 iid \\(N(\\mu,\\sigma^2)\\) 有 \\(\\frac{\\bar X - \\mu}{\\sigma / \\sqrt{n}}\\) 是标准正态分布 \\(\\sqrt{\\frac{(n - 1) S^2}{\\sigma^2 (n - 1)}} = S / \\sigma\\) 是卡方除以自由度的开方 有 \\[ \\frac{\\frac{\\bar X - \\mu}{\\sigma /\\sqrt{n}}}{S/\\sigma} = \\frac{\\bar X - \\mu}{S/\\sqrt{n}} \\] 服从自由度\\(n-1\\)的\\(t\\)分布 均值的置信区间 \\[\\begin{eqnarray*} &amp; &amp; 1 - \\alpha \\\\ &amp; = &amp; P\\left(-t_{n-1,1-\\alpha/2} \\leq \\frac{\\bar X - \\mu}{S/\\sqrt{n}} \\leq t_{n-1,1-\\alpha/2}\\right) \\\\ \\\\ &amp; = &amp; P\\left(\\bar X - t_{n-1,1-\\alpha/2} S / \\sqrt{n} \\leq \\mu \\leq \\bar X + t_{n-1,1-\\alpha/2}S /\\sqrt{n}\\right) \\end{eqnarray*}\\] \\(t_{df,\\alpha}\\) 是t分布的 \\(\\alpha^{th}\\) 分位数 自由度 \\(df\\) t检验不适合有偏分布 置信区间中心也不在均值上 5.11 似然函数 一组数据的似然函数是数据固定下参数的联合概率密度函数 似然函数可用来估计参数 是参数的函数 似然函数比估计两个可能参数值的可能性 给定模型与数据 似然函数包含所有参数可能性 样本独立时 参数的似然函数是各独立样本似然函数的乘积 参数使似然函数概率取最大值时真实的可能性更大 更支持这组数据 这个估计是最大似然估计（MLE） 5.12 贝叶斯推断 \\(\\mbox{Posterior} \\propto \\mbox{Likelihood} \\times \\mbox{Prior}\\) 先验beta分布 01之间 依赖 \\(\\alpha\\) \\(\\beta\\) 的概率密度函数 \\[ \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} p ^ {\\alpha - 1} (1 - p) ^ {\\beta - 1} ~~~~\\mbox{for} ~~ 0 \\leq p \\leq 1 \\] 均值 \\(\\alpha / (\\alpha + \\beta)\\) 方差 \\(\\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\\) \\(\\alpha = \\beta = 1\\) 为均匀分布 后验beta分布 参数\\(\\tilde \\alpha = x + \\alpha\\) \\(\\tilde \\beta = n - x + \\beta\\) 的beta分布 \\[\\begin{align} \\mbox{Posterior} &amp;\\propto p^x(1 - p)^{n-x} \\times p^{\\alpha -1} (1 - p)^{\\beta - 1} \\\\ &amp; = p^{x + \\alpha - 1} (1 - p)^{n - x + \\beta - 1} \\end{align}\\] 后验均值 \\[\\begin{align} E[p ~|~ X] &amp; = \\frac{\\tilde \\alpha}{\\tilde \\alpha + \\tilde \\beta}\\\\ \\\\ &amp; = \\frac{x + \\alpha}{x + \\alpha + n - x + \\beta}\\\\ \\\\ &amp; = \\frac{x + \\alpha}{n + \\alpha + \\beta} \\\\ \\\\ &amp; = \\frac{x}{n} \\times \\frac{n}{n + \\alpha + \\beta} + \\frac{\\alpha}{\\alpha + \\beta} \\times \\frac{\\alpha + \\beta}{n + \\alpha + \\beta} \\\\ \\\\ &amp; = \\mbox{MLE} \\times \\pi + \\mbox{Prior Mean} \\times (1 - \\pi) \\end{align}\\] 后验均值是先验均值与最大似然估计的混合 当 \\(n\\) 变大 \\(\\pi\\) 接近 \\(1\\) 先验作用小 当 \\(n\\) 很小 先验作用大 当数据量够大时 先验概率作用就很小了 当先验概率足够稳定 数据就作用不大了 信任区间 \\(95\\%\\) 信任区间 \\([a, b]\\) 会满足\\(P(p \\in [a, b] ~|~ x) = .95\\) 最高后验密度 (HPD) 区间 5.13 两独立样本t检验 \\(X_1,\\ldots,X_{n_x}\\) 为 iid \\(N(\\mu_x,\\sigma^2)\\) \\(Y_1,\\ldots,Y_{n_y}\\) 为 iid \\(N(\\mu_y, \\sigma^2)\\) \\(\\bar X\\), \\(\\bar Y\\), \\(S_x\\), \\(S_y\\) 为均值与标准差 根据均值与方差的线性组合 有 \\(\\bar Y - \\bar X\\) 也是正态 均值 \\(\\mu_y - \\mu_x\\) 方差 \\(\\sigma^2 (\\frac{1}{n_x} + \\frac{1}{n_y})\\) 混合方差为 \\(S_p^2 = \\{(n_x - 1) S_x^2 + (n_y - 1) S_y^2\\}/(n_x + n_y - 2)\\) 为\\(\\sigma^2\\)的良好估计 该估计为无偏估计 \\[\\begin{eqnarray*} E[S_p^2] &amp; = &amp; \\frac{(n_x - 1) E[S_x^2] + (n_y - 1) E[S_y^2]}{n_x + n_y - 2}\\\\ &amp; = &amp; \\frac{(n_x - 1)\\sigma^2 + (n_y - 1)\\sigma^2}{n_x + n_y - 2} \\end{eqnarray*}\\] 该估计独立于 \\(\\bar Y - \\bar X\\) 因为方差独立于均值 两个独立的卡方变量之和是自由度之和的卡方值 \\[\\begin{eqnarray*} (n_x + n_y - 2) S_p^2 / \\sigma^2 &amp; = &amp; (n_x - 1)S_x^2 /\\sigma^2 + (n_y - 1)S_y^2/\\sigma^2 \\\\ \\\\ &amp; = &amp; \\chi^2_{n_x - 1} + \\chi^2_{n_y-1} \\\\ \\\\ &amp; = &amp; \\chi^2_{n_x + n_y - 2} \\end{eqnarray*}\\] 构建统计量 \\[ \\frac{\\frac{\\bar Y - \\bar X - (\\mu_y - \\mu_x)}{\\sigma \\left(\\frac{1}{n_x} + \\frac{1}{n_y}\\right)^{1/2}}}{\\sqrt{\\frac{(n_x + n_y - 2) S_p^2}{(n_x + n_y - 2)\\sigma^2}}} = \\frac{\\bar Y - \\bar X - (\\mu_y - \\mu_x)}{S_p \\left(\\frac{1}{n_x} + \\frac{1}{n_y}\\right)^{1/2}} \\] 该统计量为符合自由度 \\(n_x + n_y - 2\\) 的 \\(t\\) 分布 置信区间 \\[ \\bar Y - \\bar X \\pm t_{n_x + n_y - 2, 1 - \\alpha/2}S_p\\left(\\frac{1}{n_x} + \\frac{1}{n_y}\\right)^{1/2} \\] 方差不等 \\[ \\bar Y - \\bar X \\sim N\\left(\\mu_y - \\mu_x, \\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y}\\right) \\] 统计量 \\[ \\frac{\\bar Y - \\bar X - (\\mu_y - \\mu_x)}{\\left(\\frac{s_x^2}{n_x} + \\frac{s_y^2}{n_y}\\right)^{1/2}} \\] 近似于自由度 \\[ \\frac{\\left(S_x^2 / n_x + S_y^2/n_y\\right)^2} {\\left(\\frac{S_x^2}{n_x}\\right)^2 / (n_x - 1) + \\left(\\frac{S_y^2}{n_y}\\right)^2 / (n_y - 1)} \\] 的\\(t\\)分布 5.14 假设检验 使用数据做决定 空假设 \\(H_0\\) 无变化 备择假设 \\(H_a\\) 或大 或小 或不等 真值表 Truth Decide Result \\(H_0\\) \\(H_0\\) Correctly accept null \\(H_0\\) \\(H_a\\) Type I error \\(H_a\\) \\(H_a\\) Correctly reject null \\(H_a\\) \\(H_0\\) Type II error Z检验 Z检验 \\(H_0:\\mu = \\mu_0\\) 与 \\(H_1: \\mu &lt; \\mu_0\\) \\(H_2: \\mu \\neq \\mu_0\\) \\(H_3: \\mu &gt; \\mu_0\\) 检验统计量 \\(TS = \\frac{\\bar{X} - \\mu_0}{S / \\sqrt{n}}\\) 拒绝空假设条件 \\(TS \\leq -Z_{1 - \\alpha}\\) \\(|TS| \\geq Z_{1 - \\alpha / 2}\\) \\(TS \\geq Z_{1 - \\alpha}\\) 样本数要足够 否则选 \\(t\\) 检验 通过 \\(\\alpha\\) 控制了 Type I error 但没控制 \\(\\beta\\) Type II error 所以结论为没有拒绝 \\(H_0\\) 而不是接受 \\(H_0\\) 拒绝 \\(H_0\\) 的值域为拒绝域 二项分布不易做正态假设可精确计算拒绝域 5.15 P值 假定没有事发生 出现状况的可能性 先定义分布 然后计算相关统计量 对比常见阈值看数值是否够极端 阈值为达到显著性水平 与p值有区别 p值可设定任意显著性水平 小于就可以拒绝 两尾检验 单尾概率翻倍 独立于假设检验 但常常一起使用 5.16 功效 错误拒绝空假设的概率为功效（power） Power \\(= 1 - \\beta\\) 对 Type II error 的控制 正态分布假设下的推导 \\[\\begin{align} 1 -\\beta &amp; = P\\left(\\frac{\\bar X - 30}{\\sigma /\\sqrt{n}} &gt; z_{1-\\alpha} ~|~ \\mu = \\mu_a \\right)\\\\ &amp; = P\\left(\\frac{\\bar X - \\mu_a + \\mu_a - 30}{\\sigma /\\sqrt{n}} &gt; z_{1-\\alpha} ~|~ \\mu = \\mu_a \\right)\\\\ \\\\ &amp; = P\\left(\\frac{\\bar X - \\mu_a}{\\sigma /\\sqrt{n}} &gt; z_{1-\\alpha} - \\frac{\\mu_a - 30}{\\sigma /\\sqrt{n}} ~|~ \\mu = \\mu_a \\right)\\\\ \\\\ &amp; = P\\left(Z &gt; z_{1-\\alpha} - \\frac{\\mu_a - 30}{\\sigma /\\sqrt{n}} ~|~ \\mu = \\mu_a \\right)\\\\ \\\\ \\end{align}\\] sigma &lt;- 10; mu_0 = 0; mu_a = 2; n &lt;- 100; alpha = .05 plot(c(-3, 6),c(0, dnorm(0)), type = &quot;n&quot;, frame = F, xlab = &quot;Z value&quot;, ylab = &quot;&quot;) xvals &lt;- seq(-3, 6, length = 1000) lines(xvals, dnorm(xvals), type = &quot;l&quot;, lwd = 3) lines(xvals, dnorm(xvals, mean = sqrt(n) * (mu_a - mu_0) / sigma), lwd =3) abline(v = qnorm(1 - alpha)) - 计算步骤 - 考虑 \\(H_0 : \\mu = \\mu_0\\) 与 \\(H_a : \\mu &gt; \\mu_0\\) 且在\\(H_a\\)下 \\(\\mu = \\mu_a\\) - 在 \\(H_0\\) 下统计量 \\(Z = \\frac{\\sqrt{n}(\\bar X - \\mu_0)}{\\sigma}\\) 符合 \\(N(0, 1)\\) - 在\\(H_a\\)下 \\(Z\\) 是 \\(N\\left( \\frac{\\sqrt{n}(\\mu_a - \\mu_0)}{\\sigma}, 1\\right)\\) - 如果 \\(Z &gt; Z_{1-\\alpha}\\) 拒绝空假设 也就是给定条件下功效不够 - 当检验 \\(H_a : \\mu &gt; \\mu_0\\), 如果功效为 \\(1 - \\beta\\) 那么 \\(1 - \\beta = P\\left(Z &gt; z_{1-\\alpha} - \\frac{\\mu_a - \\mu_0}{\\sigma /\\sqrt{n}} ~|~ \\mu = \\mu_a \\right) = P(Z &gt; z_{\\beta})\\) 也就是 \\(z_{1-\\alpha} - \\frac{\\sqrt{n}(\\mu_a - \\mu_0)}{\\sigma} = z_{\\beta}\\) - \\(\\mu_a\\), \\(\\sigma\\), \\(n\\), \\(\\beta\\), \\(\\mu_0\\), \\(\\alpha\\) 给定五个可解出剩余的 - 两尾检验考虑 \\(\\alpha / 2\\) - 功效在 \\(\\alpha\\) 提高 单尾检验功效高于两尾 \\(\\mu_1\\) 距离 \\(\\mu_0\\) 远功效大 样本数提高功效高 - 计算功效不需要特定样本 只需要指定 \\(\\frac{\\mu_a - \\mu_0}{\\sigma}\\) 也就是有效样本大小 无单位 - R 中使用 power.t.test 来计算 \\(t\\) 检验功效相关参数 指定多数求一个 5.17 多重比较 多次进行比较会导致错误率与校正出现问题 False positive rate 错误结果是显著的比率 \\(\\alpha\\) 样本数增大错误增加 Family wise error rate (FWER) 所有比较中至少一个假阳性比率 Bonferroni correction 假设你进行m次测试 控制 \\(\\alpha\\) 在某水平 计算所有测试的 \\(p\\) 值 将 \\(\\alpha\\) 设为 \\(\\frac{\\alpha}{m}\\) 所有测试都在这个置信度下进行 容易计算 过于保守 False discovery rate (FDR) 声称显著是错误的概率 \\(m\\) 次测试 水平 \\(\\alpha\\) 计算 \\(p\\) 值 排序 \\(P_{(i)} \\leq \\alpha \\times \\frac{i}{m}\\) 为显著 相对容易计算 不保守 允许一定的假阳性 调节p值 \\(P_i^{fwer} = \\max{m \\times P_i,1}\\) 类似FWER处理 \\(\\alpha\\) 的方式处理 \\(p\\) 按照正常 \\(\\alpha\\) 检测 一般情况对 \\(p\\) 值用 bonferroni/BH矫正就够了 对比间依赖强烈考虑 method=“BY” 多重比较从原理到应用 从实用角度分类 适合常见科研实验结果处理 5.18 重采样推断 jackknife 用来无偏估计偏差与标准误 每次估计删掉一个数据 \\(\\bar \\theta = \\frac{1}{n}\\sum_{i=1}^n \\hat \\theta_{i}\\) 偏差 \\((n - 1) \\left(\\bar \\theta - \\hat \\theta\\right)\\) 标准误 \\(\\left[\\frac{n-1}{n}\\sum_{i=1}^n (\\hat \\theta_i - \\bar\\theta )^2\\right]^{1/2}\\) 可用来估计分位数 是bootstrap的线性逼近 但性质不好 假观察量角度理解jackknife \\(\\mbox{Pseudo Obs} = n \\hat \\theta - (n - 1) \\hat \\theta_{i}\\) 生成原数据集 bootstrap 5.19 概念可视化 统计概念可视化 构建置信区间与求标准误 假定采样分布是总体分布 重采样估计统计量 有放回的重采样 \\(B\\) 次 \\(N\\) 个样本 得到估计统计量的一个分布 直接计算置信区间 非参方法 偏差小 进阶指南 置换检验 分组对比时取消原分组随机分组 重复进行 记录分组差异 对比原参数与置换后参数差异进行推断 "],["reg.html", "第6章 回归模型 6.1 回归模型导论 6.2 术语 6.3 回归线的最小二乘回归 6.4 统计线性回归模型 6.5 残差 6.6 回归推断 6.7 多元回归 6.8 模型诊断与选择 6.9 广义线性模型 6.10 二元响应 6.11 计数或速率响应 6.12 分段平滑", " 第6章 回归模型 6.1 回归模型导论 Francis Galton 1885年用父母身高预测子女身高的案例 考虑单变量的数据代表：最小二乘值 最小二乘值物理意义为质心 最小二乘统计学意义是平均值 可用不等式解 也可用求导方法解 \\[\\begin{align} \\sum_{i=1}^n (Y_i - \\mu)^2 &amp; = \\ \\sum_{i=1}^n (Y_i - \\bar Y + \\bar Y - \\mu)^2 \\\\ &amp; = \\sum_{i=1}^n (Y_i - \\bar Y)^2 + \\ 2 \\sum_{i=1}^n (Y_i - \\bar Y) (\\bar Y - \\mu) +\\ \\sum_{i=1}^n (\\bar Y - \\mu)^2 \\\\ &amp; = \\sum_{i=1}^n (Y_i - \\bar Y)^2 + \\ 2 (\\bar Y - \\mu) \\sum_{i=1}^n (Y_i - \\bar Y) +\\ \\sum_{i=1}^n (\\bar Y - \\mu)^2 \\\\ &amp; = \\sum_{i=1}^n (Y_i - \\bar Y)^2 + \\ 2 (\\bar Y - \\mu) (\\sum_{i=1}^n Y_i - n \\bar Y) +\\ \\sum_{i=1}^n (\\bar Y - \\mu)^2 \\\\ &amp; = \\sum_{i=1}^n (Y_i - \\bar Y)^2 + \\sum_{i=1}^n (\\bar Y - \\mu)^2\\\\ &amp; \\geq \\sum_{i=1}^n (Y_i - \\bar Y)^2 \\ \\end{align}\\]2 (Y - ) {i=1}^n (Y_i - Y) + {i=1}^n (Y - )^2 \\ &amp; = {i=1}^n (Y_i - Y)^2 + 2 (Y - ) ({i=1}^n Y_i - n Y) + {i=1}^n (Y - )^2 \\ &amp; = {i=1}^n (Y_i - Y)^2 + {i=1}^n (Y - )^2\\ &amp; {i=1}^n (Y_i - Y)^2 \\end{align} 通过原点的回归 最小化\\(\\sum_{i=1}^n (Y_i - X_i \\beta)^2\\) 两变量关系用回归线解释 回归分析种类大全 6.2 术语 \\(X_1, X_2, \\ldots, X_n\\) 表示 \\(n\\) 个数据点 \\(Y_1, \\ldots , Y_n\\) 表示另外 \\(n\\) 个数据点 用希腊字母表示不知道的东西 如 \\(\\mu\\) 大写字母表示概念值 小写字母表示真实值 如 \\(P(X_i &gt; x)\\) \\(\\bar X = \\frac{1}{n}\\sum_{i=1}^n X_i\\) 表示均值 数据的中心趋向 \\(\\tilde X_i = X_i - \\bar X\\) 表示对数据中心化 均值为0 均值为数据的最小二乘估计 \\(S^2 = \\frac{1}{n-1} \\sum_{i=1}^n (X_i - \\bar X)^2 = \\frac{1}{n-1} \\left( \\sum_{i=1}^n X_i^2 - n \\bar X ^ 2 \\right)\\) 表示方差 \\(S\\) 为标准差 数据的离散程度 \\(X_i / s\\) 表示数据缩放 方差为1 \\(Z_i = \\frac{X_i - \\bar X}{s}\\) 表示数据的标准化 先中心化再标准化 \\(Cov(X, Y) = \\frac{1}{n-1}\\sum_{i=1}^n (X_i - \\bar X) (Y_i - \\bar Y)= \\frac{1}{n-1}\\left( \\sum_{i=1}^n X_i Y_i - n \\bar X \\bar Y\\right)\\) 表示协方差 \\(Cor(X, Y) = \\frac{Cov(X, Y)}{S_x S_y}\\) 表示相关性 \\(Cor(X, Y) = Cor(Y, X)\\) \\(-1 \\leq Cor(X, Y) \\leq 1\\) \\(Cor(X, Y)\\) 度量线性关系强度 \\(Cor(X, Y) = 0\\) 表示无线性关系 6.3 回归线的最小二乘回归 用最小二乘法寻找回归线 最小化 \\(\\sum_{i=1}^n \\{Y_i - (\\beta_0 + \\beta_1 X_i)\\}^2\\) 如果定义 \\(\\mu_i = \\beta_0\\) \\(\\hat \\beta_0 = \\bar Y\\) 不考虑其他变量 \\(Y\\) 的均值就是最小二乘估计 如果定义 \\(\\mu_i = X_i \\beta_1\\) \\(\\hat \\beta_1 = \\frac{\\sum_{i=1^n} Y_i X_i}{\\sum_{i=1}^n X_i^2}\\) 如果考虑过原点线的回归 斜率如上 如果考虑 \\(\\mu_i = \\beta_0 + \\beta_1 X_i\\) \\[\\begin{align} \\ \\sum_{i=1}^n (Y_i - \\hat \\mu_i) (\\hat \\mu_i - \\mu_i) = &amp; \\sum_{i=1}^n (Y_i - \\hat\\beta_0 - \\hat\\beta_1 X_i) (\\hat \\beta_0 + \\hat \\beta_1 X_i - \\beta_0 - \\beta_1 X_i) \\\\ = &amp; (\\hat \\beta_0 - \\beta_0) \\sum_{i=1}^n (Y_i - \\hat\\beta_0 - \\hat \\beta_1 X_i) + (\\beta_1 - \\beta_1)\\sum_{i=1}^n (Y_i - \\hat\\beta_0 - \\hat \\beta_1 X_i)X_i\\\\ \\end{align}\\]beta_0 - 0) {i=1}^n (Y_i - _0 - _1 X_i) + (_1 - 1){i=1}^n (Y_i - _0 - _1 X_i)X_i\\ \\end{align} 解为\\(\\hat \\beta_1 = Cor(Y, X) \\frac{Sd(Y)}{Sd(X)} ~~~ \\hat \\beta_0 = \\bar Y - \\hat \\beta_1 \\bar X\\) 如果标准化数据 \\(\\{ \\frac{X_i - \\bar X}{Sd(X)}, \\frac{Y_i - \\bar Y}{Sd(Y)}\\}\\) 解为\\(Cor(Y, X)\\) 回归是因变量向自己均值回归与向自变量相关回归的平衡 6.4 统计线性回归模型 最小二乘是一种估计方法，做推断需要模型 建立线性回归的概率模型\\(Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_{i}\\) \\(\\epsilon_{i}\\) 为 iid \\(N(0, \\sigma^2)\\) \\(E[Y_i ~|~ X_i = x_i] = \\mu_i = \\beta_0 + \\beta_1 x_i\\) \\(Var(Y_i ~|~ X_i = x_i) = \\sigma^2\\) 对\\(N(\\mu_i, \\sigma^2)\\)独立变量 \\(Y\\) 进行极大似然估计 \\({\\cal L}(\\beta, \\sigma) = \\prod_{i=1}^n \\left\\{(2 \\pi \\sigma^2)^{-1/2}\\exp\\left(-\\frac{1}{2\\sigma^2}(y_i - \\mu_i)^2 \\right) \\right\\}\\) 取对数有 \\(-2 \\log\\{ {\\cal L}(\\beta, \\sigma) \\} = \\frac{1}{\\sigma^2} \\sum_{i=1}^n (y_i - \\mu_i)^2 + n\\log(\\sigma^2)\\) 最小二乘估计就是极大似然估计 \\(\\hat \\beta_1 = Cor(Y, X) \\frac{Sd(Y)}{Sd(X)} ~~~ \\hat \\beta_0 = \\bar Y - \\hat \\beta_1 \\bar X\\) 截距是自变量为0时 \\(Y\\) 的期望 斜率是自变量变化一个单位对 \\(Y\\) 的影响 6.5 残差 模型 \\(Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i\\) 预测值 \\(\\hat Y_i = \\hat \\beta_0 + \\hat \\beta_1 X_i\\) \\(e_i = Y_i - \\hat Y_i\\) 观察数据与回归线的垂直距离 最小二乘估计最小化残差 \\(\\sum_{i=1}^n e_i^2\\) 残差 \\(e_i\\) 可看作 \\(\\epsilon_i\\) 的估计 可证 \\(E[e_i] = 0\\) 模型中考虑截距 \\(\\sum_{i=1}^n e_i = 0\\) 考虑自变量 \\(\\sum_{i=1}^n e_i X_i = 0\\) 残差可用来评价模型效果 残差波动不同于模型波动 残差波动 \\(\\sigma^2\\) 的极大似然估计为 \\(\\frac{1}{n}\\sum_{i=1}^n e_i^2\\) \\(\\hat \\sigma^2 = \\frac{1}{n-2}\\sum_{i=1}^n e_i^2\\) 为无偏估计 \\[\\begin{align} \\sum_{i=1}^n (Y_i - \\bar Y)^2 &amp; = \\sum_{i=1}^n (Y_i - \\hat Y_i + \\hat Y_i - \\bar Y)^2 \\\\ &amp; = \\sum_{i=1}^n (Y_i - \\hat Y_i)^2 + 2 \\sum_{i=1}^n (Y_i - \\hat Y_i)(\\hat Y_i - \\bar Y) + \\sum_{i=1}^n (\\hat Y_i - \\bar Y)^2 \\\\ \\end{align}\\] 其中 \\((Y_i - \\hat Y_i) = \\{Y_i - (\\bar Y - \\hat \\beta_1 \\bar X) - \\hat \\beta_1 X_i\\} = (Y_i - \\bar Y) - \\hat \\beta_1 (X_i - \\bar X)\\) \\((\\hat Y_i - \\bar Y) = (\\bar Y - \\hat \\beta_1 \\bar X - \\hat \\beta_1 X_i - \\bar Y )= \\hat \\beta_1 (X_i - \\bar X)\\) 有\\(\\sum_{i=1}^n (Y_i - \\hat Y_i)(\\hat Y_i - \\bar Y) = \\sum_{i=1}^n \\{(Y_i - \\bar Y) - \\hat \\beta_1 (X_i - \\bar X))\\}\\{\\hat \\beta_1 (X_i - \\bar X)\\}=\\hat \\beta_1 \\sum_{i=1}^n (Y_i - \\bar Y)(X_i - \\bar X) -\\hat\\beta_1^2\\sum_{i=1}^n (X_i - \\bar X)^2= \\hat \\beta_1^2 \\sum_{i=1}^n (X_i - \\bar X)^2-\\hat\\beta_1^2\\sum_{i=1}^n (X_i - \\bar X)^2 = 0\\) 综上 \\(\\sum_{i=1}^n (Y_i - \\bar Y)^2 = \\sum_{i=1}^n (Y_i - \\hat Y_i)^2 + \\sum_{i=1}^n (\\hat Y_i - \\bar Y)^2\\) 有 Total Variation = Residual Variation + Regression Variation 模型解释部分\\(R^2 = \\frac{\\sum_{i=1}^n (\\hat Y_i - \\bar Y)^2}{\\sum_{i=1}^n (Y_i - \\bar Y)^2} = 1 - \\frac{\\sum_{i=1}^n (Y_i - \\hat Y_i)^2}{\\sum_{i=1}^n (Y_i - \\bar Y)^2}\\) 已知 \\((\\hat Y_i - \\bar Y) = \\hat \\beta_1 (X_i - \\bar X)\\) \\(\\hat \\beta_1 = Cor(Y, X)\\frac{Sd(Y)}{Sd(X)}\\) 有 \\(R^2 = \\frac{\\sum_{i=1}^n (\\hat Y_i - \\bar Y)^2}{\\sum_{i=1}^n (Y_i - \\bar Y)^2}= \\hat \\beta_1^2 \\frac{\\sum_{i=1}^n(X_i - \\bar X)^2}{\\sum_{i=1}^n (Y_i - \\bar Y)^2}= Cor(Y, X)^2\\) \\(R^2\\) 实际上是相关性 \\(r\\) 的平方 &lt;- 线性模型的可解释性 \\(R^2\\) 会伴随样本数增加而增加 会因删除异常值而增加 data(anscombe);example(anscombe) 小恐龙变换 6.6 回归推断 \\(\\frac{\\hat \\theta - \\theta}{\\hat \\sigma_{\\hat \\theta}}\\) 总符合正态分布或\\(t\\)分布 假设检验 \\(H_0 : \\theta = \\theta_0\\) 与 \\(H_a : \\theta &gt;, &lt;, \\neq \\theta_0\\) 置信区间 \\(\\theta\\) 通过 \\(\\hat \\theta \\pm Q_{1-\\alpha/2} \\hat \\sigma_{\\hat \\theta}\\) 构建 \\[\\begin{align} Var(\\hat \\beta_1) &amp; = Var\\left(\\frac{\\sum_{i=1}^n (Y_i - \\bar Y) (X_i - \\bar X)}{\\sum_{i=1}^n (X_i - \\bar X)^2}\\right) \\\\ &amp; = \\frac{Var\\left(\\sum_{i=1}^n Y_i (X_i - \\bar X) \\right) }{\\left(\\sum_{i=1}^n (X_i - \\bar X)^2 \\right)^2} \\\\ &amp; = \\frac{\\sum_{i=1}^n \\sigma^2(X_i - \\bar X)^2}{\\left(\\sum_{i=1}^n (X_i - \\bar X)^2 \\right)^2} \\\\ &amp; = \\frac{\\sigma^2}{\\sum_{i=1}^n (X_i - \\bar X)^2} \\\\ \\end{align}\\] \\(\\sigma_{\\hat \\beta_1}^2 = Var(\\hat \\beta_1) = \\sigma^2 / \\sum_{i=1}^n (X_i - \\bar X)^2\\) \\(\\sigma_{\\hat \\beta_0}^2 = Var(\\hat \\beta_0) = \\left(\\frac{1}{n} + \\frac{\\bar X^2}{\\sum_{i=1}^n (X_i - \\bar X)^2 }\\right)\\sigma^2\\) 这样 \\(\\frac{\\hat \\beta_j - \\beta_j}{\\hat \\sigma_{\\hat \\beta_j}}\\) 遵守自由度为\\(n-2\\)的\\(t\\)分布或正态分布 在\\(x_0\\) 回归线的标准误 \\(\\hat \\sigma\\sqrt{\\frac{1}{n} + \\frac{(x_0 - \\bar X)^2}{\\sum_{i=1}^n (X_i - \\bar X)^2}}\\) 在\\(x_0\\) 预测值的标准误 \\(\\hat \\sigma\\sqrt{1 + \\frac{1}{n} + \\frac{(x_0 - \\bar X)^2}{\\sum_{i=1}^n (X_i - \\bar X)^2}}\\) CI代表回归线在特定\\(x\\)处的变动 PI代表预测值在此处的变动 前者在回归线固定时不变 后者还要考虑预测值围绕回归线的变动 The prediction interval is the range in which future observation can be thought most likely to occur, whereas the confidence interval is where the mean of future observation is most likely to reside. From here 6.7 多元回归 线性模型 \\(Y_i = \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\ldots + \\beta_{p} X_{pi} + \\epsilon_{i} = \\sum_{k=1}^p X_{ik} \\beta_j + \\epsilon_{i}\\) 最小化 \\(\\sum_{i=1}^n \\left(Y_i - \\sum_{k=1}^p X_{ki} \\beta_j\\right)^2\\) 最小二乘估计也是误差正态化的极大似然估计 最小二乘估计等价于 \\(\\sum_{i=1}^n (Y_i - X_{1i}\\hat \\beta_1 - \\ldots - X_{ip}\\hat \\beta_p) X_k = 0\\) 本质上使其他参数固定解出一个 然后逐级代入 最后全部解出参数值 参考线性代数 参数代表固定其他参数后变动一个单位引发的变化 方差估计 \\(\\hat \\sigma^2 = \\frac{1}{n-p} \\sum_{i=1}^n e_i ^2\\) 参数标准误\\(\\hat \\sigma_{\\hat \\beta_k}\\) \\(\\frac{\\hat \\beta_k - \\beta_k}{\\hat \\sigma_{\\hat \\beta_k}}\\) 符合自由度 \\(n-p\\) 的 \\(T\\) 分布 多元模型中加入变量会导致原有变量的参数估计发生变化 甚至方向相反 一般是由于加入变量与原有变量存在共相关 导致两者参数估计都不准 n &lt;- 100; x2 &lt;- 1 : n; x1 &lt;- .01 * x2 + runif(n, -.1, .1); y = -x1 + x2 + rnorm(n, sd = .01) summary(lm(y ~ x1))$coef summary(lm(y ~ x1 + x2))$coef R 会自动检测并消除变量生成的变量 如上面 x2 中需要加入 runif(n,-.1,.1) 才能得到结果 多元模型中包括分类变量考虑加入虚拟变量 \\(Y_i = \\beta_0 + X_{i1} \\beta_1 + \\epsilon_{i}\\) 属于该分类时 \\(E[Y_i] = \\beta_0 + \\beta_1\\) 否则为\\(E[Y_i] = \\beta_0\\) 分类变量截距有意义 代表其中一个分类 等同于其他分类与该分类进行 t 检验 如果模型中去掉截距 等同于所有分类与零进行 t 检验 参数系数为均值差 可用 relevel(data,'name') 来指定比对对象 两变量均值差的标准误通过 \\(Var(\\hat \\beta_B - \\hat \\beta_C) = Var(\\hat \\beta_B) + Var(\\hat \\beta_C) - 2 Cov(\\hat \\beta_B, \\hat \\beta_C)\\) 来计算进行推断 交互作用 \\(E[Y_i | X_{1i}=x_1, X_{2i}=x_2] = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + \\beta_3 x_{1}x_{2}\\) 中交互作用参数实际表示 \\(E[Y_i | X_{1i}=x_1+1, X_{2i}=x_2+1]-E[Y_i | X_{1i}=x_1, X_{2i}=x_2+1]-E[Y_i | X_{1i}=x_1+1, X_{2i}=x_2]-E[Y_i | X_{1i}=x_1, X_{2i}=x_2] =\\beta_3\\) 各交互参数变化一单位响应变化 多元回归的参数解释需要考虑清楚变量类型与交互作用 多元回归中变量与响应 变量与变量间的相关性要全盘考虑 通过模拟观察决定 6.8 模型诊断与选择 通过残差诊断 最小二乘决定均值为零 方差通过 \\(\\hat \\sigma^2 = \\frac{\\sum_{i=1}^n e_i^2}{n-p}\\) 进行无偏估计 异常值判断 对回归关系包括系数与其标准误的影响 残差的分布检验等 ?influence.measures There are known knowns. These are things we know that we know. There are known unknowns. That is to say, there are things that we know we don’t know. But there are also unknown unknowns. There are things we don’t know we don’t know. Donald Rumsfeld 随机化有助于平衡未知变量 杠杆点 加入前后与回归线距离差的比值 参数方差膨胀 共相关或随机相关 vif来检验 协变量在欠拟合下有偏 协变量的选择需要专业知识与经验 6.9 广义线性模型 Nelder 与 Wedderburn 1972年提出 响应是指数家族模型 模型组成部分是线性的 线性预测变量与响应通过连接函数联系 线性模型 \\(Y_i \\sim N(\\mu_i, \\sigma^2)\\) \\(\\eta_i = \\sum_{k=1}^p X_{ik} \\beta_k\\) \\(g(\\mu) = \\eta\\) 似然模型为 \\(Y_i = \\sum_{k=1}^p X_{ik} \\beta_k + \\epsilon_{i}\\) \\(\\epsilon_i \\stackrel{iid}{\\sim} N(0, \\sigma^2)\\) logistic 模型 \\(Y_i \\sim Bernoulli(\\mu_i)\\) \\(\\eta_i = \\sum_{k=1}^p X_{ik} \\beta_k\\) \\(g(\\mu) = \\eta = \\log\\left( \\frac{\\mu}{1 - \\mu}\\right)\\) \\(g\\)为logit函数 似然函数为 \\(\\prod_{i=1}^n \\mu_i^{y_i} (1 - \\mu_i)^{1-y_i} = \\exp\\left(\\sum_{i=1}^n y_i \\eta_i \\right) \\prod_{i=1}^n (1 + \\eta_i)^{-1}\\) 泊松模型 \\(Y_i \\sim Poisson(\\mu_i)\\) \\(\\eta_i = \\sum_{k=1}^p X_{ik} \\beta_k\\) \\(g(\\mu) = \\eta = \\log(\\mu)\\) 似然函数为 \\(\\prod_{i=1}^n (y_i !)^{-1} \\mu_i^{y_i}e^{-\\mu_i}\\propto \\exp\\left(\\sum_{i=1}^n y_i \\eta_i - \\sum_{i=1}^n \\mu_i\\right)\\) 似然函数与数据的联系 \\(\\sum_{i=1}^n y_i \\eta_i = \\sum_{i=1}^n y_i\\sum_{k=1}^p X_{ik} \\beta_k = \\sum_{k=1}^p \\beta_k\\sum_{i=1}^n X_{ik} y_i\\) 只有\\(\\sum_{i=1}^n X_{ik} y_i\\) 极大似然估计的解 \\(0=\\sum_{i=1}^n \\frac{(Y_i - \\mu_i)}{Var(Y_i)}W_i\\) \\(W_i\\)是连接函数的反函数的微分 响应的方差中线性模型 \\(Var(Y_i) = \\sigma^2\\) 是常数 logistic 模型 \\(Var(Y_i) = \\mu_i (1 - \\mu_i)\\) 泊松模型 \\(Var(Y_i) = \\mu_i\\) 可通过对模型方差增加调谐参数 \\(\\phi\\) 使模型更灵活 quasi-likelihood 模型求解为 \\(\\hat \\beta_k\\) 及可能的 \\(\\hat \\phi\\) 线性预测变量关系 \\(\\hat \\eta = \\sum_{k=1}^p X_k \\hat \\beta_k\\) 平均响应 \\(\\hat \\mu = g^{-1}(\\hat \\eta)\\) 系数解释 \\(g(E[Y | X_k = x_k + 1, X_{\\sim k} = x_{\\sim k}]) - g(E[Y | X_k = x_k, X_{\\sim k}=x_{\\sim k}]) = \\beta_k\\) 贝叶斯视角下就是预设不同参数的分布，然后用数据更新参数的分布 如果每一个响应受到来自于一个分布的随机效应的影响，例如个体基线不同，那么就可以构建随机效应模型来模拟，有时参数的系数也可能来自于一个分布而非固定 6.10 二元响应 \\(\\log\\left(\\frac{\\rm{Pr}(RW_i | RS_i, b_0, b_1 )}{1-\\rm{Pr}(RW_i | RS_i, b_0, b_1)}\\right) = b_0 + b_1 RS_i\\) \\(b_0\\) 预测变量为零时胜率对数 \\(b_1\\) 预测变量变化一个单位胜率的改变对数 \\(\\exp(b_1)\\) 预测变量变化一个单位胜率的改变 6.11 计数或速率响应 \\(\\log\\left(E[NH_i | JD_i, b_0, b_1]\\right) = b_0 + b_1 JD_i\\) \\(e^{E[\\log(Y)]}\\) \\(Y\\) 的几何平均值 \\(e^{\\beta_0}\\) 第零天的几何平均值 \\(e^{\\beta_1}\\) 每天相对增加或减少的几何平均值 通过设置 offset 可用来估计增长率 注意方差膨胀与零膨胀问题 6.12 分段平滑 可用线性回归拟合曲线 原理是分段拟合连接 断点平滑可用二次项 分段项可看作基进行组合 "],["opt.html", "第7章 最优化 7.1 数学本质 7.2 简史 7.3 最小二乘法 7.4 线性规划 7.5 凸优化 7.6 仿射集", " 第7章 最优化 7.1 数学本质 当\\(f_i(x)\\leq b_i,(i = 1,...,m)\\)时，最小化\\(f_0(x)\\)。也就是满足限制条件下最小化某函数时其变量\\(x\\)的取值。 7.2 简史 1900-1970 理论发展期 1947，Dantzig 提出线性规划的 simplex 算法 1960s，早期插值方法 1970s，椭球法与其他亚梯度方法 1980s，线性规划的多项式时间插值法 1990之前主要运筹学里用，后来用到工程里 1990年后，应用于工程 现在，非线性凸优化的多项式时间内点法 7.3 最小二乘法 最小化\\(||Ax-b||_2^2\\)，其解析解为\\(x^\\star = (A^TA)^{-1}A^Tb\\)，该算法比较成熟，计算时间正比于\\(n^2k(A\\in R^{k\\times n})\\) 7.4 线性规划 线性规划问题没有解析解，求解算法比较成熟，如果\\(m\\geq n\\),求解时间正比于\\(n^2m\\) 7.5 凸优化 将问题转化为凸函数\\(f_i(\\alpha x+\\beta y)\\geq \\alpha f_i(x)+\\beta f_i(y)\\) ，如果\\(\\alpha + \\beta = 1\\)，\\(\\alpha \\geq 0, \\beta\\geq 0\\)，最小二乘法与线性规划是凸优化的特殊形式。 求解凸优化问题没有解析解，求解时间正比于 \\(max\\{ n^3,n^2m,F\\}\\)，\\(F\\)是求函数一阶与二阶导数的时间，实际问题转化为凸优化问题不容易发现但确实可以求解。 7.6 仿射集 \\[x = \\theta x_1 + (1-\\theta)x2\\] 仿射集：穿过任意两点的线的集合 凸集：仿射集里的线性片段 $0\\leq \\theta \\leq 1$ 凸组合 \\[x = \\theta_1 x_1 + \\theta_2 x_2+...+\\theta_kx_k, \\theta_1+\\theta_2+...+\\theta_k = 1, \\theta_i\\geq0\\] 超平面 \\[{x|a^Tx = b}(a\\neq 0)\\] 半空间\\[{x|a^Tx \\leq b}(a\\neq 0)\\] 超平面与半空间都是凸的 "],["mlsl.html", "第8章 统计模型 8.1 统计学习概论 8.2 统计学习简史 8.3 统计学习定义 8.4 预测 8.5 推断 8.6 估计模型 8.7 评价模型 8.8 研究设计 8.9 错误率 8.10 ROC 曲线 8.11 重采样技术 8.12 caret 包 8.13 数据分割 8.14 训练选项 8.15 预测变量作图 8.16 数据预处理 8.17 协变量生成 8.18 线性回归&amp;多元线性回归 8.19 非线性 8.20 树 8.21 支持向量机 8.22 无监督学习 8.23 人工神经网络 8.24 模型联合 8.25 无监督预测 8.26 模型预测 8.27 模型可视化", " 第8章 统计模型 8.1 统计学习概论 统计学习：理解数据的工具集 监督学习：有因变量，根据自变量预测估计因变量 非监督学习：无因变量，探索自变量间的关系与结构 8.2 统计学习简史 19世纪初，Legendre 与 Gauss 发表了最小二乘法的论文，该方法首先应用在天文学领域 1936年，Fisher 提出线性判别分析来解决定性分析问题 1940s，logistic回归提出 1970s，Nelder 与 Wedderburn 提出广义线性模型，将线性回归与logistic回归统一到一个体系 1980s，计算机技术进步，非线性问题开始得到解决 Breiman，Friedman，Olshen 与 Stone 提出回归树与聚类，提供交叉检验方法 1986年，Hastie 与 Tibshirani 提出广义加性模型，将广义线性模型与一些非线性模型同一到一个体系 伴随软件，机器学习与其他理论的发展，统计学习作为统计学子学科快速发展 8.3 统计学习定义 \\(Y = f(X) + \\epsilon\\) 统计学习本质上是在寻找最合适的f来进行预测与推断 8.4 预测 \\(\\hat Y = \\hat f(X)\\)，\\(\\hat f(X)\\) 通常看作黑箱 \\(\\hat Y\\)预测\\(Y\\)需要考虑两部分误差：可约误差与不可约误差 可约误差指\\(\\hat f\\)推断\\(f\\)上的偏差 不可约误差指由\\(\\epsilon\\)引入的误差 误差的期望 \\(E(Y - \\hat Y)^2 = [f(x) - \\hat f(x)]^2 + Var(\\epsilon)\\) (证明用到\\(E(Y)\\)) 8.5 推断 关注X与Y的关系，\\(\\hat f(X)\\) 通常有明确的形式 自变量因变量是否相关 如何相关 关系的数学描述 8.6 估计模型 使用训练集与验证集 参数方法与非参数方法 模型的欠拟合与过拟合，回归模型低方差高偏差，邻近聚类高方差低偏差 权衡模型的准确性（预测）与可解释性（推断） 模型的奥卡姆剃刀与黑箱 8.7 评价模型 8.7.1 拟合质量测量 训练集均方误 \\(MSE_{Tr} = Ave_{i \\in Tr}[y_{i} − \\hat f(x_i)]^2\\) 测试集均方误 \\(MSE_{Te} = Ave_{i \\in Te}[y_{i} − \\hat f(x_i)]^2\\) 测试集均方误源于训练集拟合模型的方差，误差项\\(\\epsilon\\)的方差及模型误差的平方三部分 8.7.2 聚类评价 错误率 \\(Err_{Te} = Ave_{i \\in Te}I[y_i \\neq \\hat C(x_i)]\\) 贝叶斯分类器：错误率最小的分类器，使x属于某个分类的概率最大 k临近值聚类：距离最小的k个为一类所产生的分类器 问题 -&gt; 数据 -&gt; 特征 -&gt; 算法 -&gt; 参数 -&gt; 评价 The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data. John Tukey 数据质量优先于模型 不要自动特征选择 算法的可扩展性与计算性能要考虑 数据过拟合问题 数据总是由信号与噪音组成 但会被算法无差别对待 数据要与问题相关 低相关度的组合可能产生高相关度 8.8 研究设计 定义错误率 将数据分割为训练集 预测集 验证集 在训练集上使用交叉检验选择特征与预测算法 在预测集或验证集上使用一次数据 预测效果起码要优于瞎猜 避免使用小样本 比例为 60% 训练集 20% 预测集 20% 验证集 或 60% 训练集 40% 预测集 或小样本交叉检验 注意数据结构 时序分析要对数据分段采样 8.9 错误率 真阳性 真的是对的 TP 假阳性 真的是错的 FP Type I 真阴性 假的是错的 TN 假阴性 假的是对的 FN Type II 灵敏度 TP/(TP+FP) 特异性 TN/(TN+FN) 均方差 MSE \\(\\frac{1}{n} \\sum_{i=1}^n (Prediction_i - Truth_i)^2\\) 均方误 RMSE \\(\\sqrt{\\frac{1}{n} \\sum_{i=1}^n(Prediction_i - Truth_i)^2}\\) 中位差 Median absolute deviation 准确性 (TP+TN)/(TP+FP+TN+FP) 一致性 kappa值 8.10 ROC 曲线 分类问题寻找判别阈值 满足一定TP下最小FP的模型 FP v.s.TP 作图 AUC 曲线下面积表示选择标准 一般超过80% 对角线是随机猜的结果 8.11 重采样技术 8.11.1 交叉检验 训练集上的操作 训练集上再分为训练集与测试集 在测试集上评价 重复并平均化测试集错误 用来进行变量 模型 参数选择 随机 分组 留一 分组多方差大 分组少有偏差 有放回的为bootstrap 不建议用 核心思想：通过保留一部份训练集数据作为检验集来估计真实检验集的错误率与模型拟合效果 验证集方法：将训练集数据分为两部分，一部份拟合模型，一部份检验模型，这样得到的错误率为真实检验集的一个估计，选取错误率较低的模型建模 验证集方法缺点：错误率依赖于采样变动较大，训练集少，高估了错误率 留一法(LOOCV)：每次建模留一个数据点作为验证集，\\(MSE_i = (y_i - \\hat y_i)^2\\)重复n次，得到一个CV值作为对错误率的估计:\\(CV_{(n)} = \\frac{1}{n} \\sum_{i = 1}^{n} MSE_i\\) 留一法优点：使用数据量大，偏差小；结果唯一，不受随机化影响 留一法缺点：计算量大，公式插入杠杆统计量调节杠杆点对方程拟合的影响，得到\\(CV_{(n)} = \\frac{1}{n} \\sum_{i = 1}^{n} (\\frac{y_i - \\hat y_i}{1 - h_i})^2\\) k叠交叉检验：将训练集分为k叠，每次建模用(k-1)叠，用1叠检验 k叠交叉检验优点：计算量小，结果与留一法相差不多- 交叉检验的结果用来寻找\\(CV\\)值最小的点来选择模型，通常与真实检验集最小点结果相差不大乎，但交叉检验给出的\\(MSE\\)会偏低 偏差方差权衡：使用的训练集数据越多，估计偏差越小，方差越大（相关性越高的方差越大） 分类问题使用错误率计算\\(CV\\)：\\(CV{(n)} = \\frac{1}{n} \\sum_{i = 1}^{n} Err_{i}\\) 少n多p问题上使用交叉检验，不可先进行全模型变量选择再交叉检验，应该对整个过程交叉检验 8.11.2 bootstrap 在训练集里有放回的重采样等长的数据形成新的数据集并计算相关参数，重复n次得到对参数的估计，计算标准误 生成Bootstrap Percentile置信区间 适用于独立样本，样本间有相关如时间序列数据可采用block法分组屏蔽掉进行bootstrap 因为存在重复，使用bootstrap建立训练集与预测集会有非独立样本，造成检验集模型方差的低估，去掉重复使模型复杂，不如交叉检验对检验集误差估计的准 slipper 包 8.12 caret 包 数据清洗 预处理 数据分割 createDataPartition 数据比例 重采样 产生时间片段 训练检验整合函数 train predict 模型对比 算法整合为选项 线性判别 回归 朴素贝叶斯 支持向量机 分类与回归树 随机森林 Boosting 等 8.13 数据分割 train &lt;- createDataPartition(y=spam$type,p=0.75, list=FALSE) 数据三一分 得到index folds &lt;- createFolds(y=spam$type,k=10,list=TRUE,returnTrain=TRUE) 数据分10份 返回每一份列表 folds &lt;- createResample(y=spam$type,times=10,list=TRUE) 数据bootstrap重采样 返回每一份列表 folds &lt;- createTimeSlices(y=tme,initialWindow=20,horizon=10) 时序数据重采样 产生20为窗口时序片段的训练集与预测集 8.14 训练选项 args(train.default) 通过 method 控制算法 metric 控制算法评价 trainControl 控制训练方法 trainControl中 method选择模型选择方法 如bootstrap 交叉检验 留一法 number 控制次数 repeats 控制重采样次数 seed 控制可重复性 总体设置一个 具体每一次用列表设置控制具体过程 特别是并行模型 8.15 预测变量作图 featurePlot ggplot2 8.16 数据预处理 train 中的 preProcess=c(\"center\",\"scale\") 标准化 spatialSign 该转化可提高计算效率 有偏 preProcess(training[,-58],method=c(\"BoxCox\")) 正态化转化 method=\"knnImpute\" 用最小邻近法填补缺失值 nearZeroVar 去除零方差变量 findCorrelation 去除相关变量 findLinearCombos 去除线性组合变量 classDist 测定分类变量的距离 生成新变量 测试集也要预处理 8.17 协变量生成 原始数据提取特征 提取特征后生成新变量 因子变量要转为虚拟变量 样条基变量 splines 包中的 bs 数据压缩 preProcess 中 method 设置为 pca pcaComp 指定主成分个数 8.18 线性回归&amp;多元线性回归 \\(ED_i = b_0 + b_1 WT_i + e_i\\) 基本模型 参见前面回归部分 8.18.1 简单线性回归 \\(Y \\approx \\beta_0 + \\beta_1 X\\) 用最小二乘法估计\\(\\beta_0\\)与\\(\\beta_1\\)得到估计值\\(\\hat \\beta_0\\)与\\(\\hat \\beta_1\\)，代入\\(X\\)，得到模型估计值\\(\\hat Y\\) 残差平方和：\\(RSS = e_1^2 + e_2^2 + ... + e_n^2\\)，使RSS最小，求导可得参数 回归线不等于最小二乘线，最小二乘线是通过采样对回归线的估计 估计会存在偏差，均值的偏差用标准误来描述\\(Var(\\hat \\mu) = SE(\\mu)^2 = \\frac{\\sigma^2}{n}\\) 回归参数的估计也涉及标准误的计算\\(Var(\\beta_{1}) = \\frac{\\sigma^2}{\\sum_{i=1}^n{(x_i - \\bar{x})^2}}\\) \\(\\sigma^2\\)可用残差标准误RSE(\\(RSE = RSS/(n − 2)\\))来估计\\(\\qquad\\hat\\sigma^2 = \\frac{n-p}{n}\\;s^2\\) 据此可得回归参数的95%置信区间\\(\\hat \\beta_1 ± 2 \\cdot SE(\\hat \\beta_1)\\) 参数的评价可通过假设检验进行，零假设为\\(\\beta_1\\)为0，也就是自变量对因变量无影响，构建t统计量\\(t = \\frac{\\hat \\beta_1 - 0}{\\hat {SE}(\\hat \\beta_1)}\\)，然后可根据p值判断参数的显著性 评价参数后需要评价模型，主要通过\\(RSE\\)与\\(R^2\\)来进行 \\(R^2\\)表示模型所解释总体方差的比例，与\\(RSE\\)不同，独立于Y，\\(R^2 = \\frac{TSS - RSS}{TSS}\\) \\(R^2\\)与两变量间的相关系数是一致的，但\\(R^2\\)统计量的应用面要广于相关系数 相关系数也可进行假设检验进而判断相关的显著性 8.18.2 多元线性回归 通过统计量F检验确定回归是否显著，零假设为所有自变量系数为0 \\(F = \\frac{(TSS - RSS)/p}{RSS/(n-p-1)}\\) 变量选择：向前选择（从0个到p个，显著则包含），向后选择（从p个到0个，不显著则剔除），混合选择（通过p的阈值调节） 因为RSS会减少，\\(R^2\\)会伴随自变量数目的增加而增加 \\(RSE\\)在多元线性线性回归中为\\(RSE = RSS/(n − p - 1)\\)，伴随自变量个数增加影响超过\\(RSS\\)减少的影响，\\(RSE\\)会增大 自变量间的影响会导致相比单一变量预测更容易出现不显著，这说明自变量间有可能可相互解释 预测的置信区间与预测区间，前者指模型的变动范围，后者指某个预测值的变动范围，考虑真值本身的变动，后者大于前者 因子变量通过对每个水平添加系数0，1来回归，也可根据需要赋值 8.18.3 线性模型延拓 线性模型基本假设：可加性与线性 去掉可加性：考虑交互作用 层级原理：交互作用项显著而主作用不显著时不可去掉主作用项 去掉线性：多项式回归 8.18.4 常见问题 关系非线性：残差图判断 误差项共相关：误差项的相关会导致标准误估计偏低，低估参数的区间使不显著差异变得显著，考虑时间序列数据，观察误差项轨迹判断 误差项方差非常数：喇叭状残差图，通过对因变量进行对数或开方来收敛方差，或者用加权最小二乘 异常值：通过标准化残差图判断 杠杆点：加入后会影响模型拟合，通过杠杆统计量判断： \\(h_i = \\frac{1}{n} + \\frac{(x_i - \\bar x)^2}{\\sum_{i&#39; = 1}^{n} (x_i&#39; - \\bar x)^2}\\) 多元回归中该统计量均值为\\((p+1)/n\\)，超过很多则可能为杠杆点 在标准残差-杠杆值图中，右上或右下方为危险值，左方数值对回归影响不大 共线性：共线性的变量相互可替代，取值范围扩大，标准误加大，对因变量影响相互抵消，降低参数假设检验的功效 多重共线性：引入方差膨胀因子，自变量引入全模型与单一模型方差的比值，超过5或10说明存在共相关，\\(VIF(\\hat \\beta_j) = \\frac{1}{1 - R^2_{X_j|X_{-j}}}\\) 解决共线性：丢弃变量或合并变量 共线性不同于交互作用 8.18.5 线性回归与kmeans算法比较 k临近算法：\\(\\hat f(x_0) = \\frac{1}{K} \\sum_{x_i \\in N_0} y_i\\) 核心是选择k KNN算法在解决非线性问题上有优势，但一样的面对高维诅咒 线性回归可给出可解释的形式与简单的描述 8.18.6 logistic回归 因变量以概率形式出现 \\(p(X) = \\frac {e^{\\beta_0 + \\beta_1 X}}{1 + e^{\\beta_0 + \\beta_1 X}}\\) 变形后\\(\\frac {p(X)}{1 - p(X)}\\) 为胜率，比概率应用更实际些，去对数后为对数胜率（logit） 因变量\\(p(X)\\)与自变量间关系非线性 用极大似然估计确定参数，似然函数为\\(l(\\beta_0, \\beta_1) = \\prod_{i:y_i = 1} p(x_i)\\prod_{i&#39;:y_{i&#39;} = 0} (1 - p(x_{i&#39;}))\\)，该函数取最大值 线性回归中，最小二乘法为极大似然估计的特例 混杂因素的解释上要考虑单因素回归与多元回归 多响应logistic回归一般被判别分析取代 8.18.7 线性判别分析 使用原因：分类离散时logistic回归不稳定，n小X正态时更稳定，适用于多响应 贝页斯理论：\\(Pr(Y = k|X = x) = \\frac{\\pi_k f_k(x)}{\\sum_{l = 1}^K \\pi_lf_l(x)}\\) 其中\\(\\pi\\) 代表先验概率，估计\\(f_k(X)\\)需要对\\(x\\)的分布作出假设 自变量为1时，假定\\(f_k(x)\\)分布为正态的，有\\(f_k(x) = \\frac{1}{\\sqrt{2 \\pi} \\sigma_k} exp(- \\frac{1}{2 \\sigma_k^2} (x - \\mu_k)^2)\\)，代入可得\\(p_k(x)\\)，取对数有\\(\\sigma_k(x) = x \\cdot \\frac{\\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2\\sigma^2} + log(\\pi_k)\\)，使\\(\\sigma_k(x)\\)最大的分类方法为判定边界 贝页斯分类器需要知道所有分布参数，实际中会采用线性判别分析（LDA），通过以下训练集估计方法来插入贝页斯分类器：\\(\\hat \\pi_k = n_k/n\\)、\\(\\hat \\mu_k = \\frac{1}{n_k} \\sum_{i:y_i = k} x_i\\) 与 \\(\\hat \\sigma^2 = \\frac{1}{n - K} \\sum_{k = 1}^K \\sum_{i:y_i = k} (x_i - \\hat \\mu_k)^2\\) 线性体现在判别函数\\(\\hat \\sigma_k(x)\\)的形式是线性的 自变量多于1时，假设自变量均来自多元正态分布的分类 列连表，表示假阳性，假阴性，可计算灵敏度与特异性 LDA是对贝页斯分类的模拟，旨在降低总错误率，因此灵敏度与特异性区分并不明显，可根据实际需要调节 ROC曲线用来展示两种错误，横坐标假阳性，纵坐标真阳性 8.18.8 二次判别分析（QDA）及其它 不同于LDA，二次判别分析考虑各分类参数中方差不同而不是相同，引入了二次项 对分类描述更为精细，但容易过拟合，样本较少，LDA优先 对比logistic回归，两者数学形式相近，取值上logistic回归使用极大似然法，LDA使用共方差的高斯分布假设，结论多数条件一致，但随假设不同而不同 KNN更适用于非线性关系，标准化很有必要，QDA相对温和 8.18.9 线性模型选择与正则化 最小二乘法（OLS）容易解释，预测性能好，但不万能 预测准确性上，当p&gt;n时，模型方差变大 模型解释上，p过多需要去除，进行模型选择 8.18.9.1 子集选择 从p个自变量中选出与模型响应相关的进行建模 使用devianc，最大化为最优子集 最佳子集选择：p个自变量\\(p \\choose k\\) ，计算\\(RSS\\)与\\(R^2\\)，\\(RSS\\)要小，\\(R^2\\)要大，选择最佳的 步进法：p值过大，计算负担重，采用逐步改进法进行模型选择 向前步进选择：从0个自变量开始加，第k个自变量选择p-k个模型，如果\\(RSS\\)与\\(R^2\\)表现好就保留，递近选择变量，不保证选择最佳模型，p值较大优先考虑 向后步进选择：从p个自变量开始减，如果第k个自变量在模型\\(RSS\\)与\\(R^2\\)中没表现，就剔除进行变量选择，不保证选择最佳模型，适用于p值较小的情况(较大可能无法拟合) 步进选择构建\\(1 + p(p+1)/2\\)个模型，最佳子集法需要构建\\(2^p\\)个模型 混合模型:向前选择，之后向后验证，剔除不再提高效果的模型 8.18.9.2 测试集误差估计 \\(RSS\\)与\\(R^2\\)评价的是训练集拟合状况，不适用于估计测试集误差 估计测试集误差可以构建统计量调节训练集误差或直接通过验证集来估计 Mallow’s \\(C_p\\)：\\(C_p = \\frac{1}{n} (RSS + 2d\\hat \\sigma^2)\\) \\(d\\)代表使用的变量数，\\(\\hat \\sigma^2\\)是对模型方差的估计 AIC：\\(AIC = -2logL + 2 \\cdot d\\) 极大似然估计，线性模型下\\(C_p\\)与AIC实质等同 BIC：\\(BIC = \\frac{1}{n}(RSS + log(n)d\\hat \\sigma^2)\\) n是样本数，大于7时BIC会比\\(C_p\\)选择更轻量的模型 调节\\(R^2\\)：\\(Adjusted\\) \\(R^2 = 1 - \\frac{RSS/n-d-1}{TSS/(n - 1)}\\) 值越大，测试集误差越小 不同于\\(C_p\\)，AIC，BIC有严格的统计学意义，调节\\(R^2\\)虽然直观，但理论基础相对薄弱，单纯考虑了对无关变量的惩罚 验证与交叉验证：直接估计测试集误差而不用估计模型方差 单标准误原则：先计算不同规模测试集\\(MSE\\)的标准差，选择曲线中最小测试集误差一个标准误内最简单的模型 8.18.9.3 收缩 对系数估计进行收缩，接近0或等于0进行变量选择 8.18.9.3.1 岭回归 不同于最小二乘估计对\\(RSS\\)的最小化，岭回归最小化\\(RSS + \\lambda \\sum_{j = 1}^{p} \\beta_j^2\\)，其中\\(\\lambda\\)为调谐参数，后面一项为收缩惩罚，是个\\(l_2\\)范数，使参数估计逼近0，选择合适\\(\\lambda\\)很重要，可用交叉检验来实现 因为范数大小影响模型惩罚项，所以进行岭回归前要做标准化处理\\[\\bar x_{ij} = \\frac{x_{ij}}{\\sqrt{\\frac{1}{n} \\sum_{i = 1}^n (x_{ij} - \\bar x_j)^2}}\\] 岭回归的参数\\(\\lambda\\)与范数收缩状况可看作最小\\(MSE\\)的函数来表现偏差-误差均衡 岭回归适用于最小二乘回归产生方差较大的情况，同时，计算负担较小，只伴随\\(\\lambda\\)取值范围变化而变化 8.18.9.3.2 Lasso 形式与岭回归一致，最小化\\(RSS + \\lambda \\sum_{j = 1}^{p} |\\beta_j|\\)，使用\\(l_1\\)范数 岭回归参数同步收缩接近0，Lasso可以通过软边界直接收缩到0实现变量选择，产生稀疏模型，想像超球体与超多面体与超球面的接触 贝页斯视角下，岭回归与lasso关于线性模型系数的先验分布是不同的：前者为高斯分布，接近0时平坦，后验概率等同最优解；后者为拉普拉斯分布，接近0时尖锐，先验概率系数接近0，后验概率不一定为稀疏向量 岭回归与Lasso分别适用于真实模型自变量多或少的情况，并不广谱，考虑交叉检验来进行选择 交叉检验也可用来选择\\(\\lambda\\), 通过选择的自变量参与建模 8.18.9.4 降维 前提是自变量间不独立，将p个自变量向量投影到M维空间(M &lt; p)，使用投影M拟合线性回归模型 \\(\\sum_{m = 1}^{M}\\theta_m z_{im} = \\sum_{m = 1}^{M} \\theta_m \\sum_{j = 1}^{p} \\phi_{jm}x_{ij} = \\sum_{j = 1}^p \\sum_{m = 1}^{M} \\theta_m \\phi_{jm} x_{ij} = \\sum_{j = 1}^{p} \\beta_j x_{ij}\\) 主成分：各自变量在主成分方向上方差最大 主成分回归(PCA)：实际为无监督算法，得到主成分后作为新变量进行最小二乘回归，认为因变量与自变量变异最大的方向一致，需要仔细检验这个假设，主成分个数的选择影响模型效果 岭回归疑似为主成分回归的连续版，两者都需要标准化，效果也相近 偏最小二乘(PLA)：第一个投影方向为因变量与自变量回归方向，后续投影是对残差投影方向的回归，重复得到监督学习的效果 PLA通常并不比PCA更好，引入了监督算法提高了偏差 8.18.9.5 高维数据 n远远少于p或接近的数据 最小二乘估计在n小于p时残差为0，太过精细 \\(C_p\\)，AIC，BIC方法因为有参数\\(\\hat \\sigma^2\\)需要估计，而这个参数会在高维数据下变成0，调节\\(R^2\\)也会变成1 高维诅咒：正则化或收缩对高维方法产生影响，合适调谐参数十分重要，测试集误差必然增长 引入新变量会对预测产生不可知影响，选出的自变量并非不可替代，结果用独立验证集误差或交叉检验误差描述 8.19 非线性 8.19.1 多项式回归 模型基本形式为单一自变量在不同幂指数下的多项式，最小二乘拟合 模型在特定点的方差受系数方差与协方差影响，幂越高，模型越精细，方差越大 幂次一般不超过3或4 可进行logistic回归 8.19.2 阶梯函数 阶梯函数将自变量由连续变成有序分类变量 函数形式为引入指标函数\\(C_K(x)\\)进行自变量分段，然后进行最小二乘拟合 依赖找间隔点 可进行logistic回归 8.19.3 基函数 固定线性系数\\(\\beta\\),自变量的形式由\\(b(x)\\)决定，\\(b(x)\\)为基函数 多项式回归与阶梯函数均为基函数的特例 8.19.4 回归样条 设定分段点，分段点前后进行多项式回归 K个点分割(K+1)段，存在(K+1)个多项式回归，自由度过高 进行边界约束，对n次方程而言，约束分段点0阶，1阶，2阶导数连续，减少3个自由度，共有K个点，则有\\((n+1-3)k + n + 1\\)个自由度，相比无约束的\\((n+1)k\\)，自由度减少，更稳健 一般而言约束限制为(自由度-1)阶连续，这样自由度比分界点略多些，够用 分段样条最好在两端加入线性限制，收敛自由度，这样在边界稳健，为自然样条 分段点位置一般均匀分布，个数（本质上是自由度）通过交叉检验来确定 分段多项式回归限定了自由度，因此结果一般比多项式回归更稳定 8.19.5 平滑样条 如果以RSS衡量不加入限制，很容易产生过拟合，因此考虑加入平滑项 最小化 \\[ \\sum_{i = 1}^n (y_{i} - g(x_i))^2 + \\lambda \\int g&#39;&#39;(t)^2 dt \\] 其中，\\(g(x)\\)为平滑样条，由损失函数与惩罚项组成，二次导数表示在t处的平坦度，越平坦，惩罚越小，越崎岖，惩罚越大，因而平滑 对三次函数而言，平滑样条会将函数两端收敛的跟自然样条一样，实际上，平滑样条是自然样条的收缩版 参数\\(\\lambda\\)也影响平滑效果，越大越平滑，因为k固定，只涉及\\(\\lambda\\)的选择 参数\\(\\lambda\\)的选择基于有效自由度，可以用留一法进行估计，形式与杠杆点统计量差不多，可以很方便的进行数值求解 平滑样条的自由度比多项式要小，更稳健 8.19.6 本地回归 首先分段，然后分段内进行加权回归，离某点越近，权重越高，进行最小二乘拟合，得到每个点的函数，联合模型拟合 自变量较多，可考虑本地有选择的选取自变量进行本地回归 同样遭受高维诅咒带来的临近值少或稀疏问题 8.19.7 广义加性模型 \\[y_i = \\beta_0 + \\sum_{i = 1}^n f_j(x_{ij}) + \\epsilon\\] 每个自变量都有自己的函数形式，加合求解 每个自变量影响都可以展示 可分段，也可使用平滑，平滑方法中使用了反馈拟合策略对不易用最小二乘拟合求解的问题进行求解，效果差不多，分段不必要 可用于分类回归问题，解释性好 优点：非线性，更准确，易解释，可进行统计推断，可用自由度衡量平滑性 缺点：不易考虑交互影响 8.20 树 8.20.1 回归树 将因变量按自变量分区间，每个区间内预测值一致，直观易解释 \\(\\sum_{j = 1}^J\\sum_{i \\in R_J}(y_i - \\hat y_{R_j})^2\\) 计算困难，使用自上而下的贪心算法 递归二元分割：构建树过程每个节点都选最佳分割点，也就是分割后残差最小的变量与数值 算法在叶样本数为5时结束 树修剪，选择训练集误差最小的子树，引入调谐因子\\(\\alpha\\) 最小化\\(\\sum_{m = 1}^{|T|} \\sum_{i:x_i \\in R_m} (y_i - \\hat y_{R_m})^2 + \\alpha|T|\\) 类似lasso算法 确定\\(\\alpha\\)要用交叉检验，之后选出特定模型 8.20.2 分类树 因变量为分类变量，RSS用分类错误率代替 \\(E = 1 - max_k(\\hat p_{mk})\\)但分类错误率对树生长并不敏感，应采用其他指标 Gini系数：\\(G = \\sum_{k = 1}^K\\hat p_{mk}(1 - \\hat p_{mk})\\)，分类越准，值越小，衡量端纯度 cross-entropy：\\(D = - \\sum_{k = 1}^K\\hat p_{mk} log\\hat p_{mk}\\)，与Gini系数相似，描述一致 如果以修剪树为目标，指标应选择分类错误率 节点产生相同预测说明预测纯度不同，可靠性不同 与线性模型相比，适用数据种类不同，借助可视化判断 优点：容易解释，适用于决策，容易出图，处理分类问题简单 缺点：预测准确率低于其他常见回归与分类方法 8.20.3 Bagging 决策树方法相比线性回归模型方差很大 引入Bootstrap，通过平均构建低方差模型 \\(\\hat f_{avg}(x) = \\frac{1}{B} \\sum_{b = 1}^B \\hat f^{*b}(x)\\) 不修剪，通过平均降低方差 对于分类变量，通过投票，少数服从多数得到答案 误差估计通过包外样本（OOB）进行交叉检验并进行树的选择，降低计算成本 变量权重在Bagging中不易衡量，可通过衡量每棵树的RSS或者Gini系数在进行一次变量分割后RSS下降程度并进行排序取得 该方法可应用于其他统计模型 重采样 重新计算预测值 平均或投票给出结果 减少方差 偏差类似 适用于非线性过程 bagged trees 重采样 重建树 结果重评价 更稳健 效果不如RF Bagged loess 可用来处理细节 8.20.4 随机森林 bagging中使用所有的变量进行选择，但是会更易出现共相关变量，方差降低不多 随机森林的核心在于强制使用较少的自变量，为其他自变量提供预测空间进而提高模型表现 变量数一般选择为\\(\\sqrt p\\) 表现会比bagging好一些 bootstrap采样 每一个节点bootstrap选取变量 多棵树投票 准确度高 速度慢 不好解释 容易过拟合 8.20.5 Boosting 通用的统计学习方法 树生长基于先前的树，不使用bootstrap，使用修改过的原始数据 先生成有d个节点的树，之后通过加入收缩的新树来拟合残差，收缩因子为\\(\\lambda\\)，呈现层级模式，最后模型为\\(\\hat f(x) = \\sum_{b = 1}^B \\lambda \\hat f^b(x)\\) boosting学习缓慢，一般学习较慢的学习效果更好 三个参数：树个数B（交叉检验），收缩因子\\(\\lambda\\)（控制学习速率），树节点数（一般为1，为交互作用深度，控制涉及变量） 深度d为1时是加性模型 随机森林与Boosting产生的模型都不好解释 迭代分割变量 在最大化预测时分割 评估分支的同质性 多个树的预测更好 优点 容易解释应用 可用在神经网络上 缺点 不容易交叉验证 不确定性不宜估计 结果可能变化 -算法 先在一个组里用所有的变量计算 寻找最容易分离结果的变量 把数据按照该变量节点分为两组 在每一个组中寻找最好的分离变量 迭代直到过程结束 节点纯度用 Gini 系数或 交叉墒来衡量 rattle 包的 fancyRpartPlot 出图漂亮 可用来处理非线性模型与变量选择 弱预测变量加权后构建强预测变量 从一组预测变量开始 添加有惩罚项的预测变量来训练模型 以降低训练集误差为目的 通用方法 8.21 支持向量机 8.21.1 最大边界分类器 8.21.1.1 超平面 p维空间里(p-1)维子空间 \\(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + ... + \\beta_p X_p = 0\\) 定义一个p维超平面，X落在超平面上 p维空间中点X不在超平面上就在其两侧 8.21.1.2 超平面分类 n*p矩阵X分为两类Y-1或1 代入超平面大于0为1，小于0为-1，有\\(Y*\\beta*X &gt; 0\\) 表示分类正确 构建训练函数\\(f(x^*) = \\beta_0 + \\beta_1 X_1^* + \\beta_2 X_2^* + ... + \\beta_p X_p^*\\) 正数表示为1，负数为-1，距离0越远表示距离超平面越远，越近表示分类越不确定，判定边界为线性 8.21.1.3 最大边界分类器 最大边界超平面：距离边界最近的距离的所有超平面中距离边界点最远的那个超平面 分类良好但容易在p大时过拟合 形成最大边界分类器所需要的边界点为支持向量，用以支持最大边界超平面 \\(f(x^*)*y_i\\)在系数平方和为1时为点到平面的垂直距离，最小化后最大化这个距离是求最大边界超平面的关键 8.21.2 支持向量分类器 有些情况不存在超平面，需要求一个软边界来适配最多的分类，这就是支持向量分类器 因为是软边界所以允许在超平面或边界一边出现误判 计算上还是为最小化最大化距离，但分类上距离要乘以\\(1 - \\epsilon_i\\)项，也就是松弛变量 松弛变量大于0表示边界误判，大于1表示超平面误判，总和为C，表示边界的容忍度，越大分类越模糊 C可通过交叉检验获得，控制bias-variance权衡 只有边界内观察点影响超平面的选择，这些点为支持向量，是形成模型的关键 与LDA不同，使用部分数据，与logistic回归类似 8.21.3 支持向量机原理 非线性条件下可以考虑将超平面理解为非线性超平面，提高样本维度换取分类效果 加入多项式等非线性描述后计算量不可控 支持向量机通过核来控制非线性边界 通过样本内积来解决支持向量分类问题 线性支持向量分类器\\(f(x) = \\beta_0 + \\sum_{i = 1}^{n} \\alpha_i &lt; x,x_i &gt;\\) 只有支持向量在解中非0，现在只需要支持向量的内积就可以求解 内积可以推广为核函数，核函数可以采用非线性模式 \\(f(x) = \\beta_0 + \\sum_{i = 1}^{n} \\alpha_i K( x,x_i )\\) 径向基核函数较为常用 使用内积的核函数计算上简单且等价与高维空间超平面分类 8.21.3.1 多于二分类 一对一分类：对比\\(K \\choose 2\\)个分类器在检验集中的效果，通过计数来选择分类结果 一对多分类：对比K个与剩下的K-1个分类，分类结果最远的认为属于那个分类 8.21.4 svm与logistic回归关系 中枢损失，对关键点敏感 传统方法也可以借鉴核函数观点视同 支持向量无法提供参数概率信息，采用核函数的logistic回归可以，计算量大 分类距离较远，支持向量机会比logistic回归好一点 支持向量机是计算机背景，logistic回归是概率背景 8.22 无监督学习 8.22.1 主成分分析 用较少的变量代表较多的变量，方便可视化与理解数据 第一主成分\\(Z_1 = \\phi_{11} X_1 + \\phi_{21}X_2 + ... + \\phi_{p1} X_p\\) 方差最大， 正则化后有\\(\\sum_{j = 1}^p \\phi_{j1}^2 = 1\\)，则\\(\\phi\\)为变量在第一主成分上的载荷 求解上第一主成分最大化\\(\\frac{1}{n} \\sum_{i = 1}^{n} z_{i1}^2\\) 求解载荷值，\\(z_{ni}\\)是第一个样本在第一个主成分上的得分 载荷表示变量重要程度，得分表示样本重要程度 第二主成分与第一主成分正交求解 biplot 同时表示载荷与得分，载荷向量接近表示有相关性，方向不一表示相关性弱，变量在主成分得分差异表示其状态 第一个主成分表示在p维空间里距离n个观察最近的超平面，因此具备代表性 取M个主成分可代表所有数据\\(x_{ij} \\approx \\sum_{m = 1}^M z_{im} \\phi_{jm}\\) 变量单位要统一，已经统一就不要标准化了 主成分是唯一的，符号可能有变化，载荷与得分值也唯一 主成分的重要性通过方差解释比例(PVE)来衡量，用碎石图来可视化\\[\\frac{\\sum_{i = 1}^n (\\sum_{j =1}^p \\phi_{jm} x_{ij})^2}{\\sum_{j =1}^p x_{ij}^2}\\] 寻找碎石图的肘部来确定选取主成分的个数，方法不固定 可用来进行M小于p的主成分回归 SVD 算法 8.22.2 聚类方法 寻找子分类或簇的方法，从异质性寻找同质性 8.22.2.1 k均值聚类 子类中方差小，子类间方差大 事先指定子类个数 最小化所有K个平均欧式距离\\(W(C_k) = \\frac{1}{|C_k|} \\sum_{i,i&#39; \\in C_k} \\sum_{j = 1}^{p} (x_{ij} - x_{i&#39;j})^2\\) 先对所有样本随机分类，然后每种分类取中心，选取里中心距离最近的点重新分类，重新计算中心，迭代得到聚类结果 8.22.2.2 分层聚类 不需要指定先前聚类数，形成冰柱图 冰柱图要垂直分层解释，水平解释容易出现误导- 修剪冰柱图可给出聚类数 计算所有样本间距离，越相近就融合为一类，重新计算距离，反复这一过程 计算两者间相似度是很关键的，不同场景应用不同算法 变量的标准化处理上也很重要，考虑实际场景 8.23 人工神经网络 RNN神经网络算法 LSTM神经网络算法 tensorflow keras与深度学习 通过正交变量监督黑箱模型的敏感度 8.24 模型联合 通过平均与投票结合模型 联合分类器提高准确率 caretEnsemble 包 案例 广义加性模型 library(ISLR); data(Wage); library(ggplot2); library(caret); Wage &lt;- subset(Wage,select=-c(logwage)) # Create a building data set and validation set inBuild &lt;- createDataPartition(y=Wage$wage,p=0.7, list=FALSE) validation &lt;- Wage[-inBuild,]; buildData &lt;- Wage[inBuild,] inTrain &lt;- createDataPartition(y=buildData$wage,p=0.7, list=FALSE) training &lt;- buildData[inTrain,]; testing &lt;- buildData[-inTrain,] mod1 &lt;- train(wage ~.,method=&quot;glm&quot;,data=training) mod2 &lt;- train(wage ~.,method=&quot;rf&quot;,data=training,trControl = trainControl(method=&quot;cv&quot;),number=3) pred1 &lt;- predict(mod1,testing); pred2 &lt;- predict(mod2,testing) qplot(pred1,pred2,colour=wage,data=testing) predDF &lt;- data.frame(pred1,pred2,wage=testing$wage) combModFit &lt;- train(wage ~.,method=&quot;gam&quot;,data=predDF) combPred &lt;- predict(combModFit,predDF) sqrt(sum((pred1-testing$wage)^2)) sqrt(sum((pred2-testing$wage)^2)) sqrt(sum((combPred-testing$wage)^2)) 8.25 无监督预测 先聚类 后预测 clue 包 cl_predict 函数 推荐系统 8.26 模型预测 时序数据 包含趋势 季节变化 循环 效应分解 decompose window 窗口 ma 平滑 ets 指数平滑 forecast 预测 空间数据同样有这种问题 临近依赖 地域效应 quantmod 包 或 quandl 包处理金融数据 外推要谨慎 8.27 模型可视化 统计模型可视化 "],["product.html", "第9章 开发数据产品 9.1 shiny 9.2 rCharts 9.3 GoogleVis 9.4 Slidify 9.5 yhat 9.6 swagger 9.7 案例", " 第9章 开发数据产品 9.1 shiny 源自 R-studio 动态网络应用 入门版 OpenCPU 高级版 Manipulate install.packages(\"shiny\");libray(shiny) ui.R 控制外观 sever.R 控制计算 runApp() 启动应用 sever.R 中 shinyServer 之前的代码只在启动应用时执行一次 适合读入数据 shinyServer(function(input, output){ 之内的非互动函数只被每个用户执行一次 Render* 为互动函数 数值改变就执行一次 runApp(display.mode='showcase') 可用来同时高亮显示执行代码 reactive 用来加速互动函数外的信息交换 actionButton 用来一次提交输入数据 if (input$goButton == 1){ Conditional statements } 用来定义条件语句 cat browser() 调试 fluidRow 产生表格 shinydashboard flexdashboard docker image prettydoc 9.2 rCharts 主页 动态交互可视化工具 require(devtools);install_github('rCharts', 'ramnathv') 9.3 GoogleVis 主页 R 代码产生图表 生成html install.packages('googleVis');library(googleVis) 教程 9.4 Slidify 主页 html5 幻灯片 install.packages(\"devtools\");library(devtools);install_github('slidify', 'ramnathv');install_github('slidifyLibraries', 'ramnathv');library(slidify) author(\"yufree\") YAML 配置幻灯片结构 ## 幻灯片开始 --- 加空行表结束 .class #id 自定义css文件id slidify(\"index.Rmd\") 生成 browseURL(\"index.html\") 观看 publish_github(user, repo) github发布 9.5 yhat 主页 本地提交算法或模型 生成可调用API 支持R与python 9.6 swagger 主页 生产API 9.7 案例 算法先发现女儿怀孕 netflix为什么不用获奖算法 伪装品酒师 facebook 算法压抑多样性 利用点评数据预测经济发展可能比政府数据更新更及时，也更准确，刚搜了一下发现淘宝就有卖这类数据的… #biorxiv 京都大学的一篇预印本论文基于深度神经网络与功能性核磁共振技术重构了视觉图像，看来读心术跟梦境重现术用不了多久就能见到产品了 #qz 茶是一种很特殊的跨国交易品，Nikhil Sonnad 发现丝绸之路上国家对茶的发音接近 cha，而地理大发现后沿岸（大概可理解为海上丝绸之路）上国家对茶的发音接近 tea（闽南语的茶），这种利用特产发音研究贸易史的方法很有启发性 飓风玛丽亚的官方死亡人数是64，但纽约时报对比了往年数据认为应该是1052，这个往年对比对方法对灾害评价更有意义，可以发现一些非灾害直接导致但潜在相关的死亡现象 某数据科学家收集并可视化了17年的买菜收据研究其购买行为的潜在模式，很神奇地发现他每次买东西的顺序都是相似的，然而后来被证明是电脑根据货物分类的默认排序 写一个markdown编译器 facebook 与普林斯顿的互掐 船跟教堂都曾是很直观的测量单位 twitter上喝酒的性别分析 美国各地对饮料的提法，南部人说coke，东北与西海岸说soda，其余地方说pop 百度指数抓取 twitter 上数据现实真相传播速度比谣言要慢，机器传播真假速率一致，人的传播起主要作用 #科学美国人 雪花的生长模拟与分类，脑洞很大，这是我头一次看到有人把 t-sne 跟 rnn 算法用到科普里 地震记录可视化 国际象棋生存概率 各国人民想买什么 如何修厕所跟如何用筷子具有搜索相关性 很有画面感 09-17年推特的语义幸福度走势图，这两天因枪击达到了历史最低点，整体呈现出了6-7年的周期性，目前处于下行大趋势 谷歌新闻实验室出品的可视化图形、书籍及工具的流行趋势，可作为入门可视化的“光环效应”指南，没想到甘特图排那么靠前，另外漏掉了今年的新秀joyplot 新西兰的新生儿名字在最近50年里呈现了长尾化，父母在给孩子起名字时有了更强的多样性，要知道在1850年英国新生儿里有13.7%的William和14.6%的Mary，突然想明白了为啥有个历史悠久的威廉玛丽学院了… 图解机器学习系列 训练一个种族歧视的AI "],["bayes.html", "第10章 贝叶斯统计 10.1 贝塔分布 10.2 为什么击球的概率分布符合贝塔分布？ 10.3 先验与后验 10.4 经验贝叶斯 10.5 从整体到个人 10.6 可信区间与置信区间 10.7 后验错误率 10.8 错误发现率 10.9 q值 10.10 贝叶斯视角的假设检验 10.11 比例检验 10.12 错误率控制 10.13 影响因子 10.14 混合概率模型 10.15 模拟验证结果 10.16 网络资源", " 第10章 贝叶斯统计 10.1 贝塔分布 贝塔分布的本质是概率分布的分布 棒球击球率的预测问题，你不可能预测一个刚打出本垒下一个也击中，会有一个先验概率 这个概率可以用一个参数 \\(\\alpha\\) 与 \\(\\beta\\) 的贝塔分布来描述，例如一共打了300个球，81个击中，219个击空，那么 \\(\\alpha\\) 为81，\\(\\beta\\) 为219 均值为\\(\\frac{\\alpha}{\\alpha + \\beta} = \\frac{81}{81+219} = 0.27\\) 概率密度分布图，从图上我们可以看出一个大约在0.2-0.35的概率区间，表示击球的先验概率空间可能的取值 library(ggplot2) x &lt;- seq(0,1,length=100) db &lt;- dbeta(x, 81, 219) ggplot() + geom_line(aes(x,db)) + ylab(&quot;Density of beta&quot;) 10.2 为什么击球的概率分布符合贝塔分布？ 设想球员A打了一个球打中了，那么在没有先验知识的情况下我会认为他击中概率为1 这个球员又打中了一个球，那么还是1 但第三个没打中，我们会认为他击中概率是0吗？ 一般而言，这类连续击球问题可以用二项分布来描述，例如10个球打中8个的概率，我们假设这个击球概率为q，那么这个概率应该是个q的函数： \\[f(q) \\propto q^a(1-q)^b\\] q对于一个实际问题是确定的常数，所以出现这个场景的概率实际上是a与b的函数 为了保障这个概率函数累积为1，需要除一个跟a与b有关的数 这个数可以用贝塔函数\\(B(a,b)\\)来表示，数学证明略 如果接着打了一个中了，那么如何更新这个概率？ 根据贝叶斯公式，最后推导出的结果如下： \\[Beta(\\alpha+1,\\beta+0)\\] 那么我们对这个击球率的估计就略高了一点，这是贝塔分布的神奇之处，形式非常简单，理解也很直观 10.3 先验与后验 如果我们后续观察的击球少，那么不太容易影响到对概率的先验估计 x &lt;- seq(0,1,length=100) db &lt;- dbeta(x, 81+1, 219) ggplot() + geom_line(aes(x,db)) + ylab(&quot;Density of beta&quot;) 如果后续观察了大量的击球都中了，那么概率会偏向后面数据量的那一部分 x &lt;- seq(0,1,length=100) db &lt;- dbeta(x, 81+1000, 219) ggplot() + geom_line(aes(x,db)) + ylab(&quot;Density of beta&quot;) 这是贝叶斯分析的核心思想，通过证据更新经验 最后得到的均值（后验0.83）一定是介于经验值（先验0.27）与证据值（全击中就是1）之间 贝塔分布天然适合描述一个对概率的估计场景 另一种不那么严谨的理解方法是如果一个概率是稳定的，那么多次实验的结果差别不会太大，则有： \\[\\frac{a}{b} = \\frac{c}{d} = \\frac{a+b}{c+d}\\] 如果每次实验的概率持平，那么不存在不确定度；但如果前面实验的次数少而后面实验的次数多，那么概率会偏重于后面，这就是贝塔分布想说明的事 10.4 经验贝叶斯 对于两个球员，一个打了10个球中了4个，另一个打了1000个球中了300个，一般击中概率0.2，你会选哪一个？ 我们对于小样本量的统计推断会有天然的不信任，如何通过统计量来描述？ 下面用MLB的数据说明，首先提取出球员的击球数据： library(dplyr) library(tidyr) library(Lahman) # 拿到击球数据 career &lt;- Batting %&gt;% filter(AB &gt; 0) %&gt;% anti_join(Pitching, by = &quot;playerID&quot;) %&gt;% group_by(playerID) %&gt;% summarize(H = sum(H), AB = sum(AB)) %&gt;% mutate(average = H / AB) # 把ID换成球员名字 career &lt;- People %&gt;% tbl_df() %&gt;% dplyr::select(playerID, nameFirst, nameLast) %&gt;% unite(name, nameFirst, nameLast, sep = &quot; &quot;) %&gt;% inner_join(career, by = &quot;playerID&quot;) %&gt;% dplyr::select(-playerID) # 展示数据 career ## # A tibble: 9,862 × 4 ## name H AB average ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Hank Aaron 3771 12364 0.305 ## 2 Tommie Aaron 216 944 0.229 ## 3 Andy Abad 2 21 0.0952 ## 4 John Abadie 11 49 0.224 ## 5 Ed Abbaticchio 772 3044 0.254 ## 6 Fred Abbott 107 513 0.209 ## 7 Jeff Abbott 157 596 0.263 ## 8 Kurt Abbott 523 2044 0.256 ## 9 Ody Abbott 13 70 0.186 ## 10 Frank Abercrombie 0 4 0 ## # … with 9,852 more rows # 击球前5 career %&gt;% arrange(desc(average)) %&gt;% head(5) %&gt;% kable() name H AB average Jeff Banister 1 1 1 Doc Bass 1 1 1 Steve Biras 2 2 1 C. B. Burns 1 1 1 Jackie Gallagher 1 1 1 # 击球后5 career %&gt;% arrange(average) %&gt;% head(5) %&gt;% kable() name H AB average Frank Abercrombie 0 4 0 Horace Allen 0 7 0 Pete Allen 0 4 0 Walter Alston 0 1 0 Trey Amburgey 0 4 0 如果仅考虑击球率会把很多板凳球员与运气球员包括进来，一个先验概率分布很有必要 那么考虑下如何得到，经验贝叶斯方法认为如果估计一个个体的参数，那么这个个体所在的整体的概率分布可作为先验概率分布 这个先验概率分布可以直接从数据中得到，然后我们要用极大似然或矩估计的方法拿到贝塔分布的两个参数： career_filtered &lt;- career %&gt;% filter(AB &gt;= 500) m &lt;- MASS::fitdistr(career_filtered$average, dbeta, start = list(shape1 = 1, shape2 = 10)) alpha0 &lt;- m$estimate[1] beta0 &lt;- m$estimate[2] # 看下拟合效果 ggplot(career_filtered) + geom_histogram(aes(average, y = ..density..), binwidth = .005) + stat_function(fun = function(x) dbeta(x, alpha0, beta0), color = &quot;red&quot;, size = 1) + xlab(&quot;Batting average&quot;) 10.5 从整体到个人 当我们估计个人的击球率时，整体可以作为先验函数，个人的数据可以通过贝塔分布更新到个体 那么如果一个人数据少，我们倾向于认为他是平均水平；数据多则认为符合个人表现 这事实上是一个分层结构，经验贝叶斯推断里隐含了这么一个从整体到个人的过程 career_eb &lt;- career %&gt;% mutate(eb_estimate = (H + alpha0) / (AB + alpha0 + beta0)) # 击球率高 career_eb %&gt;% arrange(desc(eb_estimate)) %&gt;% head(5) %&gt;% kable() name H AB average eb_estimate Rogers Hornsby 2930 8173 0.358 0.355 Shoeless Joe Jackson 1772 4981 0.356 0.350 Ed Delahanty 2597 7510 0.346 0.342 Billy Hamilton 2164 6283 0.344 0.340 Harry Heilmann 2660 7787 0.342 0.338 # 击球率低 career_eb %&gt;% arrange(eb_estimate) %&gt;% head(5) %&gt;% kable() name H AB average eb_estimate Bill Bergen 516 3028 0.170 0.179 Ray Oyler 221 1265 0.175 0.191 John Vukovich 90 559 0.161 0.196 John Humphries 52 364 0.143 0.196 George Baker 74 474 0.156 0.196 # 整体估计 ggplot(career_eb, aes(average, eb_estimate, color = AB)) + geom_hline(yintercept = alpha0 / (alpha0 + beta0), color = &quot;red&quot;, lty = 2) + geom_point() + geom_abline(color = &quot;red&quot;) + scale_colour_gradient(trans = &quot;log&quot;, breaks = 10 ^ (1:5)) + xlab(&quot;Batting average&quot;) + ylab(&quot;Empirical Bayes batting average&quot;) 数据点多会收缩到\\(x=y\\)，也就是个人的击球率；数据点少则回归到整体击球率 这就是经验贝叶斯方法的全貌：先估计整体的参数，然后把整体参数作为先验概率估计个人参数 10.6 可信区间与置信区间 经验贝叶斯可以给出点估计，但现实中我们可能更关心区间估计 一般这类区间估计可以用二项式比例估计来进行，不过没有先验经验的限制置信区间大到没意义 经验贝叶斯会给出一个后验分布，这个分布可以用来求可信区间 library(broom) # 给出后验分布 career &lt;- Batting %&gt;% filter(AB &gt; 0) %&gt;% anti_join(Pitching, by = &quot;playerID&quot;) %&gt;% group_by(playerID) %&gt;% summarize(H = sum(H), AB = sum(AB)) %&gt;% mutate(average = H / AB) career &lt;- People %&gt;% tbl_df() %&gt;% dplyr::select(playerID, nameFirst, nameLast) %&gt;% unite(name, nameFirst, nameLast, sep = &quot; &quot;) %&gt;% inner_join(career, by = &quot;playerID&quot;) career0 &lt;- Batting %&gt;% filter(AB &gt; 0) %&gt;% anti_join(Pitching, by = &quot;playerID&quot;) %&gt;% group_by(playerID) %&gt;% summarize(H = sum(H), AB = sum(AB), year = mean(yearID)) %&gt;% mutate(average = H / AB) career2 &lt;- People %&gt;% tbl_df() %&gt;% dplyr::select(playerID, nameFirst, nameLast, bats) %&gt;% unite(name, nameFirst, nameLast, sep = &quot; &quot;) %&gt;% inner_join(career0, by = &quot;playerID&quot;) career_eb &lt;- career %&gt;% mutate(eb_estimate = (H + alpha0) / (AB + alpha0 + beta0)) career_eb &lt;- career_eb %&gt;% mutate(alpha1 = H + alpha0, beta1 = AB - H + beta0) # 提取洋基队的数据 yankee_1998 &lt;- c(&quot;brosisc01&quot;, &quot;jeterde01&quot;, &quot;knoblch01&quot;, &quot;martiti02&quot;, &quot;posadjo01&quot;, &quot;strawda01&quot;, &quot;willibe02&quot;) yankee_1998_career &lt;- career_eb %&gt;% filter(playerID %in% yankee_1998) # 提取可信区间 yankee_1998_career &lt;- yankee_1998_career %&gt;% mutate(low = qbeta(.025, alpha1, beta1), high = qbeta(.975, alpha1, beta1)) yankee_1998_career %&gt;% dplyr::select(-alpha1, -beta1, -eb_estimate) %&gt;% knitr::kable() playerID name H AB average low high brosisc01 Scott Brosius 1001 3889 0.257 0.244 0.271 jeterde01 Derek Jeter 3465 11195 0.310 0.300 0.317 knoblch01 Chuck Knoblauch 1839 6366 0.289 0.277 0.298 martiti02 Tino Martinez 1925 7111 0.271 0.260 0.280 posadjo01 Jorge Posada 1664 6092 0.273 0.262 0.283 strawda01 Darryl Strawberry 1401 5418 0.259 0.247 0.270 willibe02 Bernie Williams 2336 7869 0.297 0.286 0.305 # 绘制可信区间 yankee_1998_career %&gt;% mutate(name = reorder(name, average)) %&gt;% ggplot(aes(average, name)) + geom_point() + geom_errorbarh(aes(xmin = low, xmax = high)) + geom_vline(xintercept = alpha0 / (alpha0 + beta0), color = &quot;red&quot;, lty = 2) + xlab(&quot;Estimated batting average (w/ 95% interval)&quot;) + ylab(&quot;Player&quot;) # 对比置信区间与可信区间 career_eb &lt;- career_eb %&gt;% mutate(low = qbeta(.025, alpha1, beta1), high = qbeta(.975, alpha1, beta1)) set.seed(2016) some &lt;- career_eb %&gt;% sample_n(20) %&gt;% mutate(name = paste0(name, &quot; (&quot;, H, &quot;/&quot;, AB, &quot;)&quot;)) frequentist &lt;- some %&gt;% group_by(playerID, name, AB) %&gt;% do(tidy(binom.test(.$H, .$AB))) %&gt;% dplyr::select(playerID, name, estimate, low = conf.low, high = conf.high) %&gt;% mutate(method = &quot;Confidence&quot;) bayesian &lt;- some %&gt;% dplyr::select(playerID, name, AB, estimate = eb_estimate, low = low, high = high) %&gt;% mutate(method = &quot;Credible&quot;) combined &lt;- bind_rows(frequentist, bayesian) combined %&gt;% mutate(name2 = reorder(name, -AB)) %&gt;% ggplot(aes(estimate, name2, color = method, group = method)) + geom_point() + geom_errorbarh(aes(xmin = low, xmax = high)) + geom_vline(xintercept = alpha0 / (alpha0 + beta0), color = &quot;red&quot;, lty = 2) + xlab(&quot;Estimated batting average&quot;) + ylab(&quot;Player&quot;) + labs(color = &quot;&quot;) 可信区间与置信区间很大的区别在于前者考虑了先验概率进而实现了区间的收缩，后者则可看作无先验贝塔分布给出的区间估计，频率学派目前没有很好的收缩区间估计的方法 10.7 后验错误率 现实问题经常不局限于估计，而是侧重决策，例如如果一个球员的击球率高于某个值，他就可以进入名人堂（击球率大于0.3），这个决策常常伴随区间估计而不是简单的点估计 # 以 Hank Aaron 为例 career_eb %&gt;% filter(name == &quot;Hank Aaron&quot;) %&gt;% do(data_frame(x = seq(.27, .33, .0002), density = dbeta(x, .$alpha1, .$beta1))) %&gt;% ggplot(aes(x, density)) + geom_line() + geom_ribbon(aes(ymin = 0, ymax = density * (x &lt; .3)), alpha = .1, fill = &quot;red&quot;) + geom_vline(color = &quot;red&quot;, lty = 2, xintercept = .3) # 提取该球员数据 career_eb %&gt;% filter(name == &quot;Hank Aaron&quot;) ## # A tibble: 1 × 10 ## playerID name H AB average eb_estimate alpha1 beta1 low high ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 aaronha01 Hank Aaron 3771 12364 0.305 0.304 3850. 8821. 0.296 0.312 # 计算其不进入名人堂的概率 pbeta(.3, 3850, 8818) ## [1] 0.169 后验错误率（Posterior Error Probability）可类比经典假设检验中的显著性水平\\(\\alpha\\) 后验包括率（Posterior Inclusion Probability）可类比经典假设检验中的置信水平\\(1-\\alpha\\) # 所有球员的后验错误率分布，大部分不超过0.3 career_eb &lt;- career_eb %&gt;% mutate(PEP = pbeta(.3, alpha1, beta1)) ggplot(career_eb, aes(PEP)) + geom_histogram(binwidth = .02) + xlab(&quot;Posterior Error Probability (PEP)&quot;) + xlim(0, 1) # 后验错误率与击球率的关系 career_eb %&gt;% ggplot(aes(eb_estimate, PEP, color = AB)) + geom_point(size = 1) + xlab(&quot;(Shrunken) batting average estimate&quot;) + ylab(&quot;Posterior Error Probability (PEP)&quot;) + geom_vline(color = &quot;red&quot;, lty = 2, xintercept = .3) + scale_colour_gradient(trans = &quot;log&quot;, breaks = 10 ^ (1:5)) 后验错误率高于0.3的多数是击球率与击球数都高的人，因为贝叶斯方法惩罚了击球数低的人 10.8 错误发现率 错误发现率（FDR）可用来控制一个整体决策，保证整体犯错的概率低于某个数值，错误发现率越高，越可能把假阳性包括进来 假如我们把进入名人堂的决策作为一个整体，则可允许一定的整体错误率，因为每个人的后验错误率可以计算且期望值线性可加和，我们可以得到一个整体的错误率 # 取前100个球员 top_players &lt;- career_eb %&gt;% arrange(PEP) %&gt;% head(100) # 总错率率 sum(top_players$PEP) ## [1] 5.52 # 平均错误率 mean(top_players$PEP) ## [1] 0.0552 # 错误率随所取球员的变化 sorted_PEP &lt;- career_eb %&gt;% arrange(PEP) mean(head(sorted_PEP$PEP, 50)) ## [1] 0.0023 mean(head(sorted_PEP$PEP, 200)) ## [1] 0.257 错误率在排序后前面低后面高，但这个错误率不特指某个球员，而是包含到某个球员的整体犯错的概率 10.9 q值 q值定义为排序后累积到某个样本的整体平均错误率，类似多重比较中对整体错误率控制的p值 # 生成每个球员的q值 career_eb &lt;- career_eb %&gt;% arrange(PEP) %&gt;% mutate(qvalue = cummean(PEP)) # 观察不同q值对名人堂球员数的影响 career_eb %&gt;% ggplot(aes(qvalue, rank(PEP))) + geom_line() + xlab(&quot;q-value cutoff&quot;) + ylab(&quot;Number of players included&quot;) # 观察小q值部分 career_eb %&gt;% filter(qvalue &lt; .25) %&gt;% ggplot(aes(qvalue, rank(PEP))) + geom_line() + xlab(&quot;q-value cutoff&quot;) + ylab(&quot;Number of players included&quot;) 200个人进入名人堂可能有约1/4的球员不合适，如果是50个人进入名人堂那么基本不会犯错 q值是一个整体而非个体的平均错误率，具有累积性，不代表q值大的那一个就是错的 q值在频率学派的多重比较里也有定义，虽然没有空假设（有先验概率），但实质等同 10.10 贝叶斯视角的假设检验 前面描述的是击球率如何求，如何进行区间估计与多个体的错误率控制，面向的个体或整体，那么如何解决比较问题 设想多个球员，我们考虑如何去比较他们击球率。如果两个球员击球率的概率密度曲线比较接近，那么即便均值有不同我们也无法进行区分；如果重叠比较少，那么我们有理由认为他们之间的差异显著 贝叶斯视角下如何定量描述这个差异是否显著？ 10.10.1 模拟验证 单纯取样比大小然后计算比例 # 提取两人数据 aaron &lt;- career_eb %&gt;% filter(name == &quot;Hank Aaron&quot;) piazza &lt;- career_eb %&gt;% filter(name == &quot;Mike Piazza&quot;) # 模拟取样10万次 piazza_simulation &lt;- rbeta(1e6, piazza$alpha1, piazza$beta1) aaron_simulation &lt;- rbeta(1e6, aaron$alpha1, aaron$beta1) # 计算一个人超过另一个人的概率 sim &lt;- mean(piazza_simulation &gt; aaron_simulation) sim ## [1] 0.605 10.10.2 数值积分 两个概率的联合概率分布，然后积分一个队员大于另一个的概率 d &lt;- .00002 limits &lt;- seq(.29, .33, d) sum(outer(limits, limits, function(x, y) { (x &gt; y) * dbeta(x, piazza$alpha1, piazza$beta1) * dbeta(y, aaron$alpha1, aaron$beta1) * d ^ 2 })) ## [1] 0.603 10.10.3 解析解 两个贝塔分布一个比另一个高是有含有贝塔函数的解析解的： \\[p_A \\sim \\mbox{Beta}(\\alpha_A, \\beta_A)\\] \\[p_B \\sim \\mbox{Beta}(\\alpha_B, \\beta_B)\\] \\[{\\rm Pr}(p_B &gt; p_A) = \\sum_{i=0}^{\\alpha_B-1}\\frac{B(\\alpha_A+i,\\beta_A+\\beta_B)}{(\\beta_B+i) B(1+i, \\beta_B) B(\\alpha_A, \\beta_A) }\\] h &lt;- function(alpha_a, beta_a, alpha_b, beta_b) { j &lt;- seq.int(0, round(alpha_b) - 1) log_vals &lt;- (lbeta(alpha_a + j, beta_a + beta_b) - log(beta_b + j) - lbeta(1 + j, beta_b) - lbeta(alpha_a, beta_a)) 1 - sum(exp(log_vals)) } h(piazza$alpha1, piazza$beta1, aaron$alpha1, aaron$beta1) ## [1] 0.605 10.10.4 正态近似求解 贝塔分布在\\(\\alpha\\)与\\(\\beta\\)比较大时接近正态分布，可以直接用正态分布的解析解求，速度快很多 h_approx &lt;- function(alpha_a, beta_a, alpha_b, beta_b) { u1 &lt;- alpha_a / (alpha_a + beta_a) u2 &lt;- alpha_b / (alpha_b + beta_b) var1 &lt;- alpha_a * beta_a / ((alpha_a + beta_a) ^ 2 * (alpha_a + beta_a + 1)) var2 &lt;- alpha_b * beta_b / ((alpha_b + beta_b) ^ 2 * (alpha_b + beta_b + 1)) pnorm(0, u2 - u1, sqrt(var1 + var2)) } h_approx(piazza$alpha1, piazza$beta1, aaron$alpha1, aaron$beta1) ## [1] 0.604 10.11 比例检验 这是个列联表问题，频率学派对比两个比例 two_players &lt;- bind_rows(aaron, piazza) two_players %&gt;% transmute(Player = name, Hits = H, Misses = AB - H) %&gt;% knitr::kable() Player Hits Misses Hank Aaron 3771 8593 Mike Piazza 2127 4784 prop.test(two_players$H, two_players$AB) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: two_players$H out of two_players$AB ## X-squared = 0.1, df = 1, p-value = 0.7 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.0165 0.0109 ## sample estimates: ## prop 1 prop 2 ## 0.305 0.308 贝叶斯学派对比两个比例 credible_interval_approx &lt;- function(a, b, c, d) { u1 &lt;- a / (a + b) u2 &lt;- c / (c + d) var1 &lt;- a * b / ((a + b) ^ 2 * (a + b + 1)) var2 &lt;- c * d / ((c + d) ^ 2 * (c + d + 1)) mu_diff &lt;- u2 - u1 sd_diff &lt;- sqrt(var1 + var2) data_frame(posterior = pnorm(0, mu_diff, sd_diff), estimate = mu_diff, conf.low = qnorm(.025, mu_diff, sd_diff), conf.high = qnorm(.975, mu_diff, sd_diff)) } credible_interval_approx(piazza$alpha1, piazza$beta1, aaron$alpha1, aaron$beta1) ## # A tibble: 1 × 4 ## posterior estimate conf.low conf.high ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.604 -0.00180 -0.0151 0.0115 多个球员对比一个 set.seed(2016) intervals &lt;- career_eb %&gt;% filter(AB &gt; 10) %&gt;% sample_n(20) %&gt;% group_by(name, H, AB) %&gt;% do(credible_interval_approx(piazza$alpha1, piazza$beta1, .$alpha1, .$beta1)) %&gt;% ungroup() %&gt;% mutate(name = reorder(paste0(name, &quot; (&quot;, H, &quot; / &quot;, AB, &quot;)&quot;), -estimate)) f &lt;- function(H, AB) broom::tidy(prop.test(c(H, piazza$H), c(AB, piazza$AB))) prop_tests &lt;- purrr::map2_df(intervals$H, intervals$AB, f) %&gt;% mutate(estimate = estimate1 - estimate2, name = intervals$name) all_intervals &lt;- bind_rows( mutate(intervals, type = &quot;Credible&quot;), mutate(prop_tests, type = &quot;Confidence&quot;) ) ggplot(all_intervals, aes(x = estimate, y = name, color = type)) + geom_point() + geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) + xlab(&quot;Piazza average - player average&quot;) + ylab(&quot;Player&quot;) 置信区间与可信区间的主要差异来自于经验贝叶斯的区间收敛 10.12 错误率控制 如果我打算交易一个球员，那么如何筛选候选人？ 先选那些击球率更好的球员 # 对比打算交易的球员与其他球员 career_eb_vs_piazza &lt;- bind_cols( career_eb, credible_interval_approx(piazza$alpha1, piazza$beta1, career_eb$alpha1, career_eb$beta1)) %&gt;% dplyr::select(name, posterior, conf.low, conf.high) career_eb_vs_piazza ## # A tibble: 9,862 × 4 ## name posterior conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Rogers Hornsby 2.84e-11 0.0345 0.0639 ## 2 Ed Delahanty 7.51e- 7 0.0217 0.0517 ## 3 Shoeless Joe Jackson 8.92e- 8 0.0277 0.0611 ## 4 Willie Keeler 4.61e- 6 0.0183 0.0472 ## 5 Nap Lajoie 1.55e- 5 0.0159 0.0441 ## 6 Tony Gwynn 1.82e- 5 0.0157 0.0442 ## 7 Harry Heilmann 7.19e- 6 0.0180 0.0476 ## 8 Lou Gehrig 1.43e- 5 0.0167 0.0461 ## 9 Billy Hamilton 6.47e- 6 0.0191 0.0504 ## 10 Eddie Collins 1.99e- 4 0.0113 0.0393 ## # … with 9,852 more rows # 计算q值 career_eb_vs_piazza &lt;- career_eb_vs_piazza %&gt;% arrange(posterior) %&gt;% mutate(qvalue = cummean(posterior)) # 筛选那些q值小于0.05的 better &lt;- career_eb_vs_piazza %&gt;% filter(qvalue &lt; .05) better ## # A tibble: 48 × 5 ## name posterior conf.low conf.high qvalue ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Rogers Hornsby 2.84e-11 0.0345 0.0639 2.84e-11 ## 2 Shoeless Joe Jackson 8.92e- 8 0.0277 0.0611 4.46e- 8 ## 3 Ed Delahanty 7.51e- 7 0.0217 0.0517 2.80e- 7 ## 4 Willie Keeler 4.61e- 6 0.0183 0.0472 1.36e- 6 ## 5 Billy Hamilton 6.47e- 6 0.0191 0.0504 2.38e- 6 ## 6 Harry Heilmann 7.19e- 6 0.0180 0.0476 3.18e- 6 ## 7 Lou Gehrig 1.43e- 5 0.0167 0.0461 4.77e- 6 ## 8 Nap Lajoie 1.55e- 5 0.0159 0.0441 6.11e- 6 ## 9 Tony Gwynn 1.82e- 5 0.0157 0.0442 7.46e- 6 ## 10 Bill Terry 3.04e- 5 0.0162 0.0472 9.76e- 6 ## # … with 38 more rows 这样我们筛到一个可交易的群体，总和错误率不超过5% 10.13 影响因子 击球率高除了能力影响外还有可能是因为得到的机会多或者光环效应，例如一开始凭运气打得好，后面给机会多，通过经验累积提高了击球率 career %&gt;% filter(AB &gt;= 20) %&gt;% ggplot(aes(AB, average)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + scale_x_log10() 击球数低方差会大，这比较正常，很多人挂在起跑线上了 直接使用经验贝叶斯方法会导致整体向均值收敛，这高估了新手的数据 prior_mu &lt;- alpha0 / (alpha0 + beta0) career_eb %&gt;% filter(AB &gt;= 20) %&gt;% gather(type, value, average, eb_estimate) %&gt;% mutate(type = plyr::revalue(type, c(average = &quot;Raw&quot;, eb_estimate = &quot;With EB Shrinkage&quot;))) %&gt;% ggplot(aes(AB, value)) + geom_point() + scale_x_log10() + geom_hline(color = &quot;red&quot;, lty = 2, size = 1.5, yintercept = prior_mu) + facet_wrap(~type) + ylab(&quot;average&quot;) + geom_smooth(method = &quot;lm&quot;) 为了如实反应这种情况，我们应该认为击球率符合贝塔分布，但同时贝塔分布的两个参数受击球数的影响，击球数越多，越可能击中 这个模型可以用贝塔－二项式回归来描述 \\[\\mu_i = \\mu_0 + \\mu_{\\mbox{AB}} \\cdot \\log(\\mbox{AB})\\] \\[\\alpha_{0,i} = \\mu_i / \\sigma_0\\] \\[\\beta_{0,i} = (1 - \\mu_i) / \\sigma_0\\] \\[p_i \\sim \\mbox{Beta}(\\alpha_{0,i}, \\beta_{0,i})\\] \\[H_i \\sim \\mbox{Binom}(\\mbox{AB}_i, p_i)\\] 10.13.1 拟合模型 寻找拟合后的模型参数，构建新的先验概率 library(gamlss) # 拟合模型 fit &lt;- gamlss(cbind(H, AB - H) ~ log(AB), data = career_eb, family = BB(mu.link = &quot;identity&quot;)) ## GAMLSS-RS iteration 1: Global Deviance = 96508 ## GAMLSS-RS iteration 2: Global Deviance = 76324 ## GAMLSS-RS iteration 3: Global Deviance = 71916 ## GAMLSS-RS iteration 4: Global Deviance = 71910 ## GAMLSS-RS iteration 5: Global Deviance = 71910 10.13.2 求后验概率 # 计算所有拟合值 mu &lt;- fitted(fit, parameter = &quot;mu&quot;) sigma &lt;- fitted(fit, parameter = &quot;sigma&quot;) # 计算所有后验概率 career_eb_wAB &lt;- career_eb %&gt;% dplyr::select(name, H, AB, original_eb = eb_estimate) %&gt;% mutate(mu = mu, alpha0 = mu / sigma, beta0 = (1 - mu) / sigma, alpha1 = alpha0 + H, beta1 = beta0 + AB - H, new_eb = alpha1 / (alpha1 + beta1)) # 展示拟合后的击球率 ggplot(career_eb_wAB, aes(original_eb, new_eb, color = AB)) + geom_point() + geom_abline(color = &quot;red&quot;) + xlab(&quot;Original EB Estimate&quot;) + ylab(&quot;EB Estimate w/ AB term&quot;) + scale_color_continuous(trans = &quot;log&quot;, breaks = 10 ^ (0:4)) # 对比 library(tidyr) lev &lt;- c(raw = &quot;Raw H / AB&quot;, original_eb = &quot;EB Estimate&quot;, new_eb = &quot;EB w/ Regression&quot;) career_eb_wAB %&gt;% filter(AB &gt;= 10) %&gt;% mutate(raw = H / AB) %&gt;% gather(type, value, raw, original_eb, new_eb) %&gt;% mutate(mu = ifelse(type == &quot;original_eb&quot;, prior_mu, ifelse(type == &quot;new_eb&quot;, mu, NA))) %&gt;% mutate(type = factor(plyr::revalue(type, lev), lev)) %&gt;% ggplot(aes(AB, value)) + geom_point() + geom_line(aes(y = mu), color = &quot;red&quot;) + scale_x_log10() + facet_wrap(~type) + xlab(&quot;At-Bats (AB)&quot;) + ylab(&quot;Estimate&quot;) 矫正后我们的数据更复合现实了，其实这是贝叶斯分层模型的一个简单版本，通过考虑更多因素，我们可以构建更复杂的模型来挖掘出我们所需要的信息 10.13.3 考虑更多因素 现在我们听说左利手跟右利手的表现可能不一样，所以我们要对模型进行完善，考虑把左右手参数加入模型 # 展示数据 career2 %&gt;% count(bats) ## # A tibble: 4 × 2 ## bats n ## &lt;fct&gt; &lt;int&gt; ## 1 B 808 ## 2 L 2814 ## 3 R 5587 ## 4 &lt;NA&gt; 653 # 排除NA career3 &lt;- career2 %&gt;% filter(!is.na(bats)) %&gt;% mutate(bats = relevel(bats, &quot;R&quot;)) # 重建模型 fit2 &lt;- gamlss(cbind(H, AB - H) ~ log(AB) + bats, data = career3, family = BB(mu.link = &quot;identity&quot;)) ## GAMLSS-RS iteration 1: Global Deviance = 92788 ## GAMLSS-RS iteration 2: Global Deviance = 73148 ## GAMLSS-RS iteration 3: Global Deviance = 68734 ## GAMLSS-RS iteration 4: Global Deviance = 68728 ## GAMLSS-RS iteration 5: Global Deviance = 68728 sigma &lt;- fitted(fit2, &quot;sigma&quot;)[1] df &lt;- tidyr::crossing(bats = c(&quot;L&quot;, &quot;R&quot;), AB = c(1, 10, 100, 1000, 10000)) df$mu &lt;- predict(fit2, what = &quot;mu&quot;, newdata = df) df &lt;- tidyr::crossing(df, x = seq(.1, .36, .0005)) df %&gt;% mutate(alpha = mu / sigma, beta = (1 - mu) / sigma, density = dbeta(x, alpha, beta)) %&gt;% ggplot(aes(x, density, color = factor(AB), lty = bats)) + geom_line() + labs(x = &quot;Batting average&quot;, y = &quot;Prior density&quot;, color = &quot;AB&quot;, lty = &quot;Batting hand&quot;) 存在先验概率的情况下，可以考虑考察随着击球数增长左右手的不同 df &lt;- tidyr::crossing(bats = c(&quot;L&quot;, &quot;R&quot;), AB = c(10, 100, 1000, 10000)) df %&gt;% mutate(H = .3 * AB, mu = predict(fit2, what = &quot;mu&quot;, newdata = df), sigma = predict(fit2, what = &quot;sigma&quot;, newdata = df, type = &quot;response&quot;), alpha0 = mu / sigma, beta0 = (1 - mu) / sigma, alpha1 = alpha0 + H, beta1 = beta0 + AB - H, estimate = alpha1 / (alpha1 + beta1), conf.low = qbeta(.025, alpha1, beta1), conf.high = qbeta(.975, alpha1, beta1), record = paste(H, AB, sep = &quot; / &quot;)) %&gt;% ggplot(aes(estimate, record, color = bats)) + geom_point() + geom_errorbarh(aes(xmin = conf.low, xmax = conf.high)) + labs(x = &quot;Estimate w/ 95% credible interval&quot;, y = &quot;Batting record&quot;, color = &quot;Batting hand&quot;) 另一个要考虑的因素是不同年份的平均击球率可能也有起伏 career3 %&gt;% mutate(decade = factor(round(year - 5, -1))) %&gt;% filter(AB &gt;= 500) %&gt;% ggplot(aes(decade, average)) + geom_boxplot() + theme(axis.text.x = element_text(angle = 90, hjust = 1)) + ylab(&quot;Batting average&quot;) # 用样条插值来进行拟合 library(splines) fit3 &lt;- gamlss(cbind(H, AB - H) ~ 0 + ns(year, df = 5) + bats + log(AB), data = career3, family = BB(mu.link = &quot;identity&quot;)) # 观察在击球数1000上先验概率的变化 plot_gamlss_fit &lt;- function(f) { career3 %&gt;% dplyr::select(year, bats) %&gt;% distinct() %&gt;% filter(bats != &quot;B&quot;) %&gt;% mutate(AB = 1000) %&gt;% mutate(mu = predict(f, what = &quot;mu&quot;, newdata = .), sigma = predict(f, what = &quot;sigma&quot;, newdata = ., type = &quot;response&quot;), alpha0 = mu / sigma, beta0 = (1 - mu) / sigma, conf_low = qbeta(.025, alpha0, beta0), conf_high = qbeta(.975, alpha0, beta0)) %&gt;% ggplot(aes(year, mu, color = bats, group = bats)) + geom_line() + geom_ribbon(aes(ymin = conf_low, ymax = conf_high), linetype = 2, alpha = .1) + labs(x = &quot;Year&quot;, y = &quot;Prior distribution (median + 95% quantiles)&quot;, color = &quot;Batting hand&quot;) } plot_gamlss_fit(fit3) 同时另一个问题是这些因素会交互影响 fit4 &lt;- gamlss(cbind(H, AB - H) ~ 0 + ns(year, 5) * bats + log(AB), data = career3, family = BB(mu.link = &quot;identity&quot;)) plot_gamlss_fit(fit4) Pitching %&gt;% dplyr::select(playerID, yearID, GS) %&gt;% distinct() %&gt;% inner_join(dplyr::select(People, playerID, throws)) %&gt;% count(yearID, throws, wt = GS) %&gt;% filter(!is.na(throws)) %&gt;% mutate(percent = n / sum(n)) %&gt;% filter(throws == &quot;L&quot;) %&gt;% ggplot(aes(yearID, percent)) + geom_line() + geom_smooth() + scale_y_continuous(labels = scales::percent_format()) + xlab(&quot;Year&quot;) + ylab(&quot;% of games with left-handed pitcher&quot;) 左右手之间的差距伴随年份在逐渐减少 players &lt;- tidyr::crossing(year = c(1915, 1965, 2015), bats = c(&quot;L&quot;, &quot;R&quot;), H = 30, AB = 100) players_posterior &lt;- players %&gt;% mutate(mu = predict(fit4, what = &quot;mu&quot;, newdata = players), sigma = predict(fit4, what = &quot;sigma&quot;, newdata = players, type = &quot;response&quot;), alpha0 = mu / sigma, beta0 = (1 - mu) / sigma, alpha1 = alpha0 + H, beta1 = beta0 + AB - H) players_posterior %&gt;% tidyr::crossing(x = seq(.15, .3, .001)) %&gt;% mutate(density = dbeta(x, alpha1, beta1)) %&gt;% ggplot(aes(x, density, color = bats)) + geom_line() + facet_wrap(~ year) + xlab(&quot;Batting average&quot;) + ylab(&quot;Posterior density&quot;) + ggtitle(&quot;Posterior distributions for batters with 30 / 100&quot;) 经验贝叶斯对先验概率的估计类似频率学派，但进行的又是贝叶斯分析 10.14 混合概率模型 用击球概率为例，击球手跟非击球手的概率分布是不一样的，那么实际看到的总体球员概率分布应该是一个混合在一起的两个独立分布 # 找出投球3次以上的人 pitchers &lt;- Pitching %&gt;% group_by(playerID) %&gt;% summarize(gamesPitched = sum(G)) %&gt;% filter(gamesPitched &gt; 3) # 参考上一章节的发现找出击球率稳定的选手 career &lt;- Batting %&gt;% filter(AB &gt; 0, lgID == &quot;NL&quot;, yearID &gt;= 1980) %&gt;% group_by(playerID) %&gt;% summarize(H = sum(H), AB = sum(AB), year = mean(yearID)) %&gt;% mutate(average = H / AB, isPitcher = playerID %in% pitchers$playerID) # 链接上名字 career &lt;- People %&gt;% tbl_df() %&gt;% dplyr::select(playerID, nameFirst, nameLast, bats) %&gt;% unite(name, nameFirst, nameLast, sep = &quot; &quot;) %&gt;% inner_join(career, by = &quot;playerID&quot;) 10.14.1 期望最大算法 将一个分布拆成两个，可以使用期望最大算法 set.seed(2017) # 先随机分为两组 starting_data &lt;- career %&gt;% filter(AB &gt;= 20) %&gt;% dplyr::select(-year, -bats, -isPitcher) %&gt;% mutate(cluster = factor(sample(c(&quot;A&quot;, &quot;B&quot;), n(), replace = TRUE))) # 观察效果 starting_data %&gt;% ggplot(aes(average, color = cluster)) + geom_density() library(VGAM) fit_bb_mle &lt;- function(x, n) { # dbetabinom.ab 是用n、alpha与beta作为参数的二项贝塔分布的似然度函数 ll &lt;- function(alpha, beta) { -sum(dbetabinom.ab(x, n, alpha, beta, log = TRUE)) } m &lt;- stats4::mle(ll, start = list(alpha = 3, beta = 10), method = &quot;L-BFGS-B&quot;, lower = c(0.001, .001)) ab &lt;- stats4::coef(m) data_frame(alpha = ab[1], beta = ab[2], number = length(x)) } # 看下初始参数 fit_bb_mle(starting_data$H, starting_data$AB) ## # A tibble: 1 × 3 ## alpha beta number ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 12.4 44.6 3860 # 看下随机分拆后的参数并生成各分组样本数的先验概率 fits &lt;- starting_data %&gt;% group_by(cluster) %&gt;% do(fit_bb_mle(.$H, .$AB)) %&gt;% ungroup() %&gt;% mutate(prior = number / sum(number)) fits ## # A tibble: 2 × 5 ## cluster alpha beta number prior ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 A 12.5 45.0 1891 0.490 ## 2 B 12.3 44.2 1969 0.510 算法优化的期望是将这两个分布分拆开，前面一次分拆已经产生微弱差异，下面就通过贝叶斯思想对数据更新这个差异重新分组让两者分开 assignments &lt;- starting_data %&gt;% dplyr::select(-cluster) %&gt;% tidyr::crossing(fits) %&gt;% mutate(likelihood = prior * VGAM::dbetabinom.ab(H, AB, alpha, beta)) %&gt;% group_by(playerID) %&gt;% top_n(1, likelihood) %&gt;% ungroup() # 去除掉原有分组，根据更新的后验概率重新分组 assignments ## # A tibble: 3,860 × 11 ## playerID name H AB average cluster alpha beta number prior ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 abbotje01 Jeff Abbott 11 42 0.262 B 12.3 44.2 1969 0.510 ## 2 abbotji01 Jim Abbott 2 21 0.0952 B 12.3 44.2 1969 0.510 ## 3 abbotku01 Kurt Abbott 475 1860 0.255 B 12.3 44.2 1969 0.510 ## 4 abbotky01 Kyle Abbott 3 31 0.0968 B 12.3 44.2 1969 0.510 ## 5 abercre01 Reggie Abercr… 86 386 0.223 B 12.3 44.2 1969 0.510 ## 6 abnersh01 Shawn Abner 110 531 0.207 B 12.3 44.2 1969 0.510 ## 7 abreubo01 Bobby Abreu 1607 5395 0.298 B 12.3 44.2 1969 0.510 ## 8 abreuto01 Tony Abreu 129 509 0.253 B 12.3 44.2 1969 0.510 ## 9 acevejo01 Jose Acevedo 8 101 0.0792 B 12.3 44.2 1969 0.510 ## 10 aceveju01 Juan Acevedo 6 65 0.0923 B 12.3 44.2 1969 0.510 ## # … with 3,850 more rows, and 1 more variable: likelihood &lt;dbl&gt; # 观察更新后概率分布 ggplot(assignments, aes(average, fill = cluster)) + geom_histogram() 不断重复这个过程，最终分拆数据（其实就是第一步分拆最重要，后面直接收敛了） set.seed(1987) iterate_em &lt;- function(state, ...) { fits &lt;- state$assignments %&gt;% group_by(cluster) %&gt;% do(mutate(fit_bb_mle(.$H, .$AB), number = nrow(.))) %&gt;% ungroup() %&gt;% mutate(prior = number / sum(number)) assignments &lt;- assignments %&gt;% dplyr::select(playerID:average) %&gt;% tidyr::crossing(fits) %&gt;% mutate(likelihood = prior * VGAM::dbetabinom.ab(H, AB, alpha, beta)) %&gt;% group_by(playerID) %&gt;% top_n(1, likelihood) %&gt;% ungroup() list(assignments = assignments, fits = fits) } library(purrr) # 使用purrr包存储中间结果 iterations &lt;- accumulate(1:5, iterate_em, .init = list(assignments = starting_data)) assignment_iterations &lt;- iterations %&gt;% map_df(&quot;assignments&quot;, .id = &quot;iteration&quot;) # 观察收敛过程 assignment_iterations %&gt;% ggplot(aes(average, fill = cluster)) + geom_histogram() + facet_wrap(~ iteration) fit_iterations &lt;- iterations %&gt;% map_df(&quot;fits&quot;, .id = &quot;iteration&quot;) # 两个分布的收敛过程 fit_iterations %&gt;% tidyr::crossing(x = seq(.001, .4, .001)) %&gt;% mutate(density = prior * dbeta(x, alpha, beta)) %&gt;% ggplot(aes(x, density, color = iteration, group = iteration)) + geom_line() + facet_wrap(~ cluster) 10.14.2 分配 得到每个选手在两个分布中后验概率后要对其进行分配，这里我们认为拆分出的两个分布其实就是是否是击球手的两个分组，由于两组重叠较多，直接分配会有困难 # 找6个击球数100的选手进行分配 batter100 &lt;- career %&gt;% filter(AB == 100) %&gt;% arrange(average) batter100 ## # A tibble: 7 × 8 ## playerID name bats H AB year average isPitcher ## &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; ## 1 dejesjo01 Jose de Jesus R 11 100 1990. 0.11 TRUE ## 2 gausmke01 Kevin Gausman L 12 100 2019. 0.12 TRUE ## 3 mahonmi02 Mike Mahoney R 18 100 2002. 0.18 FALSE ## 4 uriasju01 Julio Urias L 19 100 2018. 0.19 TRUE ## 5 cancero01 Robinson Cancel R 20 100 2007. 0.2 FALSE ## 6 buschmi01 Mike Busch R 22 100 1996. 0.22 FALSE ## 7 shealry01 Ryan Shealy R 32 100 2006. 0.32 FALSE # 前面算法得到的最终结果 fit_iterations ## # A tibble: 6 × 6 ## iteration cluster alpha beta number prior ## &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 A 12.5 45.0 1891 0.490 ## 2 1 B 12.3 44.2 1969 0.510 ## 3 2 B 12.4 44.6 3860 1 ## 4 3 B 12.4 44.6 3860 1 ## 5 4 B 12.4 44.6 3860 1 ## 6 5 B 12.4 44.6 3860 1 final_parameters &lt;- fit_iterations %&gt;% filter(iteration == 1) final_parameters ## # A tibble: 2 × 6 ## iteration cluster alpha beta number prior ## &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 A 12.5 45.0 1891 0.490 ## 2 1 B 12.3 44.2 1969 0.510 # 观察球员位置 final_parameters %&gt;% tidyr::crossing(x = 0:45) %&gt;% mutate(density = prior * VGAM::dbetabinom.ab(x, 100, alpha, beta)) %&gt;% ggplot(aes(x, density)) + geom_line(aes(color = cluster)) + geom_vline(aes(xintercept = H), data = batter100, lty = 2) + geom_text(aes(x = H, y = -.022, label = name), data = batter100, hjust = 1, vjust = 1, angle = 270) + labs(x = &quot;H (out of 100 at-bats)&quot;, y = &quot;Likelihood of this H out of 100 hits&quot;) # 根据贝叶斯理论，我们可以用在A分组的似然度比上两个分组似然度的和得到后验概率 final_parameters %&gt;% tidyr::crossing(H = 1:40) %&gt;% transmute(H, cluster, likelihood = prior * VGAM::dbetabinom.ab(H, 100, alpha, beta)) %&gt;% spread(cluster, likelihood) %&gt;% mutate(probabilityA = A /(A + B)) %&gt;% ggplot(aes(H, probabilityA)) + geom_line() + geom_vline(aes(xintercept = H), data = batter100, lty = 2) + geom_text(aes(x = H, y = 0, label = name), data = batter100, hjust = 1, vjust = 1, angle = 270) + labs(x = &quot;H (out of 100 at-bats)&quot;, y = &quot;(Likelihood if pitcher) / (Likelihood if pitcher + Likelihood if not)&quot;, title = &quot;Posterior probability a player is in the pitcher cluster&quot;) 通过构建后验概率，我们可以直接对结果基于概率进行分组 career_likelihoods &lt;- career %&gt;% filter(AB &gt; 20) %&gt;% tidyr::crossing(final_parameters) %&gt;% mutate(likelihood = prior * VGAM::dbetabinom.ab(H, AB, alpha, beta)) %&gt;% group_by(playerID) %&gt;% mutate(posterior = likelihood / sum(likelihood)) career_assignments &lt;- career_likelihoods %&gt;% top_n(1, posterior) %&gt;% ungroup() # 对比这种分组与实际数据的结果 career_assignments %&gt;% filter(posterior &gt; .8) %&gt;% count(isPitcher, cluster) %&gt;% spread(cluster, n) ## # A tibble: 0 × 1 ## # … with 1 variable: isPitcher &lt;lgl&gt; 这样基于对概率分布的观察，我们可以实现有现实意义的分组，对分组的改进则需要对数据的进一步理解 10.14.3 经验贝叶斯收缩 混合模型下前面所做的工作都需要重新考虑 # 观察击球数100选手的后验概率分布 batting_data &lt;- career_likelihoods %&gt;% ungroup() %&gt;% filter(AB == 100) %&gt;% mutate(name = paste0(name, &quot; (&quot;, H, &quot;/&quot;, AB, &quot;)&quot;), name = reorder(name, H), alpha1 = H + alpha, beta1 = AB - H + beta) batting_data %&gt;% tidyr::crossing(x = seq(0, .4, .001)) %&gt;% mutate(posterior_density = posterior * dbeta(x, alpha1, beta1)) %&gt;% group_by(name, x) %&gt;% summarize(posterior_density = sum(posterior_density)) %&gt;% ggplot(aes(x, posterior_density, color = name)) + geom_line(show.legend = FALSE) + geom_vline(aes(xintercept = average), data = batting_data, lty = 2) + facet_wrap(~ name) + labs(x = &quot;Batting average (actual average shown as dashed line)&quot;, y = &quot;Posterior density after updating&quot;) 此时不太好判断属于哪一分布，可采用后验概率对平均分布进行加权 eb_shrinkage &lt;- career_likelihoods %&gt;% mutate(shrunken_average = (H + alpha) / (AB + alpha + beta)) %&gt;% group_by(playerID) %&gt;% summarize(shrunken_average = sum(posterior * shrunken_average)) # 观察加权分布 eb_shrinkage %&gt;% inner_join(career) %&gt;% filter(AB &gt; 50) %&gt;% gather(type, value, average, shrunken_average) %&gt;% mutate(type = ifelse(type == &quot;average&quot;, &quot;Raw batting average&quot;, &quot;Average posterior&quot;), type = relevel(factor(type), &quot;Raw batting average&quot;)) %&gt;% ggplot(aes(AB, value)) + geom_point() + facet_wrap(~ type) + scale_x_log10() + ylab(&quot;Estimate&quot;) - 收敛后的分布会朝向两个中心而不是一个，并非所有之前的方法（例如区间估计）都可以适用到混合模型里，需要根据实际情况进行分析 10.15 模拟验证结果 上面的经验贝叶斯推断大都是给出的结果，我们需要对其进行模拟验证 pitchers &lt;- Pitching %&gt;% group_by(playerID) %&gt;% summarize(gamesPitched = sum(G)) %&gt;% filter(gamesPitched &gt; 3) career &lt;- Batting %&gt;% filter(AB &gt; 0) %&gt;% anti_join(pitchers, by = &quot;playerID&quot;) %&gt;% group_by(playerID) %&gt;% summarize(H = sum(H), AB = sum(AB)) # 从数据中找到贝塔分布的两个参数 library(ebbr) prior &lt;- career %&gt;% ebb_fit_prior(H, AB) prior ## Empirical Bayes binomial fit with method mle ## Parameters: ## # A tibble: 1 × 2 ## alpha beta ## &lt;dbl&gt; &lt;dbl&gt; ## 1 72.1 216. # 用这两个参数生成球员的击球概率 alpha0 &lt;- tidy(prior)$alpha beta0 &lt;- tidy(prior)$beta qplot(rbeta(10000, alpha0, beta0)) # 击球数使用原始数据 ggplot(career, aes(AB)) + geom_histogram() + scale_x_log10() # 构建仿真数据 set.seed(2017) career_sim &lt;- career %&gt;% mutate(p = rbeta(n(), alpha0, beta0), H = rbinom(n(), AB, p)) career_sim ## # A tibble: 11,071 × 4 ## playerID H AB p ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 aaronha01 3635 12364 0.298 ## 2 aaronto01 247 944 0.248 ## 3 abadan01 3 21 0.273 ## 4 abadijo01 15 49 0.197 ## 5 abbated01 765 3044 0.248 ## 6 abbeych01 476 1756 0.264 ## 7 abbotda01 1 7 0.190 ## 8 abbotfr01 132 513 0.250 ## 9 abbotje01 129 596 0.243 ## 10 abbotku01 535 2044 0.260 ## # … with 11,061 more rows 10.15.1 模拟对分布参数的估计 生产数据后我们可以估计分布参数，看能否与模拟值对应 career_sim_eb &lt;- career_sim %&gt;% add_ebb_estimate(H, AB) career_sim_gathered &lt;- career_sim_eb %&gt;% rename(Shrunken = .fitted, Raw = .raw) %&gt;% gather(type, estimate, Shrunken, Raw) # 观察是否能收敛数据 career_sim_gathered %&gt;% filter(AB &gt;= 10) %&gt;% ggplot(aes(p, estimate, color = AB)) + geom_point() + geom_abline(color = &quot;red&quot;) + geom_smooth(method = &quot;lm&quot;, color = &quot;white&quot;, lty = 2, se = FALSE) + scale_color_continuous(trans = &quot;log&quot;, breaks = c(10, 100, 1000, 10000)) + facet_wrap(~ type) + labs(x = &quot;True batting average (p)&quot;, y = &quot;Raw or shrunken batting average&quot;, title = &quot;Empirical Bayes shrinkage reduces variance, but causes bias&quot;, subtitle = &quot;Red line is x = y; dashed white line is a linear fit&quot;) 我们可以看到，估计方差有了一定收敛，但出现了一定偏差，可参考统计学习中方差-偏差权衡的描述 可以用均方误来衡量，此处虽牺牲了偏差，但整体误差降低了 \\[\\mbox{MSE}=\\frac{1}{n}\\sum_{1}^{n}(p-\\hat{p})^2\\] career_sim_gathered %&gt;% group_by(type) %&gt;% summarize(mse = mean((estimate - p) ^ 2)) ## # A tibble: 2 × 2 ## type mse ## &lt;chr&gt; &lt;dbl&gt; ## 1 Raw 0.0146 ## 2 Shrunken 0.000347 注意到击球数可能影响收敛，所以可以探索其对均方误的影响 metric_by_bin &lt;- career_sim_gathered %&gt;% group_by(type, AB = 10 ^ (round(log10(AB)))) %&gt;% summarize(mse = mean((estimate - p) ^ 2)) ggplot(metric_by_bin, aes(AB, mse, color = type)) + geom_line() + scale_x_log10() + scale_y_log10() + labs(x = &quot;Number of at-bats (AB)&quot;, y = &quot;Mean-squared-error within this bin (note log scale)&quot;, title = &quot;Mean squared error is higher with raw estimate, especially for low AB&quot;) 击球数越多，均方误越低，此时可进一步探索 library(scales) # 观察斜率p值变化 career_sim_gathered %&gt;% mutate(AB = 10 ^ (round(log10(AB)))) %&gt;% filter(AB &gt; 1) %&gt;% nest(-type, -AB) %&gt;% mutate(model=map(data, ~ tidy(lm(estimate ~ p, .)))) %&gt;% unnest(model) %&gt;% filter(term == &quot;p&quot;) %&gt;% ggplot(aes(AB, estimate, color = type)) + geom_line() + scale_x_log10(breaks = c(10, 100, 1000, 10000)) + geom_hline(yintercept = 1, lty = 2) + labs(x = &quot;Number of at-bats (AB)&quot;, y = &quot;Slope of estimate/p within this bin&quot;, title = &quot;Shrunken estimates introduce bias for low AB&quot;, subtitle = &quot;Note that an unbiased estimate would have a slope of 0&quot;) # 分层 career_sim_gathered %&gt;% mutate(ab_bin = cut(AB, c(0, 10, 100, 1000, Inf), labels = c(&quot;1-10&quot;, &quot;11-100&quot;, &quot;101-1000&quot;, &quot;1000+&quot;))) %&gt;% ggplot(aes(p, estimate, color = AB)) + geom_point() + geom_abline(color = &quot;red&quot;) + geom_smooth(method = &quot;lm&quot;, color = &quot;gray&quot;, lty = 2, se = FALSE) + scale_color_continuous(trans = &quot;log&quot;, breaks = c(10, 100, 1000, 10000)) + facet_grid(ab_bin ~ type, scales = &quot;free_y&quot;) + labs(x = &quot;True batting average (p)&quot;, y = &quot;Raw or shrunken estimate&quot;, title = &quot;Empirical Bayes shrinkage reduces variance, but introduces bias&quot;, subtitle = &quot;Red line is x = y; dashed white line is a linear fit&quot;) 击球数越多，越接近真相 10.15.2 区间估计 检验区间估计是否覆盖95%的真值 career_sim_eb %&gt;% summarize(coverage = mean(.low &lt;= p &amp; p &lt;= .high)) ## # A tibble: 1 × 1 ## coverage ## &lt;dbl&gt; ## 1 0.949 观察不同区间的覆盖范围 sim_prior &lt;- ebb_fit_prior(career_sim, H, AB) estimate_by_cred_level &lt;- data_frame(level = seq(.5, .98, .02)) %&gt;% mutate(model=map(level, ~ augment(sim_prior, career_sim, cred_level = .))) %&gt;% unnest(model) estimate_by_cred_level %&gt;% group_by(level) %&gt;% mutate(cover = .low &lt;= p &amp; p &lt;= .high) %&gt;% summarize(coverage = mean(cover)) %&gt;% ggplot(aes(level, coverage)) + geom_point() + geom_abline(color = &quot;red&quot;) + labs(x = &quot;Level of credible interval&quot;, y = &quot;Probability credible interval contains the true value&quot;) 结果基本吻合，说明区间估计也比较准 10.15.3 错误发现率 看一下进入名人堂的人 pt &lt;- career_sim_eb %&gt;% add_ebb_prop_test(.3, sort = TRUE) # 错误发现率控制为10% hall_of_fame &lt;- pt %&gt;% filter(.qvalue &lt;= .1) mean(hall_of_fame$p &lt; .3) ## [1] 0.0714 # 观察整体错误发现率的变动 pt %&gt;% mutate(true_fdr = cummean(p &lt; .3)) %&gt;% ggplot(aes(.qvalue, true_fdr)) + geom_line() + geom_abline(color = &quot;red&quot;) + labs(x = &quot;q-value&quot;, y = &quot;True FDR at this q-value threshold&quot;) 10.15.4 重复模拟 为防止意外或运气可以重复模拟看看 set.seed(2019) sim_replications &lt;- career %&gt;% tidyr::crossing(replication = 1:50) %&gt;% mutate(p = rbeta(n(), alpha0, beta0), H = rbinom(n(), AB, p)) sim_replications sim_replication_models &lt;- sim_replications %&gt;% nest(-replication) %&gt;% mutate(prior = purrr::map(data, ~ ebb_fit_prior(., H, AB))) # 估计参数 sim_replication_priors &lt;- sim_replication_models %&gt;% mutate(model= map(prior, tidy)) %&gt;% dplyr::select(-c(data,prior)) %&gt;% unnest(model) sim_replication_priors true_values &lt;- data_frame(parameter = c(&quot;alpha&quot;, &quot;beta&quot;, &quot;mean&quot;), true = c(alpha0, beta0, alpha0 / (alpha0 + beta0))) sim_replication_priors %&gt;% gather(parameter, value, -replication) %&gt;% inner_join(true_values, by = &quot;parameter&quot;) %&gt;% ggplot(aes(1, value)) + geom_boxplot() + geom_hline(aes(yintercept = true), color = &quot;red&quot;, lty = 2) + facet_wrap(~ parameter, scales = &quot;free_y&quot;) + labs(x = &quot;&quot;, y = &quot;Estimated parameter (true value shown as red line)&quot;, title = &quot;Estimated hyperparameters across 50 replications&quot;) # 估计区间与假设检验 ## 估计均方误 sim_replication_au &lt;- sim_replication_models %&gt;% mutate(model=map2(prior, data, augment)) %&gt;% unnest(model) sim_replication_mse &lt;- sim_replication_au %&gt;% rename(Raw = .raw, Shrunken = .fitted) %&gt;% gather(type, estimate, Raw, Shrunken) %&gt;% group_by(type, replication) %&gt;% summarize(mse = mean((estimate - p) ^ 2)) ggplot(sim_replication_mse, aes(type, mse)) + geom_boxplot() + ylab(&quot;Mean squared error across 50 replications&quot;) ## 估计区间 sim_replication_au %&gt;% mutate(cover = .low &lt;= p &amp; p &lt;= .high) %&gt;% group_by(replication) %&gt;% summarize(coverage = mean(cover)) %&gt;% ggplot(aes(coverage)) + geom_histogram(binwidth = .001) + labs(x = &quot;% of time true value was in a 95% confidence interval&quot;, title = &quot;95% credible interval is well calibrated across replications&quot;) sim_replication_intervals &lt;- sim_replication_models %&gt;% expand_grid(cred_level = c(seq(.5, .9, .05), .95)) %&gt;% mutate(model=pmap(list(prior, data, cred_level = cred_level), augment)) %&gt;% unnest(model) %&gt;% dplyr::select(replication, cred_level, p, .low, .high) sim_replication_intervals %&gt;% mutate(cover = .low &lt;= p &amp; p &lt;= .high) %&gt;% group_by(replication, cred_level) %&gt;% summarize(coverage = mean(cover)) %&gt;% ggplot(aes(cred_level, coverage, group = replication)) + geom_line(alpha = .3) + geom_abline(color = &quot;red&quot;) + labs(x = &quot;Credibility level&quot;, y = &quot;% of credible intervals in this replication that contain the true parameter&quot;, title = &quot;Credible intervals are well calibrated across 50 replications&quot;, subtitle = &quot;Red line is x = y&quot;) # q值的稳定性 sim_replication_prop_tests &lt;- sim_replication_au %&gt;% nest(-replication) %&gt;% mutate(model=map(data, add_ebb_prop_test, threshold = .3, sort = TRUE)) sim_replication_prop_tests %&gt;% group_by(replication) %&gt;% mutate(fdr = cummean(p &lt; .3)) %&gt;% ggplot(aes(.qvalue, fdr, group = replication)) + geom_line(alpha = .3) + geom_abline(color = &quot;red&quot;) + labs(x = &quot;Q-value threshold&quot;, y = &quot;Proportion of false discoveries below this threshold&quot;, title = &quot;Q-value successfully controls FDR across 50 replications&quot;) 10.16 网络资源 贝叶斯方法 贝叶斯镜像 "],["why.html", "第11章 因果分析 11.1 Introduction 11.2 Causal Information 11.3 Theoretical Background 11.4 Methods for Identification and Estimation 11.5 链接", " 第11章 因果分析 11.1 Introduction “Impact assessment, simply defined, is the process of identifying the future consequences of a current or proposed action.” (IAIA, 2009) “Policy assessment seeks to inform decision-makers by predicting and evaluating the potential impacts of policy options.” (Adelle and Weiland, 2012) “… I see no greater impediment to scientific progress than the prevailing practice of focusing all our mathematical resources on probabilistic and statistical inferences while leaving causal considerations to the mercy of intuition and good judgment.” (Pearl, 1999) 11.2 Causal Information 11.2.1 Target practical framework for causal effect estimation in the context of policy assessment and impact analysis, and in the absence of experimental data 11.2.2 Causal sources Causal Inference by Experiment: Randomized experiments Causal Inference from Observational Data and Theory: Existing data or Big data 11.2.3 Identification and Estimation Process Causal Identification: domain knowledge based Computing the Effect Size: Bayesian networks 11.3 Theoretical Background 11.3.1 Potential Outcomes Framework \\(Y_{i,1}\\) Potential outcome of individual i given treatment T=1 (e.g. taking two Aspirins) \\(Y_{i,0}\\) Potential outcome of individual i given treatment T=0 (e.g. drinking a glass of water) individual-level causal effect (ICE) \\(ICE=Y_{i,1} −Y_{i,0}\\) average causal effect (ACE) \\(ACE = E[Y_{i,1}] −E[Y_{i,0}]\\) 11.3.2 Causal Identification \\(Y_{i,1}\\) (treatment) and \\(Y_{i,0}\\) (non-treatment) can never be both observed for the same individual at the same time Association S \\(S = E[Y_1|T = 1] - E[Y_0|T = 0]\\) S is not the same with ACE association does not imply causation randomized experiment 11.3.2.1 Ignorability \\((Y_1,Y_0) \\upmodels T\\), \\(Y_1\\) and \\(Y_0\\) must be jointly independent of the treatment assignment \\((Y_1,Y_0) \\upmodels T|X\\) for realobservational studies, conditional on variables X, \\(Y_1\\), and \\(Y_0\\) are jointly independent of T, the assignment mechanism \\(ACE|X = E[Y_1|X] - E[Y_0|X] = E[Y_1|T=1,X] - E[Y_0|􏰀T = 0,X] = E[Y|􏰀T = 1,X] - E[Y|􏰀T =0,X] = S|􏰀X\\) 11.3.2.2 Assumptions Causal inference requires causal assumptions 11.4 Methods for Identification and Estimation 11.4.1 Directed Acyclic Graphs(DAG) for Identification DAGs Are Nonparametric A Node represents a variable in a domain, regardless of whether it is observable or unobservable A Directed Arc has the appearance of an arrow and represents a potential causal effect. The arc direction indicates the assumed causal direction, i.e. “A→B” means “A causes B.” A Missing Arc encodes the definitive absence of a direct causal effect, i.e. no arc between A and B means that there exists no direct causal relationship between A and B and vice versa. As such, a missing arc repre- sents an assumption 11.4.2 Indirect Connection A causes B via node C \\(A \\nupmodels B\\) and \\(A \\upmodels B|C\\) 11.4.3 Common Cause C causes both A and B \\(A \\nupmodels B\\) and \\(A \\upmodels B|C\\) 11.4.4 Common Effect C is the common effect of A and B \\(A \\upmodels B\\) and \\(A \\nupmodels B|C\\) 11.4.5 Example: Simpson’s Paradox 11.5 链接 因果推断 Google的因果分析包 "],["neta.html", "第12章 网络分析 12.1 节点属性 12.2 网络集群 12.3 随机网络模型 12.4 无尺度网络 12.5 无尺度的生成 - Barabási-Albert 模型 12.6 网络的进化 - Bianconi-Barabási 模型 12.7 度相关现象 12.8 网络稳健性 12.9 网络回归 12.10 网络扩散行为 12.11 网络可视化", " 第12章 网络分析 12.1 节点属性 最早是七桥问题 网络里节点（node）与连接（link）对应图论里的交点（vertex）与边（edge） (N,L)表示一个包含节点与连接的系统 节点的度指的是节点对内对外的连接数 网络的度指的是所有节点的平均度，无方向的除2 均值 \\(&lt;x^n&gt; = \\frac{x_1^n+x_2^n+...+x_N^n}{N} = \\frac{1}{N}\\sum_{i=1}^N x_i^n\\) 方差 \\(\\sigma_x = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N (x_i-&lt;x&gt;)^2}\\) 度的概率分布 \\(p_x = \\frac{1}{N}\\sum_i \\delta_{x,x_i}\\) \\(\\sum_ip_x = 1\\) 连接矩阵 \\(A_{ij}\\) \\(A_{ij} = 1\\) 表示点有链接 无方向的上下矩阵对称 非加权网络中\\(A_{ij}\\) 等于 1 或 0 无方向网络\\(A_{ij} = A_{ji}\\) 连接矩阵通常是稀疏的 全连接网络 \\(L_{max} = \\frac{N(N-1)}{2}\\) 平均度 \\(&lt;k&gt; = N-1\\) 密度，存在的边与可能存在边的比值 介数中心性，它代表了某节点与其他节点之间的互动程度，具有较高介数中心性的节点控制网络信息流 平均路径长度，表示网络的平均节点两两最短距离 半径，表示网络的最大的节点两两最短距离 组分，几个子网络 二分图，顶点可分成互斥独立集U和V 聚集系数，邻居互相连接的比例 \\(C_i = \\frac{2e_i}{k_i(k_i-1)}\\) \\(C_i =1\\) 表示全连接，0表示全不连接，你朋友互相认识的概率 12.2 网络集群 假设1:集群存在与节点的连接关系中 假设2:集群内部联通度高 假设3:随机网络里没有集群 假设4:最大模块假设 \\(M=\\sum_{c=1}^{n_c}[\\frac{l_c}{L}-(\\frac{k_c}{2L})^2]\\) 集群是否存在无法验证，所以只有假设 集群存在共享节点 算法很多， Louvain 与 the Infomap 比较快（\\(o(NlogN)\\)），cfinder 比较慢(\\(o(e^N)\\)) 集群也存在生成与进化问题 模块化指数（modularity index）群组内边的比例 \\(Q = \\frac{1}{2m}(A_{ij}-\\frac{k_ik_j}{2m})\\delta(c_i,c_j)\\) m 是总边数，\\(\\delta(c_i,c_j)\\) 是Kroenecker delta function，当两个节点属于一个模块时为1，否则为0 寻找集群本质是最大化模块化指数，目前并无最优算法 Newman &amp; Girvan 2004 利用边介数来寻找社群 Clauset et al. 2004 分层算法，对大网络稀疏网络设计 Pons &amp; Latapy 2005 基于随机行走的凝聚算法 Reichardt &amp; Bornholdt 2006 基于磁子低能态算法 Newman 2006 基于模块矩阵与特征向量的算法 同质性（homophily 或 assortment），考虑节点性质的均一性 同质化系数（assortment coefficient）\\(r=\\frac{\\sum_{ij}(A_{ij}-k_ik_j/2,)x_ix_j}{\\sum_{ij}(k_i\\delta_{ij}-k_ik_j/2,)x_ix_j}\\)，其中\\(k_i\\delta_{ij}\\) 是节点i排除与节点j相连后的度，类似皮尔逊相关系数，越大均质化程度越高 12.3 随机网络模型 任意两点链接概率固定，符合二项分布的概率，度取决于概率与节点数 稀疏网络近似符合泊松分布，参数只有平均度 100点之下还是用二项分布 度是泊松分布 随机网络里出现高度节点的概率很低，与现实不符 平均度为1，也就是概率为\\(\\frac{1}{N}\\)时，随机网络可出现大节点。小于1时网络高度节点的增长赶不上节点数增长。到了1时出现临界点，大的节点大概是 \\(N^{\\frac{2}{3}}\\) 。当平均度达到 \\(lnN(p&gt;lnN/N)\\) 时，所有节点连接在一起。 真实世界里平均度大于1小于\\(lnN\\)，也就是存在大节点，但并不完全贯通，处于亚临界与全联通之间，为超临界状态 随机网络里节点数固定，单总距离数 \\(N(d)\\approx 1+&lt;k&gt;+&lt;k&gt;^2+...+&lt;k&gt;^d = \\frac{&lt;k&gt;^{d+1}-1}{&lt;k&gt;-1}\\) 最大距离 \\(N(d_{max})\\approx N \\approx &lt;k&gt;^{d_{max}}\\) 距离 \\(d_{max} \\approx\\frac{lnN}{ln&lt;k&gt;}\\) 网络连接越密集，平均距离越短 互联网平均距离 \\(&lt;d&gt; \\approx 0.35+0.89lnN\\) 小世界特性，随机网络里平均距离比较短 聚集系数，邻居互相连接的比例 \\(C_i = \\frac{2&lt;L_i&gt;}{k_i(k_i-1)} = p = \\frac{&lt;k&gt;}{N}\\) Watts-Strogatz 小世界模型，低平均距离与高聚集系数，处于完全聚集长距离的正则网络与不聚集短距离的随机网络之间 12.4 无尺度网络 度的概率分布事符合幂律的 \\(log p_k = -\\gamma logCk+b\\) ，其中\\(\\gamma\\)是度指数 因为 \\(\\sum_{k=1}^\\infty p_k = 1\\)，所以 \\(C = \\frac{1}{\\sum_{k=1}^{\\infty}k^{-\\gamma}} = \\frac{1}{\\zeta(\\gamma)}\\) 后面那个是 Riemann-zeta 函数，因此概率 \\(p_k = \\frac{k^{-\\gamma}}{\\zeta(\\gamma)}\\) 最大的度 \\(k_{max} = k_{min}N^{\\frac{1}{\\gamma -1}}\\) 节点数越多，最大节点数越大，比随机网络大很多 无尺度主要是说n阶矩的分布 \\(&lt;k^n&gt; = C\\frac{k_{max}^{n-\\gamma+1} - k_{min}^{n-\\gamma+1}}{n-\\gamma+1}\\) ，多数无尺度网络的 \\(\\gamma\\) 在2-3之间，因此除了一阶矩以外，所有的高阶矩都会非常大，随机网络则有尺度 超小特性，平均距离要比随机网络小很多，\\(\\gamma =2\\) 平均距离是常数，2-3之间为\\(lnlnN\\)，3为\\(\\frac{lnN}{lnlnN}\\)，大于3为\\(lnN\\)（小世界网络）。在无尺度网络里大节点会缩小距离。 12.5 无尺度的生成 - Barabási-Albert 模型 网络的生长存在选择性依附，新节点会依附在度更高的节点上 生长概率 \\(\\prod (K_i) = \\frac{k_i}{\\sum_jk_j}\\) 度动力学 \\(\\frac{dk_i}{dt} = m\\prod(k_i) = m\\frac{k_i}{\\sum_{j=1}^{N-1}k_j}\\) m个连接 \\(\\sum_{j=1}^{N-1}k_j = 2mt-m\\) 整理后得到 \\(k_i(t) = m(\\frac{t}{t_i})^{\\beta}\\)，\\(\\beta\\) 为0.5 12.6 网络的进化 - Bianconi-Barabási 模型 选择依附会导致后来的成为节点概率低，无法解释现实世界里后来居上的现象 生长概率\\(\\prod (K_i) = \\frac{\\eta_ik_i}{\\sum_j\\eta_i k_j}\\) \\(\\eta\\) 代表适应度（fitness） 后来者适应度如果高，其度也很超过先来的 互联网适应度与概率指数分布，期刊适应度峰分布 物理机制可对应 波色-爱因斯坦凝聚态，适应度对应能量，新节点对应能级上新粒子，节点度对应能级上的粒子数。波色-爱因斯坦凝聚态可以无限吸引新粒子，因此不再无尺度，出现强者恒强 还要考虑节点删除与老化 12.7 度相关现象 大节点似乎不连接大节点，小节点总是连接小节点 两个节点连接概率 \\(p_{k,k&#39;} = \\frac{kk&#39;}{2L}\\) 神经网络是随机连接，符合概率 匹配性网络（assortative network），大节点互相连接，小节点只连接小节点，光环效应 非匹配性网络（disassortative network），大节点连接小节点但互相不连接 度相关矩阵 \\(e_{ij}\\)且\\(\\sum_{i,j}e_{ij} = 1\\) 度的概率 \\(q_k = \\frac{kp_k}{&lt;k&gt;}\\)，因此 \\(\\sum_je_{ij} = q_i\\) 单一节点度相关性 \\(k_{nn}(k_i) = \\frac{1}{k_i}\\sum_{j=1}^NA_{ij}k_j\\) 网络总相关性 \\(k_{nn}(k) = \\sum_{k&#39;}k&#39;P(k&#39;|k)\\) 神经网络里 \\(k_{nn}(k)=\\frac{&lt;k^2&gt;}{k}\\) 近似公式 \\(k_{nn}(k)=ak^{\\mu}\\) 神经网络 \\(\\mu = 0\\)，匹配性网络科学家合作网络 \\(\\mu&gt;0\\)，非匹配性网络代谢网络 \\(\\mu&lt;0\\) 度相关系数 \\(r=\\sum_{jk}\\frac{jk(e_{jk}-q_{j}q_{k})}{\\sigma^2}\\)，其中\\(\\sigma^2=\\sum_{k}k^2q_k - [\\sum_kkq_k]^2\\) 度相关系数\\(r\\)与相关指数\\(\\mu\\)假设不同但基本相关 朋友悖论：朋友总比你受欢迎 真实网络存在度相关，改变度相关会改变网络性质，对网络功能的进一步描述 模型生成的配置模型与隐参数模型可根据度来生成模型 静态生成模型是非匹配或随机网络 当\\(\\gamma&gt;3\\)，动态生成模型可能是弱匹配网络 12.8 网络稳健性 去掉节点后网络功能性的影响，复原能力与冗余机制是稳健性保障 渗透理论（percolation），少量节点去除后不影响整体，但超过关键点后会碎裂成小集群，林火理论 Malloy-Reed 法则：\\(\\frac{&lt;k^2&gt;}{k}&gt;2\\) 判断是否存在大组分 随机错误 \\(f_c = 1-\\frac{1}{\\frac{&lt;k^2&gt;}{&lt;k&gt;}-1}\\) 随机网络 \\(f_c^{ER}=1-\\frac{1}{&lt;k&gt;}\\) 无尺度网络二阶矩很大，所以容错高 提高稳健性 \\(f_c&gt;f_c^{ER}\\) 遭受攻击时 \\(f_c^{\\frac{2-\\gamma}{1-\\gamma}}=2+\\frac{2-\\gamma}{1-\\gamma}k_{min}(f_c^{\\frac{3-\\gamma}{1-\\gamma}}-1)\\) 如果优先攻击高度节点，那么稳健性会很低，随机进攻影响不大 攻击会造成级联反应，最稳健的网络一个中心节点，其余节点度相同，非无尺度网络 拉萨路效应（Lazarus effect）：一个突变细菌继续敲除基因后会死而复生，继续繁殖，相当于林火模型里放任小火堆 12.9 网络回归 网络间的回归分析 Mantel Test 可用来检测矩阵相关性 Quadratic Assignment Procedure 是Mantel检测的回归版 The Multiple Regression Quadratic Assignment Procedure 是QAP的多元回归版 12.10 网络扩散行为 节点间连接存在系统意义，有利于物质能量信息的传输 不合群传播通过试错，后面越来越慢 社群传播通过模仿，S型学习曲线，存在高速增长 12.11 网络可视化 force-directed algorithm 最优化布局：节点间距离最大，有连接的节点距离最小 常见的有 Fruchterman-Reingold (1991) 算法、Kamada &amp; Kawai (1989) 算法、Davidson &amp; Harel (1996) 算法及“GEM” (Frick et al. 1995) 算法 "],["game.html", "第13章 博弈论 13.1 术语 13.2 支配策略（dominate strategy） 13.3 最佳回应（Best respinse） 13.4 纳什均衡（Nash Equilibrium） 13.5 帕累托最优（Pareto Optimality） 13.6 混合策略（Mixed stratergies） 13.7 寻找纳什均衡 13.8 被支配策略（dominated strategy） 13.9 最大最小策略（Maxmin strategies） 13.10 扩展形式博弈 13.11 完美子博弈 13.12 信息不对称扩展形式博弈 13.13 混合与行为策略 13.14 重复博弈 13.15 随机博弈（stochastic game） 13.16 虚拟行动（fictitious play） 13.17 无悔学习（No-regret learning） 13.18 无限重复博弈的平衡 13.19 贝叶斯博弈 13.20 联盟博弈 13.21 夏普利值（Shapley Value） 13.22 核心 13.23 选举 13.24 机制设计 13.25 VCG机制 13.26 拍卖", " 第13章 博弈论 13.1 术语 博弈论说白了就是讲两方势力在一件事上为了自己的最大利益所采取的行动或决策的理论 参与者（players） \\(N= {1,...,n}\\) 参与者 \\(i\\) 有一组行动（Actions），行动的集合 \\(a=(a_1,...,a_n) \\in A=A_1 \\times A_2 \\times ... \\times A_n\\) 参与者 \\(i\\) 的每个行为的收益（Payoffs）都可以用 \\(u_i:A \\rightarrow \\Re\\) 这个函数表示 \\(u_i(a)\\) 表示某个行为产生的收益，\\(u = (u_i,...,u_n)\\)是效用函数的集合 n个参与者的标准博弈（normal form） \\(\\langle N,A,u \\rangle\\) 两人博弈可以用矩阵（matrix）来描述，行代表选手1，列代表选手2，行对应选手1的行动 \\(a_1 \\in A_1\\)，列对应选手2的行动 \\(a_2 \\in A_2\\)，每个单元列出每个参与者的收益，先行选手，后列选手 纯竞争博弈（Games of Pure competition）：两个参与者收益对立且对于所有行动集合 \\(a \\in A, u_1(a)+u_2(a) = c\\)，\\(c\\)是常数，零和博弈是一个常数为0的纯竞争博弈，此时我们只用考虑一个参与者的收益函数就可以了 13.2 支配策略（dominate strategy） 行动单一称为纯策略（pure strategies）有一定概率分布的行动策略称为混合策略（mixed strategies） 对于一个参与者，不论其它参与者采取任何策略，某策略都会得到最大的收益 \\(a_i \\in a_i\\) 为强支配策略当且仅当参与者\\(i\\) 的收益 \\(u_i(a_i,a_{-i}) &gt; u_i(a&#39;_i,a_{-i})\\)，如果 \\(a&#39;_i = a_i\\)，那么为弱支配策略 13.3 最佳回应（Best respinse） 对于一个参与者，当已知其他参与者的行为后，收益最大的策略 参与者\\(i\\)，对于其它参与者的策略\\(a_{-i} \\in a_{-i}\\) 的策略如果\\(u_i(a_i,a_{-i}) \\geqslant u_i(a&#39;_i,a_{-i})\\) 13.4 纳什均衡（Nash Equilibrium） \\(a = \\langle a_1,...,a_n\\rangle\\) 是一个纯策略纳什均衡当且仅当对于任何一个行为i，有\\(a_i \\in BR(a_{-i})\\) 如果任何参与者改变行为的收益都不会增加，那么此时进入纳什均衡 纳什均衡是一系列行为的列表，这些行为都是稳定的 支配策略是纳什均衡但反过来不一定对 任何有限博弈都存在一个纳什均衡（纳什1950年提出） 13.5 帕累托最优（Pareto Optimality） 某个结果是帕累托最优当且仅当没有其他结果可以全局帕累托支配这个结果 帕累托最优表示某个博弈结果不差于其他博弈结果 纳什均衡不一定是帕累托最优（囚徒困境） 13.6 混合策略（Mixed stratergies） 策略\\(S_i\\)指对于每个参与者行动的概率分布集合 概率 \\(Pr(a|s) = \\prod_{j \\in N}s_j(a_j)\\) 期望收益函数 \\(u_i(s) = \\sum_{a \\in A} u_i(a)Pr(a|s)\\) 随机策略会使对手混乱进入动态，很多博弈只存在混合策略纳什均衡而没有纯策略纳什均衡（石头剪子布） 混合策略的目的在于不论你使用哪一种行动，对方的收益都不变 选手 甲 乙 丙 a,b c,d 丁 e,f g,h 对于选手1而言，采取丙行动的收益是\\(aq+c(1-q)\\)，采取丁行动的收益是\\(eq+g(1-q)\\)，q代表选手2采取甲行动概率 如果要达到双方均衡，那么不论采取什么行动收益应该一致，不会因为对方概率的变化而偏离，那么我们就可以求解均衡时选手2的行动概率： \\[aq+c(1-q) = eq+g(1-q)\\] \\[q = \\frac{g-c}{a+g-c-e}\\] 这个结果表明选手2采取行动主要要参考选手1的行动收益差 同理，对选手2而言，采取甲行动收益是\\(bp+f(1-p)\\)，采取乙行动收益是\\(dp+h(1-p)\\)，p为选手1采取丙行动的概率，求解的到： \\[p=\\frac{h-f}{b+h-d-f}\\] - 要达到混合策略纳什均衡，博弈双方的行动概率主要参考对方的行动收益差；同时因为概率已知，我们也可以给出纳什均衡时双方的期望收益 - 应用：守门员博弈，当攻守双方达到纳什均衡时，其概率分布十分接近现实的统计数据，通过策略调整，博弈双方收益会逐渐收敛到纳什均衡，然后就不再变化 13.7 寻找纳什均衡 两人博弈可以用线性互补算法（Linear Complementarity）求解 严格说因为一定存在纳什均衡，寻找它不是NPC问题，但是是PPAD问题，后来人证明纳什均衡是PPAD问题 PPAD问题包括P问题的同时属于NP问题，指存在多项式的解，但不好找 P问题指多项式时间可解决的问题 NP问题指多项式时间可验证一个解的问题 NPC问题指NP问题的归约问题，同时也是NP问题，复杂度不断提高，NPC问题的存在让\\(P = NP\\) 问题很难有答案 NP-hard问题指NP问题的归约问题，但不一定是NP问题 13.8 被支配策略（dominated strategy） 指不论其他参与者采取任何策略，该策略劣于其他策略 被支配策略永远不会是最佳回应 排除法：把被支配策略删除，从剩下的行动方案中选择，交互地去除掉每个选手的被支配策略 13.9 最大最小策略（Maxmin strategies） 指其他参与者对某参与者最小收益策略下的最大收益策略\\(arg max_{s_i}min_{s_{-i}}u_i(s_1,s_2)\\) 最小最大策略指让对方收益最大而自己收益最小的策略\\(arg min_{s_i}max_{s_{-i}}u_{-i}i(s_1,s_2)\\) 在有限两人零和博弈的纳什均衡中，参与者的最大最小值与最小最大值一致 最大最小可用来线性求解纳什均衡 13.10 扩展形式博弈 正常形式博弈不涉及行动顺序与时间 扩展形式博弈考虑时序影响，是一个层级结构，双方根据对方已经使用的策略来使用自己的策略，包括信息对称与不对称两种 有限信息对称博弈用（N, A, H, Z, χ, ρ, σ, u）来表示 N代表n个参与者 A代表一组行动 H代表一组非终点的选择节点 行动函数 \\(\\chi:H \\rightarrow 2^A\\) 表示每个选择节点的可能行动 参与者函数 \\(\\rho:H \\rightarrow N\\) 表示在节点h上采取行动的选手 \\(i\\in N\\) Z代表终止节点 后继者函数 \\(\\sigma:H\\times A\\rightarrow H \\cup Z\\)映射一个选择节点和一个行动对于所有的节点与行动，如果后继者函数相同，那么节点与行动相同 效用函数\\(u=(u_1,...,u_n);u_i:Z\\rightarrow R\\) 表示在终止节点上参与者的效用 信息对称扩展形式博弈里参与者的纯策略是行动函数的乘积\\(\\prod_{h\\in H,\\rho(h)=i}\\chi(h)\\) 扩展形式博弈可以转为正常形式博弈，但是有大量冗余，正常形式博弈不一定可转化为扩展形式博弈 信息对称扩展形式博弈都有纯策略纳什均衡 求解扩展形式博弈要从完美子博弈开始，从最小的分支倒推，记录策略，实际上也是最小最大值的求解 13.11 完美子博弈 在节点h的子博弈G是节点集合H对博弈G的限制 完美子博弈均衡也是纳什均衡，但不考虑无信用恐吓 倒推法：从最低层寻找纳什均衡，逐层反推排除掉其他选择得到策略 对于零和博弈，倒推法实际就是最小最大算法 13.12 信息不对称扩展形式博弈 参与者选择节点被分配到不同信息集合里，个体无法区分选择节点 信息不对称博弈用（N, A, H, Z, χ, ρ, σ, u, I）来表示 对于 \\(I = (I_1,...,I_n)\\)，\\(I_i = (I_{i,1},...,I_{i,k_i})\\) 是依赖于 \\({h\\in H: \\phi (h) = i}\\) 的平衡，具有当存在j在节点 \\(h\\in I_{i,j}\\)与\\(h&#39;\\in I_{i,j}\\) 时，有 \\(\\chi(h) = \\chi(h&#39;)\\) 与 \\(\\rho(h) = \\rho(h&#39;)\\) 的属性 13.13 混合与行为策略 混合策略随机化纯策略 行为策略是遇到每个信息集后的抛硬币 13.14 重复博弈 参与者\\(i\\)给定一个无限序列\\(r_1,r_2,...\\)，其平均回报是\\(\\lim_{k\\rightarrow\\infty}\\sum_{j=1}^k\\frac{r_j}{k}\\) 考虑折扣因子\\(\\beta\\)，未来折扣回报是\\(\\sum_{j=1}^{\\infty}\\beta^jr_j\\)，一般人会更关注当下，对未来关注不会超过当下，但以\\(1-\\beta\\)的概率终止博弈 重复博弈中，当前收益跟未来收益权重不一致，未来收益一般小于当前收益权重： \\[U = U_1 + \\sigma U_2+ ...\\] \\(\\sigma\\)介于0，1之间 有限重复博弈可以用倒推法得到解，基本收敛于子博弈均衡 无限重复博弈要分别计算不同策略下收益，当无限重复博弈概率不断增加，有可能打破子博弈均衡，此时会发生偏移 13.15 随机博弈（stochastic game） 随机博弈是重复博弈的泛化，每一次都取决于上一次博弈结果 用(Q, N, A, P, R)来表示 Q代表有限状态集 N代表有限参与者集合 \\(A = A_1 \\times ... \\times A_n\\) 其中\\(A_i\\)是参与者i的有限行动集 \\(P:Q \\times A \\times Q \\rightarrow[0,1]\\)表示转移概率函数，从状态Q采取行动A变化另一个状态Q \\(R = r_1,...,r_n\\)中\\(r_i:Q\\times A\\rightarrow R\\) 表示参与者i的效用函数 13.16 虚拟行动（fictitious play） 对于行动\\(a\\in A\\)，用\\(w(a)\\)表示对手行动次数，可以非零初始化 用这个数字评价对手策略 \\(\\sigma(a) = \\frac{w(a)}{\\sum_{a&#39; \\in A}w(a&#39;)}\\) 在虚拟行动中每一个参与者的策略经验分布收敛，那么一定收敛到纳什均衡 13.17 无悔学习（No-regret learning） 后悔表示参与者在时间t上没有采用策略s\\(R^t(s) = max(\\alpha^t(s)-\\alpha^t,0)\\) 无悔学习表现出对任何纯策略有\\(Pr([\\lim \\inf R^t(s)]\\leq0)\\) 在每一步每个行为正比于其后悔\\(\\sigma_i^{t+1}(s) = \\frac{R^t(s)}{\\sum_{s&#39;\\in S_i}R^t(s&#39;)}\\) 对有限博弈收敛到均衡 13.18 无限重复博弈的平衡 著名的策略包括以牙还牙（tit-for-tat）跟扳机（trigger） 纳什均衡只适用于有限博弈 无限策略里有无限个纯策略均衡 对于n个参与者的博弈\\(G = (N,A,u)\\)其收益向量\\(r = (r_1,r_2,...,r_n)\\)，让\\(v_i = min_{s_{-i} \\in S_{-i}max_{s_i \\in S_i}} u_i(s_{-i},s_i)\\) i的最小最大值是对方使用最小最大策略时其收益 一个收益向量r是增强的如果\\(r_i\\geq v_i\\) 一个收益向量是可行的当存在非负值\\(\\alpha_a\\)对于所有i，有\\(\\sum_{a\\in A}\\alpha_au_i(a)\\)且\\(\\sum_{a\\in A}\\alpha_a = 1\\) 无名氏定理（folk theorem）：如果收益向量对无限博弈的纳什均衡是平均回报，那么对每个参与者都是增强的，如果可行且增强，收益向量就是有平均回报的无限纳什均衡 13.19 贝叶斯博弈 贝叶斯博弈\\((N,G,P,I)\\)里，N代表参与者集合，G代表博弈集合，P代表对某个博弈集合的先验概率，I代表G里面对每个参与者的组成部分 也可以用认知类型来定义\\(N,A,\\Theta,p,u\\)，A表示行为集合，\\(\\Theta\\)表示对参与者i的类型空间，p表示没中类型的先验概率，u表示某类型某行动对参与者i的收益 贝叶斯纳什均衡：最大化每个参与者每种行动类型收益的策略，可以是纯策略，也可以是混合策略 三种类型：对自己对方都不知道（现存），知道自己不知道对方(过渡)，都知道（过后） 过渡态期望收益：\\(EU_i(s|\\theta_i) = \\sum_{\\theta_{-i}\\in\\Theta_{-i}}p(\\theta_{-i}|\\theta_i)\\sum_{a\\in A}(\\prod_{j\\in N}s_j(a_j|\\theta_j))u_i(a,\\theta_i,\\theta_{-i})\\) 现存期望收益：\\(EU_i(s) = \\sum_{\\theta_i\\in \\Theta_i}p(\\theta_i)EU_i(s|\\theta_i)\\) 贝叶斯均衡混合策略\\(s_i\\in arg max_{s&#39;_i}EU_i(s&#39;_i,s_{-i}|\\theta_i)\\) 给定一方行为，考虑先验概率另一方收益最大时的博弈平衡 双方信息不对称，一方知道结果，另一方只能通过概率猜测是否对方是某种类型 计算不同行动的收益期望，求解概率，如果认为概率高于某个值，则选择对应行动，此时达到收益与概率的均衡 13.20 联盟博弈 收益可转移的联盟博弈（N,v）N代表有限的参与者，\\(v:2^N \\rightarrow R\\) 里每个联盟 \\(S\\subseteq N\\) 里的能够分配的收益，假定\\(v(\\varnothing)=0\\) 联盟博弈解决的问题是哪些联盟会生成及收益如何分配 超加性博弈\\(G=(N,v)\\)表示对于所有的\\(S,T\\subset N\\)，如果\\(S\\cap T = \\varnothing\\)，那么有\\(v(S\\cup T\\geq v(S)+v(T))\\)，这种情况下整体绑定为一个联盟收益最高 13.21 夏普利值（Shapley Value） 如何公平分割收益，Lloyd Shapley认为参与者要按照边际贡献的比例获得收益 公理 - 对于每一种收益方法如果两个人可相互交换\\(v(S\\cup \\{i\\}) = v(S\\cup \\{j\\}))\\)，那么其收益相等\\(\\psi_i(N,v)=\\psi_j(N,v)\\) - 如果某个人不产生收益\\(v(S\\cup \\{i\\} = v(S))\\)，那么不分成\\(\\psi_i(N,v)=0\\) - 对于\\(v_1\\)和\\(v_2\\)，博弈\\((N,v_1+v_2)\\)用\\((v_1+v_2)(S)=v_1(S)+v_2(S)\\)定义，有\\(\\psi_i(N,v_1+v_2)=\\psi_i(N,v_1)+\\psi_i(N,v2)\\) 夏普利值按照 \\(\\psi_i(N,v) = \\frac{1}{N!}\\sum_{S\\subseteq N_i} |S|!(|N|-|S|-1![v(S\\cup \\{i\\})-v(S)])\\) 分配收益，也就是满足上面三个公理的分配方式 13.22 核心 夏普利值分配比较公平，但不一定稳定，不容易形成大联盟 核心指对于\\(S\\subseteq N\\)，有\\(\\sum_{i\\in S} x_i \\geq v(S)\\) ，总和收益至少不低于内部小联盟收益 核心可能是空的且不唯一 对于简单博弈核心是空的当且仅当没有否决参与者，如果有否决参与者，核心包括所有非否决参与者收益0的收益向量 凸博弈：\\(v(S\\cup T)\\geq v(S)+v(T)-v(S\\cap T)\\)，每个凸博弈有一个非空核心且是夏普利值 13.23 选举 选举结果\\(O\\) 参与者的选择 \\(\\succ\\) 线性排序 \\(L\\) 选择顺序，可传递；非强制选择\\(L_{NS}\\) \\(\\succeq\\) 可传递 社会选择函数 \\(C:L_{NS}^n \\rightarrow O\\)，期中L是非强制选择偏好 社会福利函数 \\(W:L_{NS}^n \\rightarrow L_{NS}\\) 多数票制：选择大多数人选最多的 累计投票：每个人多张票，可以重复投给一个人 同意投票：每个人可随意投，投多个人或不投都可以 淘汰制多数票：得票最多获胜，否则淘汰得票少的重新投直到有结果 波达投票：每个结果分配一个有排序的数字，最后选择总和最高的那个 连续消除：设定顺序，然后前两个投票，输的淘汰，之后赢的跟第三个再投票直到出结果 孔多塞连续性：如果有个结果在所有对比中都胜出，那么这个候选人可以当选（不一定总是有这样的人，有时会出现循环） 不同投票方法结果可能不一样 帕累托有效（PE）如果所有参与者都同意某两个结果的顺序，那么社会福利函数也会使用那个顺序 无关选择独立性（IIA）两个结果间顺序指依赖于参与者给出的相对顺序 独裁者（dictator）某可决定社会排序的参与者 Arrow理论 任何超过三人的具有PE与IIA的社会福利函数都是独裁的 证明 弱帕累托有效：没有出现过被支配的结果 单调：一个获胜的结果再拿到更高的排序也是获胜者 独裁：存在某参与者的选择与总体选择顺序一致 弱帕累托有效且单调的社会选择函数是独裁的 单峰选择：每个投票的人都有最想选跟最不想选的候选人，选择上会避免极端 13.24 机制设计 直接形式：参与者同时传递信息到中心 间接形式：参与者传递一系列信息，这些信息前后相关 启示原则（Revelation Principle）：任何社会选择函数都可以用真实直接的机制来实施 Gibbard-Satterthwaite 理论：有限选择空间里三个元素以上的支配策略都是独裁的，非独裁策略需要转移函数 转移函数：集体对个体的税收或补贴，个人私人收益与转移函数之和是个体的整体结果收益，个人私人收益不考虑其他人的选择 真实性：对于每个参与者平衡策略里转移收益机制是真实的党是直接的且个体接受个人收益函数 有效性：有效的机制会选择最大化个体的收益，转移函数的和小于等于0 预算平衡：所有人转移函数的和为0，大于等于0是弱预算平衡 个体理性：没有人会因为参与某个机制得到负收益 可处理：收益与转移函数的计算可在多项式时间内完成 税收最大化：满足所有限制条件下最大化转移函数总和期望的机制 税收最小化：满足所有限制条件下最小化转移函数总和期望的机制 公平性：让最不开心的参与者也开心最大化 设计政策时要考虑支出补贴税收对所有人都无害或达到均衡 13.25 VCG机制 存在货币补偿时自私参与者选择社会福利最大化的通用方法 一个直接机制包括选择规则跟补偿规则，VCG作为支配策略是真实有效的，在额外假设下可以满足弱预算平衡跟个体理性 Groves机制 \\((\\chi,p)\\) \\[\\chi (\\hat v) \\in arg max_x \\sum_i \\hat v_i(x)\\] \\[p_i(\\hat v) = h_i(\\hat v_{-i}) - \\sum_{j\\neq i} \\hat v_j(\\chi(\\hat v))\\] VCG机制 \\((\\chi,p)\\) \\[\\chi (\\hat v) \\in arg max_x \\sum_i \\hat v_i(x)\\] \\[p_i(\\hat v) = max_x\\sum_{j\\neq i} \\hat v_j(x) - \\sum_{j\\neq i} \\hat v_j(\\chi(\\hat v))\\] 在VCG机制下，计算你自己存在时社会受益最大时其他人收益总和，然后计算没有你且社会收益最大时其他人收益总和，你的补偿是它们的差值 不影响最后结果的人不需要补偿，其存在导致他人收益减少的要付出，其存在导致他人收益增加的要补偿 其真实性有效性可以数学证明 VCG需要个体真实汇报个人信息，但个体间的勾结可以消除补偿，同时VCG会导致开支暴涨，增加参与人也会增加财政支出，个人可能伪装多个人，同时返还机制也不允许所有人返还所有收益 价值隐私信息需要损失效率，是动机效率的平衡 13.26 拍卖 自私参与者分配资源的机制 英国人拍卖：从保留值开始拍卖，参与人喊价，价高的得到物品并付出对应价格 日本人拍卖：所有参与者先站着，价格提升，当价格不合适就坐下，最后一个站着的人得到物品 荷兰人拍卖：设定一个高价然后开始逐渐降低，当有人说我接受时拍卖结束，价格就是当时价格 第一价格拍卖：参与者将价格写好封装，然后拍卖人开封，价高的人得到物品，付对应价格 第二价格拍卖：同上，但付第二高的价格 付费拍卖：同上，但所有人都要支出自己写的价格，彩票？ 拍卖三种规则：竞拍规则，信息释放规则，清场规则 在第二价格拍卖里，讲真话是支配策略，符合VCG机制，也可以直观证明 在英国人日本人拍卖里，独立私有价值模型下的支配策略是用真实值 在第一价格拍卖与荷兰人拍卖实质等同，前者可以异步进行，后者交流快，参与者竞拍价要低于价值，无支配策略 两个中等风险的参与者参与第一价格竞拍，分布是均匀分布，贝叶斯纳什均衡是各自价格的一半 更多的参与人参加后，价格会不断提升接近真实价格，如果是均匀分布，系数是\\(\\frac{n-1}{n}\\) 收益均等理论：n个风险中等的参与者对于单一物品有独立私有价值，参与竞拍时每个人都从风险分布F里报价，当均衡时分配总是一样的，价值为0其期望也是0，所有有效拍卖产生的收益是一样的 最优化拍卖，参与人的虚拟价值\\(\\psi_i(v_i) = v_i - \\frac{1-F_i(v_i)}{f_i(v_i)}\\)在保留价格处为0，并非VCG "],["bios.html", "第14章 生物信息 14.1 数据结构 14.2 Pubmed 搜索 14.3 动态规划 14.4 得分矩阵 14.5 E 值 14.6 PSI-BLAST 14.7 蛋白 14.8 蛋白结构预测 14.9 细菌基因组 14.10 病毒 14.11 单核苷酸多态性（SNP） 14.12 真核基因预测 14.13 DNA指纹 14.14 Ensembl 14.15 基因组学数据分析 14.16 链接", " 第14章 生物信息 14.1 数据结构 列代表特征 行代表条目 每个条目有一个唯一性特征 数据表可通过列链接成为关系数据库 14.2 Pubmed 搜索 PubMed search tags [AD] – Affiliation (company or school) [ALL] – All fields (eliminates defaults) [AU] or [AUTH] – Author [1AU] – First author [ECNO] – Enzyme Commission Numbers [EDAT] – Entry date (YYYY/MM/DD) [ISS] - Issue # of journal [JOUR] - Journal (Title, Abbreviation , ISSN) [LA] – Language [PDAT] – Publication date (YYYY/MM/DD) [PT] – Publication type [SUBS] – Substance name [TIAB] – Title/Abstract [TW] – Text words [UID] – Unique identifiers (primary keys) [VOL] or [VI] – Volume of journal MeSH terms [MH][MAJR][SH] 被 MeSH 索引的关系数据库 保守性检索 有层级关系 时间段搜索 冒号分割 YYYY/MM/DD:YYYY/MM/DD 序列长度搜索 [SLEN] 可以是蛋白 可以是核酸 蛋白分子量搜索 [MOLWT] 物种搜索 [ORGN] Nucleotide 序列蛋白数据库 MMDB 3D结构数据库 Genome 基因组数据库 OMIM 人类孟德尔遗传数据库 用来探索等位基因问题 分类数据库 用来界定分类 GEO 基因芯片的实验数据 SNP 基因指纹数据库 14.3 动态规划 用于序列比对 对角线得分 按总分评价比对结果 可全局 可局部 序列比对指标是特异性与相似性 特异性指精确匹配比率 相似性指精确匹配加化学相似性比率 结构相近则相似 FASTA 慢准 BLAST 快 三种情况 匹配 不匹配 间隔 间隔罚分 14.4 得分矩阵 考虑突变的比对 蛋白的自然突变率矩阵PM1 矩阵自相乘得到外推矩阵 PM10 PM250 取对数为打分矩阵 取不同矩阵源于研究目的对多样性的判断 14.5 E 值 表示序列的同源性 比对得分的稀有性 两个参数 数据库大小(N) 比对得分(S) E = N/S 数据库越大越可能随机碰到相同序列 得分越高越可能同源 E值很小说明同源性很高 E值很大什么说明不了 一般阈值1e-04 14.6 PSI-BLAST 先用BLAST在一定E值上建库 计算新库的氨基酸概率 再与全库比对得分 得到统计显著性 可以发现BLAST未发现的序列 建立蛋白家族 14.7 蛋白 Profiles 定量描述 Patterns 定性描述 Signature 蛋白保守序列 motif 少于20个氨基酸 指示二级结构 Domains 超过40个氨基酸 蛋白的球状区 共同点 保守 正则表达式表示保守区 E-X(2,4)-[FHM]-X(4)-{P}-L E后随意两个，三个，四个然后FHM其中一个，然后随意四个，然后一个不是P，最后为L 可以精确可以模糊 没有E值 14.8 蛋白结构预测 分子量 道尔顿（Da）描述质量 等电点 蛋白不带电的pH值 小于7 酸性 中性带负电 大于7 碱性 中性带正点 网站计算 蛋白定位 分泌 胞内 核内 MITOPRED 预测线粒体蛋白 14.9 细菌基因组 细菌是环形DNA 真核是线性染色体 细菌不加工mRNA 细菌一段mRNA上有多个顺反子 也就是多个编码DNA序列 操纵子在mRNA编码的上游或下游调控转录 GLIMMER与FGENESB用来预测一段序列的转录情况 14.10 病毒 三种 RNA DNA 逆转录病毒 突变快 RNA病毒三种 双链 正链 负链 逆转录基因组简单 Gag Pol Env 凝集素等决定病毒亚型 14.11 单核苷酸多态性（SNP） 至少1%种群中存在的DNA单核苷酸变化 后果 编码区改变影响表型 不改变蛋白序列的编码区可能影响mRNA加工 启动子或调控区可能影响表达 其他区没有影响 可作为染色体标记- 类型 不改变氨基酸 改变氨基酸 非编码区 数据库 dbSNP SNPEffect SNPs对蛋白的影响 SNPedia SNPs的临床效应 1000 基因组外显子计划 第二代测序的发展 14.12 真核基因预测 CDS是mRNA的子集 CDS可能比mRNA外显子少 基因预测只能发现编码区外显子 有些转录变化不改变蛋白序列：UTR区与同义密码子 14.13 DNA指纹 重复 突变会影响限制性片段长度 VNTR 用来排除嫌犯 PCR 用来扩增相关片段 CODIS 区域在美国用来鉴定身份 14.14 Ensembl 外显子基因组学数据库 可选择人类 鼠 斑马鱼等常见物种 14.15 基因组学数据分析 主页 14.15.1 microarrays 14.15.1.1 原理 生成互补DNA探针 标记样品中的DNA单链 可以对不同样品标记不同颜色 特异性互补反应 测定标记物光信号 14.15.1.2 应用 测定基因表达 已知序列 3’端（降解从5’端开始）选取11个片段作为探针 样品对11个片段都是高表达则基因高表达 寻找SNP SNP 单核苷酸多态性 用来探索基因型 合成SNP探针 测定对不同探针的响应判断AA AG GG类型 寻找转录因子结合位点 样品处理为含蛋白与不含蛋白两份 去除蛋白后扩增 探针是基因组感兴趣的片段 瓦片分析可知探针与含转录因子DNA结合位点 总DNA作为对照 14.15.2 NGS 14.15.2.1 原理 DNA打成50~70片段 一个样品片段上亿 加上adaptor 固定在板上后原位扩增成束 使用标记过的单核苷酸逐碱基对测光强 同时测序大量片段 得到测序结果与强度 14.15.2.2 应用 寻找SNP RNA-seq 测定RNA表达量 寻找结合位点 表达量 14.15.3 数据分析应用背景 14.15.3.1 DNA 甲基化 CpG 5’端到3‘端 CG C上甲基化 复制时该特性会保留 临近CpG位点的基因不会被表达 CpG 成簇存在 称为CpG islands bisulfite treatment 可以用来测定CpG是否被甲基化 通过将未甲基化的CpG中的C改为T 测序中测定改变率就可知CpG位点甲基化程度与位置 14.15.3.2 CHIP-SEQ 蛋白结合后固定，洗掉其余片段，然后洗掉蛋白，对序列片段测序得到结合位点 14.15.3.3 RNA 测序 RNA反转录为cDNA测序 只有外显子 同一基因多种RNA片段 均值与方差有相关性 需要进行log变换后分析 14.15.4 Bioconductor 官方说明 使用biocLite()安装，安装后仍需要library()才能使用 source(&quot;http://bioconductor.org/biocLite.R&quot;) biocLite() 14.15.4.1 数据结构 14.15.4.1.1 分析数据 F 行 S 列 F代表芯片特征数，S代表样本数 14.15.4.1.2 表型数据 S 行 V 列 V代表样本特征，为分类或连续变量 如果表型数据解释不清，可以建立一个解释样本特征的labelDescription数据框，通过phenoData &lt;- new(\"AnnotatedDataFrame\",data=pData, varMetadata=metadata) 建立AnnotatedDataFrame类型数据 14.15.4.1.3 实验描述 MIAME 类型对象 描述实验参数 14.15.4.1.4 组装数据 将分析数据，表型数据，实验描述组装为一个ExpressionSet类型的对象 exampleSet &lt;- ExpressionSet(assayData=exprs,phenoData=phenoData,experimentData=experimentData,annotation=\"hgu95av2\") annotation代表了一组相似实验设计的芯片数据的代号，通过相关代号可以索引到芯片特征信息并将其与其他数据如基因型，染色体位置等连接以便于分析 从ExpressionSet里可以按照表型数据提取子集，也就是对 S 截取 V 中特定子集 exampleSet[ , exampleSet$gender == \"Male\"] esApply 用来针对ExpressionSet应用函数 14.15.4.1.5 数据集应用 library(Biobase) library(GEOquery) geoq &lt;- getGEO(\"GSE9514\") 从基因表达精选集（GEO）上得到数据表达集 names(geoq) 得到文件名 e &lt;- geoq[[1]] 得到数据集 dim(e) 查看表达集维度 给出样本数与特征值，也就是测定序列数 dim(exprs(e)) 与上面等同，给出基因分析数据 dim(pData(e)) 给出8个样本的信息，信息头用names(pData(e))给出 dim(fData(e)) 给出特征与信息头列表 exprs为特征数×样本数矩阵 pdata为样本数×信息头 fdata为特征数×信息 experimentData(e) 给出实验信息 annotation(e) 特征注释 exptData(se)$MIAME 给出实验相关关键信息 Y &lt;- log2(exprs(bottomly.eset) + 0.5) 对NGS数据加0.5取2为底的对数（防0）得-1，排除掉0后可得MAplot观察数值分布，一般为均值小差异大，均值大相对稳定 formula 用来定义公式 model.matrix 用定义的公式生成矩阵 rowttests(y[, smallset], group[smallset]) 定义分组，设定模型可进行t-test，用火山图来表示 14.15.4.1.5.1 Iranges library(IRanges) 序列范围 ir &lt;- IRanges(start = c(3, 5, 17), end = c(10, 8, 20)) 定义序列 IRanges(5, 10) 表示5到10这6个碱基对，可以shift range(ir) 表示存在ir中序列的起止范围 gaps(ir) 表示寻找ir中间隔片段 disjoin(ir) 表示将ir中序列碎片化后互不重叠的片段 14.15.4.1.5.2 GRanges and GRangesList library(GenomicRanges) 基因范围 gr &lt;- GRanges(\"chrZ\", IRanges(start = c(5, 10), end = c(35, 45)), strand = \"+\", seqlengths = c(chrZ = 100L)) 定义位于染色体chrZ上几个序列范围，认为这些范围共同定义一个基因 可以shift，可以定义长度后trim mcols(gr)$value &lt;- c(-1, 4) 定义该基因类型中的列并赋值 grl &lt;- GRangesList(gr, gr2) 多个Granges定义一个基因库 length(grl) 给出基因库里基因个数 mcols(grl)$value &lt;- c(5, 7) 定义该基因库类型中的列并赋值 14.15.4.1.5.3 findOverlaps gr1 gr2 为两个基因范围对象 fo &lt;- findOverlaps(gr1, gr2) 寻找两个基因重叠序列 queryHits(fo) 与 subjectHits(fo) 提取两个基因重叠序号 成对出现 gr1[gr1 %over% gr2] 提取对应序列范围 14.15.4.1.5.4 Rle Rle(c(1, 1, 1, 0, 0, -2, -2, -2, rep(-1, 20))) 表示4组处理，每组各有 3 2 3 20 个重复 Rle是一种压缩存储实验设计的方式，可以用as.numeric()提取原始数据 Views(r, start = c(4, 2), end = c(7, 6) 提取对应实验组 14.15.4.2 数据读取 microarray 或 NGS 数据由芯片厂商提供，常见读取原始信息的包有affyPLM、affy、 oligo、limma 在Bioconductor里，这些原始数据要转为ExpressionSet格式 14.15.4.2.1 Affymterix CEL files library(affy) tab &lt;- read.delim(\"sampleinfo.txt\", check.names = FALSE, as.is = TRUE) 读取样本信息 ab &lt;- ReadAffy(phenoData = tab) 读取样本数据，探针层次 ejust &lt;- justRMA(filenames = tab[, 1], phenoData = tab) 直接读取为基因层数据 e &lt;- rma(ab) 对样本进行背景校正与正则化，从探针层转化为基因层数据 14.15.4.2.2 背景干扰 spikein方法 梯度加入已知浓度的基因片段 阵列上进行shift 类似拉丁方设计 可以看到同一基因不同片段大致符合先平后增模式 开始阶段是噪声主导 后面是浓度主导 使用类似基因模拟噪声主导 相减后得到去干扰浓度效应 但低值部分会导致方差过大 也可以使用统计建模方法模拟背景值与响应 得到还原度更高的信号 14.15.4.2.3 正则化 基因组数据大多数为0 加标样品变化 正则化是为了还原这一结果 分位数正则化 局部回归正则化 稳方差正则化 当重复实验时 直接用分位数正则会掩盖样品差异 可以考虑只对加标基因正则化 然后推广到全局 14.15.4.2.4 探索分析作图 14.15.4.2.4.1 MA-plot x轴为两组基因组的均值，y轴为两组基因组的均值差 用来表示两组平行间的差异 14.15.4.2.4.2 Volcano plot 横坐标为处理间基因表达差异，纵坐标为差异的-log10(p.value) 一般为火山喷发状，差异越大，p值越小 14.15.5 示例：甲基化数据分析 14.15.5.1 读取数据 devtools::install_github(&quot;coloncancermeth&quot;,&quot;genomicsclass&quot;) library(coloncancermeth) data(coloncancermeth) 该数据集为结肠癌病人与对照的DNA甲基化数据集。 14.15.5.2 数据说明 dim(meth) dim(pd) length(gr) meth为测序数据，pd为样本信息，gr测序片段信息。 colnames(pd) table(pd$Status) X = model.matrix(~pd$Status) 查看病患与正常人的分组并构建模型。 chr = as.factor(seqnames(gr)) pos = start(gr) library(bumphunter) cl = clusterMaker(chr,pos,maxGap=500) res = bumphunter(meth,X,chr=chr,pos=pos,cluster=cl,cutoff=0.1,B=0) 按染色体生成因子变量，找出基因起始位点，然后利用bumphunter包寻找甲基化数据中某个阈值（0.1）下甲基化基因聚类的后出现的位置，聚类号，聚类相关性等信息寻找问题基因，可从中提取相关信息 cols=ifelse(pd$Status==&quot;normal&quot;,1,2) Index=(res$table[6,7]-3):(res$table[6,8]+3) matplot(pos[Index],meth[Index,,drop=TRUE],col=cols,pch=1,xlab=&quot;genomic location&quot;,ylab=&quot;Methylation&quot;,ylim=c(0,1)) Index=(res$table[6,7]):(res$table[6,8]) test &lt;- meth[Index,,drop=T] colnames(test) &lt;- pd$bcr_patient_barcode test1 &lt;- test[,cols==1] test2 &lt;- test[,cols==2] test3 &lt;- apply(test2, 2, mean) apply(matrix, 1, rank) 从上面可以得到有差异的甲基化数据所在的基因位置并提取相关样本数据信息。可根据差异作图，得到两组数据甲基化水平差异所在的基因位置。可对差异进行平滑操作，得到位置。这样就可以知道甲基化发生的序列位置与水平差异的信息了。 下面的例子是用人类基因组数据探索潜在的CpG岛。 library(BSgenome.Hsapiens.UCSC.hg19) Hsapiens[[&quot;chr1&quot;]] # 计算某染色体上潜在位点个数 countPattern(&#39;CG&#39;,Hsapiens[[&quot;chr1&quot;]]) # 计算某染色体上特定序列比例 观察与期望出现的比例 CG &lt;- countPattern(&#39;CG&#39;,Hsapiens[[&quot;chr1&quot;]])/length(Hsapiens[[&quot;chr1&quot;]]) GC &lt;- countPattern(&#39;GC&#39;,Hsapiens[[&quot;chr1&quot;]])/length(Hsapiens[[&quot;chr1&quot;]]) table &lt;- alphabetFrequency(Hsapiens[[&quot;chr1&quot;]]) expect &lt;- table[&#39;C&#39;]%*%table[&#39;G&#39;]/(length(Hsapiens[[&quot;chr1&quot;]]))^2 CG/expect 14.16 链接 Michael Love的教案 生信前沿信息集 "],["surv.html", "第15章 生存分析 15.1 Concepts 15.2 Notation 15.3 Cox proportional-hazards regression model 15.4 Case: Recidivism 15.5 further 15.6 Time-Dependent Covariates 15.7 Model Diagnostics 15.8 Reference", " 第15章 生存分析 15.1 Concepts examines and models the time it takes for events to occur the distribution of survival times Popular: Cox proportional-hazards regression model 15.2 Notation T as a random variable with cumulative distribution function \\(P (t) = Pr(T ≤ t)\\) and probability density function \\(p(t) = \\frac{dP (t)}{dt}\\) survival function S(t) is the complement of the distribution function, \\(S(t) = Pr(T &gt; t) = 1 − P (t)\\) hazard function \\(log h(t) = ν + ρt\\) 15.3 Cox proportional-hazards regression model \\(log h_i(t)=α+_1x_{i1} +β_2x_{ik} +···+β_kx_{ik}\\) Cox model \\(log h_i(t)=α(t)+β_1x_{i1} +β_2x_{ik} +···+β_kx_{ik}\\) the Cox model is a proportional-hazards model \\(\\frac{h_i(t)}{h_{i&#39;}(t)} = \\frac{e^{\\eta_i}}{e^{\\eta&#39;}}\\) 15.4 Case: Recidivism Target: recidivism of 432 male prisoners, who were observed for a year after being released from prison arrest means the male prisoners who rearrested 52 weeks factors: financial aid after release from prison, affected，release ages，race，work experience，marriage，parole，prior convictions, education library(survival) library(car) # perform survival analysis data(&quot;Rossi&quot;) Rossi[1:5, 1:10] ## week arrest fin age race wexp mar paro prio educ ## 1 20 1 no 27 black no not married yes 3 3 ## 2 17 1 no 18 black no not married yes 8 4 ## 3 25 1 no 19 other yes not married yes 13 3 ## 4 52 0 yes 23 black yes married yes 1 5 ## 5 52 0 no 19 other yes not married yes 3 3 mod.allison &lt;- coxph(Surv(week, arrest) ~ fin + age + race + wexp + mar + paro + prio, data=Rossi) summary(mod.allison) ## Call: ## coxph(formula = Surv(week, arrest) ~ fin + age + race + wexp + ## mar + paro + prio, data = Rossi) ## ## n= 432, number of events= 114 ## ## coef exp(coef) se(coef) z Pr(&gt;|z|) ## finyes -0.3794 0.6843 0.1914 -1.98 0.0474 * ## age -0.0574 0.9442 0.0220 -2.61 0.0090 ** ## raceother -0.3139 0.7306 0.3080 -1.02 0.3081 ## wexpyes -0.1498 0.8609 0.2122 -0.71 0.4803 ## marnot married 0.4337 1.5430 0.3819 1.14 0.2561 ## paroyes -0.0849 0.9186 0.1958 -0.43 0.6646 ## prio 0.0915 1.0958 0.0286 3.19 0.0014 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## exp(coef) exp(-coef) lower .95 upper .95 ## finyes 0.684 1.461 0.470 0.996 ## age 0.944 1.059 0.904 0.986 ## raceother 0.731 1.369 0.399 1.336 ## wexpyes 0.861 1.162 0.568 1.305 ## marnot married 1.543 0.648 0.730 3.261 ## paroyes 0.919 1.089 0.626 1.348 ## prio 1.096 0.913 1.036 1.159 ## ## Concordance= 0.64 (se = 0.027 ) ## Likelihood ratio test= 33.3 on 7 df, p=2e-05 ## Wald test = 32.1 on 7 df, p=4e-05 ## Score (logrank) test = 33.5 on 7 df, p=2e-05 # plot time vs survival prob plot(survfit(mod.allison), ylim=c(.7, 1), xlab=&#39;Weeks&#39;, ylab=&#39;Proportion Not Rearrested&#39;) 15.4.1 result The covariates age and prio (prior convictions) have highly statistically significant coefficients, while the coefficient for fin (financial aid) is marginally significant holding the other covariates constant, an additional year of age reduces the weekly hazard of rearrest by a factor of \\(e^b = 0.944\\) on average – that is, by 5.6 likelihood-ratio, Wald, and score chi-square statistics: null hypothesis all of the β’s are zero. 15.5 further assess the impact of financial aid on rearrest new data frame with two rows, one for each value of fin; the other covariates are fixed to their average values Rossi.fin &lt;- data.frame(fin=c(0,1), age=rep(mean(Rossi$age),2), race=rep(mean(as.numeric(Rossi$race)),2), wexp=rep(mean(as.numeric(Rossi$wexp)),2), mar=rep(mean(as.numeric(Rossi$mar)),2), paro=rep(mean(as.numeric(Rossi$paro)),2), prio=rep(mean(as.numeric(Rossi$prio)),2)) plot(survfit(mod.allison, newdata=Rossi.fin), conf.int=T, lty=c(1,2), ylim=c(.6, 1)) legend(&quot;bottomleft&quot;, legend=c(&#39;fin = 0&#39;, &#39;fin = 1&#39;), lty=c(1,2)) the higher estimated ‘survival’ of those receiving financial aid, but the two confidence envelopes overlap substantially, even after 52 weeks 15.6 Time-Dependent Covariates treat the employed variable as a tim-dependent covariates with 52 weeks’ record sum(!is.na(Rossi[,11:62])) # record count ## [1] 19809 Rossi2 &lt;- matrix(0, 19809, 14) # to hold new data set colnames(Rossi2) &lt;- c(&#39;start&#39;, &#39;stop&#39;, &#39;arresttime&#39;, names(Rossi)[1:10], &#39;employed&#39;) row&lt;-0 for (i in 1:nrow(Rossi)) { for (j in 11:62) { if (is.na(Rossi[i, j])) next else { row &lt;- row + 1 # increment row counter start &lt;- j - 11 # start time (previous week) stop &lt;- start + 1 # stop time (current week) arresttime &lt;- if (stop == Rossi[i, 1] &amp;&amp; Rossi[i, 2] ==1) 1 else 0 Rossi2[row,] &lt;- c(start, stop, arresttime, unlist(Rossi[i, c(1:10, j)])) } } } Rossi2 &lt;- as.data.frame(Rossi2) remove(i, j, row, start, stop, arresttime) modallison2 &lt;- coxph(Surv(start, stop, arresttime) ~ fin + age + race + wexp + mar + paro + prio + employed, data=Rossi2) summary(modallison2) ## Call: ## coxph(formula = Surv(start, stop, arresttime) ~ fin + age + race + ## wexp + mar + paro + prio + employed, data = Rossi2) ## ## n= 19809, number of events= 114 ## ## coef exp(coef) se(coef) z Pr(&gt;|z|) ## fin -0.3567 0.7000 0.1911 -1.87 0.0620 . ## age -0.0463 0.9547 0.0217 -2.13 0.0330 * ## race -0.3387 0.7127 0.3096 -1.09 0.2740 ## wexp -0.0256 0.9748 0.2114 -0.12 0.9038 ## mar 0.2937 1.3414 0.3830 0.77 0.4431 ## paro -0.0642 0.9378 0.1947 -0.33 0.7416 ## prio 0.0851 1.0889 0.0290 2.94 0.0033 ** ## employed -1.3283 0.2649 0.2507 -5.30 1.2e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## exp(coef) exp(-coef) lower .95 upper .95 ## fin 0.700 1.429 0.481 1.018 ## age 0.955 1.047 0.915 0.996 ## race 0.713 1.403 0.388 1.308 ## wexp 0.975 1.026 0.644 1.475 ## mar 1.341 0.745 0.633 2.842 ## paro 0.938 1.066 0.640 1.374 ## prio 1.089 0.918 1.029 1.152 ## employed 0.265 3.775 0.162 0.433 ## ## Concordance= 0.708 (se = 0.023 ) ## Likelihood ratio test= 68.7 on 8 df, p=9e-12 ## Wald test = 56.1 on 8 df, p=3e-09 ## Score (logrank) test = 64.5 on 8 df, p=6e-11 15.7 Model Diagnostics Checking Proportional Hazards modallison3 &lt;- coxph(Surv(week, arrest) ~ fin + age + prio, data=Rossi) modallison3 ## Call: ## coxph(formula = Surv(week, arrest) ~ fin + age + prio, data = Rossi) ## ## coef exp(coef) se(coef) z p ## finyes -0.35 0.71 0.19 -2 0.068 ## age -0.07 0.94 0.02 -3 0.001 ## prio 0.10 1.10 0.03 4 4e-04 ## ## Likelihood ratio test=29 on 3 df, p=2e-06 ## n= 432, number of events= 114 cox.zph(modallison3) ## chisq df p ## fin 0.0638 1 0.801 ## age 6.3255 1 0.012 ## prio 0.5187 1 0.471 ## GLOBAL 7.1367 3 0.068 par(mfrow=c(2,2)) plot(cox.zph(modallison3)) there appears to be a trend in the plot for age, with the age effect declining with time modallison4 &lt;- coxph(Surv(start,stop,arresttime)~fin+age+age:stop:stop+prio, data = Rossi2) modallison4 ## Call: ## coxph(formula = Surv(start, stop, arresttime) ~ fin + age + age:stop:stop + ## prio, data = Rossi2) ## ## coef exp(coef) se(coef) z p ## fin -0.349 0.706 0.190 -1.8 0.067 ## age 0.032 1.033 0.039 0.8 0.413 ## prio 0.098 1.103 0.027 3.6 3e-04 ## age:stop -0.004 0.996 0.001 -2.6 0.009 ## ## Likelihood ratio test=36 on 4 df, p=3e-07 ## n= 19809, number of events= 114 the coefficient for the interaction is negative and highly statistically significant: The effect of age declines with time use residual to find influential observations 15.8 Reference Cox Proportional-Hazards Regression for Survival Data Real Cases "],["epid.html", "第16章 流行病学 16.1 声明 16.2 早期疾病的概念 16.3 近代流行病学关键人物 16.4 现代慢性病流行病学 16.5 流行病学基本概念 16.6 描述性流行病学 16.7 分析流行病学 16.8 疾病监控 16.9 疾病频率的测量 16.10 联系测量 16.11 随机误差 16.12 研究道德 16.13 临床实验 16.14 队列研究 16.15 病例对照研究 16.16 标准化 16.17 混杂 16.18 效应修饰（EMM） 16.19 多变量方法 16.20 筛选 16.21 因果推断 16.22 论文研读", " 第16章 流行病学 16.1 声明 本笔记来自于波士顿大学在线教程与北卡大学教堂山分校的公开课 二手知识，谨防消化不良 翻译有误之处见谅，烦请告知，谢谢！ 16.2 早期疾病的概念 渔猎时期主要问题是食物的供应与营养均衡问题 农耕时期开始群居，出现疾病的流行问题 神秘主义，迷信与神的惩罚 希波克拉底：理性思考疾病起源，提出体液学说 欧洲流行300多年的黑死病，开始认为病因是“瘴气”，其实是老鼠跳蚤上细菌 没有验证病因与疾病关系的方法与预防措施 工业革命时期城市规模迅速扩大，分工细化，出现职业暴露健康问题 16.3 近代流行病学关键人物 Girolamo Fracastoro (1546) 认为疾病来自种子 John Graunt - The Bills of Mortality (1662) 记录伦敦死亡率，出生率数据并进行分析 Anton van Leeuwenhouk (1670s) 显微镜之父，首先观察到细胞 John Pringle and “Jail Fever” (1740s) 研究军队与监狱卫生与疾病并讨论了与伤寒的关系 James Lind and Scurvy (1754) 进行了第一例临床控制实验，验证柑橘对坏血病的治疗作用 Francois Broussais &amp; Pierre Louis (1832) 提出放血疗法，没有验证但沿用几个世纪 Ignaz Semmelweis and Oliver Wendell Holmes (1840s) 前者发现了某种产科疾病是由刚解剖完尸体的学生引入的，后者推行了疾病可能来源于医护人员的理念而饱受争议 John Snow - The Father of Epidemiology (1850s) 流行病学之父，研究并验证了霍乱与城市供水的关系 Louis Pasteur (late 1800) 提出巴氏消毒法与疫苗理论 公共卫生的概念 (1850-1875) 起源于人口统计及18世纪的启蒙运动例如功利主义的兴起对公众健康的关注 16.4 现代慢性病流行病学 肺癌：工业革命后的肺癌发病率很高，普遍认为是工厂公路导致，但后续研究表明吸烟可能是主要因素，该研究促进了病例对照研究的发展 佛雷明翰心脏病研究：48年起追踪心脏病研究，已持续三代人 knitr::include_graphics(&#39;images/Framingham1.jpg&#39;) 16.5 流行病学基本概念 16.5.1 基本假设 病有病因非随机 病因可察可研究 16.5.2 定义 研究人群中疾病分布与成因的学科 阶段 研究类型 观察&amp;形成假说 案例研究／断面研究／生态学研究 观察研究假设检验 病例控制研究与队列研究 临床研究假设检验 临床实验 16.6 描述性流行病学 关注不同时间、地点、人群的差异、相似性与相关性，形成假说 案例：传染病暴发 早期关注案例采访，寻找共同点 对地理位置作图寻找空间关系 对时间趋势作图寻找变化规律 流行曲线：横轴日期，纵轴新增病例 点源爆发：单峰，潜伏期相对一致 knitr::include_graphics(&#39;images/epidemiccurve.jpg&#39;) - 持续源爆发：单峰，潜伏期持续出现 knitr::include_graphics(&#39;images/EpidemicCurve_Cholera.png&#39;) - 逐步流行：多峰，存在人对人传染 knitr::include_graphics(&#39;images/EpidemicCurve_Measles.png&#39;) 16.6.1 疾病爆发的研究步骤 准备研究 验证诊断与爆发的存在 定义案例并寻找案例 进行描述性流行病学研究确定时间、地点与人群的差异 生成爆发原因与来源的假设 假设检验 制定控制与预防措施 交流研究发现 16.6.2 慢性病的描述性流行病学 人群特质：年龄，性别，种族，职业，饮食习惯，宗教习惯，业余活动等 地点：慢性病地域差距 时间：大趋势，季节性，片断性 其他：环境变化，诊断精度，医疗水平，人群年龄分布 16.6.3 描述流行病学分类 病例报道 单个案例 艾滋病血液传播的发现 无注射狂犬疫苗后痊愈 系列病例 多个案例 男同性恋间获得性免疫缺陷传染 断面研究 同一时间对特定人群的健康状况与风险因子进行调查 HIS NHANES 生态学研究 以群体为单位研究区域平均暴露状况 16.7 分析流行病学 不同于描述流行病学提出假设，分析流行病学进行假设检验 队列研究：定义基线与风险人群 前瞻性队列研究：参与者参加的时候不出现健康效应 回顾性队列研究：根据已经出现的健康效应反向追查风险因子 临床实验：风险因子由研究人员指定 病例对照研究：不用来研究发病率，侧重风险比，不追踪，根据已有状况回溯，对幸存者采样，适合稀有病症的研究 knitr::include_graphics(&#39;images/paste_image47.jpg&#39;) 判断流程 是否个人（生态学研究） 是否有对照（系列案例） 是否追踪（断面研究） 是否不先选取出现健康状况的组（病例对照研究） 是否不出现健康状况（回顾队列研究） 是否指定对照组（前瞻队列研究） 临床实验 16.8 疾病监控 早期教堂记录出生率与死亡率 1662 John Graunt “Bills of Mortality” 1837 英国建立 General Registrar’s Office 记录市民出生、死亡与婚姻 John Snow 对霍乱数据的分析 1842 马萨诸塞州开始记录出生死亡状况 1901 全美开始记录疾病流行状况 1925 强制执行疾病监控 目前基本是CDC控制，除了强制汇报，也有主动收集 综合疾控，不等确诊收集症状，例如google flu 16.9 疾病频率的测量 16.9.1 人群 固定人群（相对固定，或由事件定义） 动态人群（由当前状态决定的人群） 16.9.2 患病率（prevalence） 表示在指定时间里具有某种健康效应的人群比例，非新增 \\[prevalence = \\frac{affected individuals}{total individuals in the population}\\] 举例：患病率0.25表示人群中有25%的人在指定的时间段里受某种健康效应影响 经常会导致因果推断不准，因为影响因素产生的效应被本来的效应覆盖了 knitr::include_graphics(&quot;images/paste_image18.jpg&quot;) 16.9.3 风险（risk） 也称作发病率（incidence或cumulative incidence），表示在一段给定时间里新增某种健康效应的比例 \\[risk = \\frac{new cases}{total individuals at risk}\\] 举例：5年风险0.1表示在5年里某个个体有10%的几率出现某种健康效应 前瞻性研究（prospective studies）常用，但控制性研究（case-control studies）里总体风险无法确定，不能使用。 16.9.4 比率（rate） 也称作发病率比率（incidence rates）表示在一个人群中某种健康效应出现的速度。单位为每个人年，个人年表示风险个体参与研究到出现健康效应的总时间 \\[rate = \\frac{new cases}{total person-time at risk}\\] 举例：0.1案例每个人年表示对于每10个人追踪1年或2个人追踪5年将会有一个案例出现 人群无限状态下，有 \\[risk = rate \\cdot time\\] 考虑到人口的指数衰减，有 \\[risk = 1 - exp(- rate \\cdot times)\\] 当风险率非恒定时，或者对时间分段计算，或者进行生存分析 人群出现稳态时，有 \\[\\frac{prevalence}{1-prevalence} = rate \\cdot Avg.Duration\\] 当患病率很低时，有 \\[prevalence = rate \\cdot Avg.Duration\\] 疾病的持续期可计算为 \\[Avg.Duration = \\frac{prevalence}{rate}\\] 16.9.5 其他频率测量 分类比率：如年龄，性别，种族等 病态比率：不致命的状态 死亡率 致死率：患病中导致死亡的比率 攻击率：短期食物中毒 生育率：育龄妇女一年内生育新生儿的比率 新生儿死亡率：一岁以下新生儿死亡率 特殊患病率：体检率，新生儿感染率，非新增 16.10 联系测量 测定频率不涉及对比，探索关系需要对比 不同暴露状态下的频率差或者比表征 16.10.1 风险比与比率比（risk ratio rate ratio） \\[risk ratio = \\frac{risk_{exposed}}{risk_{unexposed}}\\] \\[rate ratio = \\frac{rate_{exposed}}{rate_{unexposed}}\\] 表示暴露与健康效应的关系强度，1表示无关，但比例关系不能给出绝对差异 表述风险比不要使用更多或更少，如果更多或更少需要减一除以风险比：相比不服用，服用阿司匹林有0.57倍的心肌梗死风险或43%的风险下降 16.10.2 对照组 暴露量最小的一组通常作为风险比计算中的对照组 16.10.3 风险差（risk difference） \\[risk = risk_{exposed} - risk_{unexposed} = \\frac{cases in exposed group}{total at risk in exposed group} - \\frac{cases in control group}{total at risk in control group}\\] 正数表明对某种健康效应有促进作用，负数表示有抑制作用，要指明时间区段 16.10.4 归因比例（Attributable Proportion Among the Exposed） \\[attributable proportion = \\frac{risk ratio - 1}{risk ratio}\\] 暴露组风险中归因于该原因的比例 16.10.5 人群归因比例（Population Attributable Fraction） \\[population Attributable Fraction = (proportion of cases exposed) \\cdot (attributable proportion in the exposed)\\] 人群中风险归于该原因的比例 16.10.6 胜率比（odds ratio） \\[odds ratios = \\frac{odds_{exposed}}{odds_{unexposed}}\\] 常用在控制性研究里替代风险比或比率比，这时风险比无法计算，但几率比可以在总体效应比较小与特殊采样技术使用的时候近似于风险比或比率比，解释起来与它们一致 16.11 随机误差 偏差，混杂与随机误差是流行病学采样中最常见问题 随机误差也是采样误差 置信区间用来表示随机误差而非混杂偏差等误差 95%置信区间与p值计算方法一致，可用来判断是否统计显著 16.12 研究道德 无论目的如何，以人作为研究对象是不道德的 纳粹在二战期间集中营里使用人作为研究对象，1946年审批时提出Nuremberg Code： Voluntary consent of the human subject is absolutely essential. The experiment must yield generalizable knowledge that could not be obtained in any other way and is not random and unnecessary in nature. Animal experimentation should precede human experimentation. All unnecessary physical and mental suffering and injury should be avoided. No experiment should be conducted if there is reason to believe that death or disabling injury will occur. The degree of risk to subjects should never exceed the humanitarian importance of the problem. Risks to the subjects should be minimized through proper preparations. Experiments should only be conducted by scientifically qualified investigators. Subjects should always be at liberty to withdraw from experiments. Investigators must be ready to end the experiment at any stage if there is cause to believe that continuing the experiment is likely to result in injury, disability or death to the subject. 1964年，WMA接受赫尔辛基宣言 塔斯基吉梅毒研究，没有征得患者同意，也没有进行有效治疗，1972年泄漏，1974年美国出台人类被试保护法案，所有涉及人的研究需要通过IRB审核 1978年，议会出台人类被试研究指南 法律不强制，但基金一般有相关要求 相信研究有益等同于对其怀疑才可进行 安慰剂可以使用，但要保证患者最终能得到最好的治疗 16.13 临床实验 分为预防性与治疗性干涉研究 新药研发的四阶段 8-80人小规模评价安全性，副作用及副作用出现的剂量 80-200人中等规模测试有效性，副作用及与剂量的关系 200-40,000人大规模测试其与当前治疗方式的副作用强度 推向市场后的监测，测试罕见但严重的副作用，例如H1N1疫苗 16.13.1 研究对象 人群分层考虑是否为目标人群及是否愿意参加 内部验证准确性，外部验证广泛性 样本数由功效决定，由于疾病发病率低，很小的差异也需要很大的样本来保证功效 16.13.2 对照组与控制组 排除混杂因素需要考虑除考察因素外其他因素在研究客体中分配均匀 分配方法包括自我前后对比与随机非随机分配 屏蔽 单盲：被试不知道是否是处理组 双盲：研究人员与被试都不知道处理组 三盲：进行处理的人也不知道是否是处理组 安慰剂（placebo），也就是无效药 装假（sham），假装进行某个操作流程（有道德风险） 安慰剂效应：接受治疗的人都认为会从中收益，即使知道是安慰剂也会产生该效应 服从度，处理组与控制组要区分明显，内部一致 设计尽量简单 被试生活规律 通知明确 实时追踪 屏蔽处理信息 对不服从的仔细询问，收集未使用药片，收集血液尿样进行评价 掉队会导致功效降低及存在偏误 16.13.3 临床分析中的问题 随即控制时要给出基线信息 混杂因素可能不在基线里而是直接影响结果 如果混杂因素在调整前后影响结果超过10%，那么就要进行调整- 希望被处理分析，保证处理与对照中接受治疗的意愿接近 二次分析，只对接受的人进行结果分析，失去随机性与一定样本数及混杂控制 某项研究同时有利弊，利大于弊，是否继续研究？ 预防花费如果很高，是否值得推荐？ 16.14 队列研究 16.14.1 前瞻性队列研究 研究开始时没病，记录基线，追踪个人 案例：BMI与心脏病关系 16.14.2 回顾性队列研究 适合职业暴露，回溯暴露状况 案例：游泳池污染事件 16.14.3 双向队列研究 同时进行前瞻性与回顾性队列研究 较少见 案例：橙剂喷洒飞行员追踪，急性与慢性暴露 16.14.4 固定队列与开放队列 固定队列表示人数固定或只能减少，例如日本原子弹受害者追踪，多数研究是固定队列 开放队列表示人数动态，可随时加入 16.14.5 研究对象 一般人群队列或特殊暴露队列（事件幸存者） 对比组越接近越好，信息收集越全越好 内部比对：同队列未暴露被试，肥胖调查中不肥胖的人 外部比对：内部不存在未暴露时，例如化学品职业暴露 一般人群比对：从国家抽取基础数据，但因为健康工人效应现在不常用，可使用标准死亡率（SMR）或标准流行指数（SIR）来测量联系，也就是用基础数据计算期望值与实际值的对比 健康工人效应：能工作的工人比一般人群要健康 16.14.6 队列追踪 队列研究一般开始时没有偏见 追踪率低于60%不可靠，丢失20%可能因掉队原因关联结果导致偏误 不愿参与会导致偏差 回溯研究会因保留疾病比例高于保留正常病例的原因导致选择偏误 16.14.7 优点 直接给出暴露与效应的时间序列关系 可直接计算疾病的风险率 可用来评价稀有暴露 可用来同时评价多种暴露 基本无选择偏误 16.14.8 前瞻性队列研究缺点 耗时长 费用高 不适用稀有疾病 不适用潜伏期长疾病 掉队会导致偏差 16.14.9 回顾性队列研究缺点 不适用稀有疾病 记录不匹配研究需要结果不好 过去记录丢失混杂因素信息 暴露组与对比组很难区分 掉队会导致偏差 16.14.10 偏误 选择人群无法代表群体 产生原因 在病例控制研究中控制组没有代表性 追踪丢失率在控制与处理组不同 是否愿意参加影响暴露与结果 健康工人效应(职业暴露) 诊断标准不同 回顾性研究中回顾会放大暴露或结果 观察偏误，如果是非特异性区分错误，那会指向空假设 记录偏误，引导性问题 暴露比结果难评价，结果比暴露稀有，因而暴露更容易产生导致结论错误的偏误 灵敏度与特异性对风险比与风险差的影响不同 16.15 病例对照研究 现有案例，后回顾暴露状态，两者在研究前是独立的 适用于稀有疾病，只能计算胜率比而不能计算风险比 经常内置于已有的队列研究，适用于稀有疾病假设 当研究对象为人群而不是队列研究中的未发病人群时，允许发病者作为控制组 案例：DES与子宫癌 病例来源：住院病人、死亡证明、死亡注册、断面研究 对照来源：代表群体的组、独立采样且采样策略一致避免代表性丧失 随机电话访问是之前一种选择对照的方法，由于存在偏误（无法区分居民与商业电话，固定电话使用率降低）而逐渐被替代 对照组的数量选择要考虑统计功效 采样方法：幸存者采样，基于队列采样（按队列开始时风险人群），风险组采样（出现案例时存在风险的人群）后两种可以不考虑稀有假设，因为他们对照可代表整体，胜率比可用来估计风险比 优点：对罕见病高效，节约成本，可动态研究 缺点：选择偏误，对罕见暴露低效，不能计算风险 16.16 标准化 粗比率（crude rates）忽略了人群组成差异，需要调整 死亡率上如果两组中有一组老年人占总体比率高，那么会使两组风险比较时有偏差 用整体人群作为基础分布，比率乘各分组人数之后求和得到标准比率，其实质是将各分组年龄分布归一来消除年龄偏误 Standardized Incidence Ratios 标准发病率用整体发病概率作为基准，计算各分组发病人的期望值并对比观察值 16.17 混杂 混杂因素是同时对暴露与结果产生影响的因素，例如唐氏综合症研究中出生的顺序其实对病症无影响，孕妇年龄为该研究的混杂因素 混杂因素判据：对暴露与结果都有影响；在暴露组间分配不均；不能是暴露与结果的中间步骤（饮酒通过升高HDL来降低心血管病发病率，HDL与两者相关但不是混杂因素） 混杂因素可能是另一个风险，也可以是预防因素，也可以是其他替代物 残差混杂表示在排除混杂因素后由于排除不全或分类错误或未知导致的混杂 现象或禁忌混杂，暴露与结果实际受结果的反馈影响，例如抗抑郁药与绝育的关系中抑郁本事会对绝育产生影响，这样在观察研究中不易区分 因果互换，例如母乳对婴幼儿有益，但有研究发现母乳可能造成营养不良，但后来人们发现其实是因为调查人群中婴儿出现体重偏轻或腹泻的家庭往往会停止使用母乳喂养，案例；另一个案例是止痛药与肾衰的研究中并非服用止痛药导致肾衰而是因为糖尿病多导致肾衰而糖尿病人经常服用止痛药 研究设计中防止混杂可通过限制研究人群，个体匹配与随机化实现 数据分析中混杂控制－分层，例如年龄分组后原有差异可能就消失 多分层方法可采用CMH方法计算风险比，其实就是对分组比率加权来忽视分组因素的影响，影响因素多要采用多元分析 16.18 效应修饰（EMM） 指由于另外的变量导致效应分类的状态，例如年龄可能造成某种药药效相反，可理解为线性模型中的交互作用项- 测定有混杂因素与无混杂因素下的两个风险比，如果差异很大且差异区间包括原始风险比，则存在修正测量效应；如果差异不大但影响原始风险比，则要同时考虑混杂因素；如果两者同时存在，则要考虑分层讨论混杂的情况 存在EMM时不能使用CMH方法，因为此时样本不适合混合，应该分层讨论，可用卡方检验EMM的存在与否 统计交互作用与生物学的交互作用需要区分 16.19 多变量方法 本质上是多元回归，通过参数判断变量影响 混杂变量用增加参数的方法排除，参数变化超过10%可认为明显混杂 EMM用交互作用项排除，观察是否显著 最终模型是否含有不显著相具体分析 16.20 筛选 “detectable pre-clinical phase”或DPCP表示在筛选与有症状后检测之间的时间 筛选的价值（高血压中测血压） 疾病很严重（子宫癌） 症状发生前的治疗效果要比发生后好 DPCP疾病流行概率很高 筛选的限制 胆结石中预先检测对治疗没意义，都是大了以后手术去除 肺癌中检测到了也无法有效治疗 疾病不流行 好的筛选应具有的标准 便宜 容易操作 最小化不适 可靠 有区分 测试验证 灵敏度（真阳性占阳性比例） 特异性（真阴性占阴性比例） 真阳性预测值（真阳性占阳性比例）这个值会随流行度变化而变化，即使灵敏度特异性都高，较低的流行度也会降低预测准确性，所以测试要针对易感人群并计算流行度 真阴性预测值（真阴性占阴性比例） gold standard “金标” ROC曲线 左上方靠近 多数情况可以接受假阳性而提高灵敏度 前列腺癌筛查的案例 测试本身的缺点 低流行率的假阳性 假阴性 前列腺相关报道 过度测试 癌症测试 评估筛选中需要注意的偏误 宫颈癌，乳腺癌也在常见筛选之中 16.21 因果推断 因果推断在流行病学中很重要，但目前没有标准来界定因果而仅仅有一些指南。 16.21.1 Hill 因果标准 由流行病学家Austin Bradford Hill提出的9条判断因果关系的标准，充分不必要条件，不能作为清单使用。 16.21.1.1 联系强度 由风险比，比率比，胜率比来测量，越强代表因果联系越大，反之不成立。 16.21.1.2 数据一致性（Consistency） 一致性用来排除解释某健康效应的其他可能，缺少不代表没有，可能有其他共有因素，越强因果联系越大。 16.21.1.3 特异性（Specificity） 因素结果1对1，该标准不是特别有效，有些因素会对应多种结果。 16.21.1.4 时序性 因果必要条件，先有因后有果。 16.21.1.5 剂量效应关系 剂量效应关系是充分不必要条件，例如阈值效应。 16.21.1.6 生物合理性 基础研究，没有流行病学研究前的实验室数据如毒理学研究。 16.21.1.7 相干性 相干性表示新数据不应该与现有证据矛盾。 16.21.1.8 实验证据 随机控制实验的结果，改变原因结果不同。 16.21.1.9 类比 最弱的标准，主观性较强。 16.21.2 部分原因理论 Kenneth Rothman 提出，认为健康效应的原因可看成一个饼图，缺少任一部分结果都不会发生，用来了解结果的发生过程。 16.21.3 逆向模型（Counterfactual models） 考虑无暴露状态下是否产生效应的思路，群组水平考察。 16.21.4 有向无环图（DAGs） 概念流程图，考虑混杂因素。 16.22 论文研读 科研论文类型包括原始研究（描述性与分析性）、方法、荟萃分析与评论 文章结构包括题目、作者、摘要、前言、方法、结果、讨论、结论、致谢、文献引用与图表 依次浏览摘要（概况），前言（问题的重要性），讨论（看结论与意义），方法（看实验设计），结果（看图表）并记录疑点 16.22.1 Introduction What was the primary question that the authors were trying to answer? Why were they asking this? Rationale? What was their goal? 16.22.2 Methods What type of study design was used? Was this a logical choice, given the goals of the study? What are the weaknesses of this study design? What problems and biases might have occurred? How were subjects identified and enrolled? How successful was enrollment? Could selection bias have occurred as a result of control selection bias, or differential non-participation in a case-control study? Did selection of controls meet the “would” criterion? If it was a cohort study, how complete was follow up How carefully was the exposure of interest defined? How was the exposure assessed? What was the quality of the exposure data? Was exposure data validated? How carefully was the outcome of interest defined? How was it assessed? Was it validated? Could selection bias have affected the results? What was the potential for information bias? Non-differential misclassification? Errors in recording or coding of data? General inability of subjects to remember? Differential misclassification? Recall bias? Interviewer bias? Recorder bias? Differential quality of data? What were the likely confounding variables? Did the authors control for confounding in the design of the study, in the analysis, or both? Did they fail to account for any potentially important confounders? Was control of confounding adequate? Could there have been residual confounding? Did they perform stratified analysis? Did they use regression analysis? Would these problems bias toward the null or away from the nul? 16.22.3 Results Do the results suggest an association? If so, how was it assessed, and how strong was the association? Did the authors estimate risk ratios or risk differences? How precise were the measures of association? Was the sample size adequate? Did the authors report confidence intervals? p-values? Did the authors adequately assess random error? 16.22.4 Discussion Was the interpretation appropriate? Are the results of this study consistent with other studies in this area? If there are differences with other study findings, what could they be due to? 16.22.5 Conclusion What are the public health implications of the study? 16.22.6 Clinical Trial Were patients randomly assigned to the comparison groups? Was the study blinded? Did the patients or doctors know which group the patient was in? Was the randomization effective in creating two groups which were similar with respect to age, gender, race, and other potentially confounding variables? Did patients adhere to the treatment? Did patients drop out? Were appropriate statistical tests used to compare the groups? Were the groups analyzed based on their randomized assignment, i.e. a so-called “intention to treat analysis” Was the sample size large enough to detect a meaningful difference if it had existed? 16.22.7 Cohort Study How did they select the subjects in the comparison groups? Were the groups comparable with respect to other factors? How did they ascertain risk factor status? Was the data accurate? Could there have been bias? How complete was the follow up data? Was the statistical analysis appropriate? Did they control for possible confounding variables? Was the sample size adequate to detect clinically important differences if they existed? 16.22.8 Case-Control Study What was the source population? How were cases and controls defined? Was there selection bias? Was the ‘would’ criterion met? How was information collected? Was it accurate? Was it collected in a comparable way in both groups? Could there have been recall bias? Interviewer bias? Was the statistical analysis appropriate? Did they control for possible confounding variables? Was the sample size adequate to detect clinically important differences if they existed? 16.22.9 Screening Test If so, did they have an independent blind comparison with a reference diagnostic technique, i.e., a “gold standard”? Was the diagnostic test evaluated in an appropriate group of patients, similar to those you would find in your practice? Did they address the ability of the test to discriminate between normal and abnormal? How was abnormality defined? Did they calculate sensitivity and specificity or likelihood ratios or report their data in such a way that you could calculate them? 16.22.10 Additional Considerations Are the Findings Important? External Validity (Generalizability) "],["nlp.html", "第17章 自然语言处理", " 第17章 自然语言处理 早期依赖语言学家的文法，后来依赖统计模型，基础是语料库语言模型。n元语料库，一般是三元模型，计算当前词与前面两个词同时出现的及自己单独出现的概率。这个概率可以统计很多文章，通过tf-idf加权矩阵来计算每个词的加权概率。 为了防止出现零概率，可以用古德-图灵估计里为零概率的词赋很小的概率，这个概率来自低词频贡献，词频越低，对其他零词频词的概率贡献越多。也就是设定一个词频阈值，阈值之上不对概率扣减，阈值之下概率进行古德-图灵估计，零概率的均分前面打折省下来的概率。另一个思路是低元模型对高元模型的线性插值。 分词问题，可以用语料库计算出现某个序列的概率，概率最大的分词方法被选用。分词可以采用层级模型，颗粒度不同的分词存在各自最适用的应用场景。 隐马尔可夫模型（HMM），这是一个信号模型，给定一组状态序列，寻找对应的信号序列，例如翻译与语音识别。本质上是寻找产生最大概率的那一组信号，通过贝叶斯定理可以转换为寻找并最大化某信号下状态的条件概率与该信号合理出现概率的乘积。在HMM下，通过马尔可夫假设，我们只考虑每个信号前面的一个信号之间条件概率（也就是前面的语言模型）与当前信号状态条件概率乘积的连乘，然后用维特比算法（线性规划）找出最大值，也就是给定模型与输出信号，计算最可能出现的状态（语音识别问题）。同时，HMM可以解决给定参数后，计算某个输出序列的概率（输入法）。但HMM本身也需要进行参数估计，可以采用标注数据但成本高，也可以用EM的方法，先假设一个随机模型可以产生输出序列，前后转移概率随机，两两含义对应概率也随机，然后用数据输入模型计算所有路径概率，此时相当于标注了数据，用其计算最大似然度下的最优参数，然后再输入新参数，不断迭代直到新参数比旧参数对数据没有更高的最大似然输出概率 信息量比特数跟发生可能性的对数有关，信息量与发生概率的乘积的累积总和就是信息熵，信息熵越大，均质性越强，不确定性越高；反之，高概率信息的引入会降低不确定性，系统内额外相关的信息总会不增加不确定度（条件信息熵），由额外信息减少的信息熵是互信息，取值01之间，越大额外信息与原始信息越相关取值越高，可用来消除语言二意性。相对熵用来衡量两个文本信息熵的大小。自然语言处理考虑上下文是考虑了条件熵，考虑语境就是考虑了相对熵，语言复杂度就是给定上下文每个位置可选择的单词数量，语料库引入可提高模型准确度。 布尔逻辑可用来进行索引表的检索，图论与深度／广度优先算法，爬虫找到页面，提取链接，构建哈希表存储，可采取异步分批存储与定向发送（网页聚类），pagerank 通过计算网页链入链出的数量与质量迭代来确定网页的重要程度，在进行关键词检索时，首先依赖词频，但要去掉高频词，同时如果某个词词频高但出现在独立网页中比较多时（类高频词）可以用逆词频，也就是网页总数除以出现该词的页面数的对数来对词频加权，如果在独立网页中出现概率高，信息量大，其总排序要靠前，这样可以筛选出跟查询词比较接近的语境（TF-IDF） 语音识别需要用到动态规划与有限状态机来降低计算／搜索成本 高维相似度可以用余弦定理来计算，首先得到每个样本的特征向量，然后计算相似度，高的归为一类，然后同一类中计算余弦相似度不断归类。不同的相似度可以用不同的权重来表示 同时，也可以用矩阵计算来进行分类，对矩阵进行奇异值分解，左边酉矩阵可以提取特征跟主题相关性，右边则可提取主题与样本相关性，可快速进行较粗的分类，而余弦定理就需要不断迭代。 相似哈希表可用来快速比较相似度 费马小定理可用来进行基于质数的加密 最大熵模型可用来计算存在影响因素下（或者说特定语境下）的出现概率问题，这是一个指数模型，需要训练的参数非常多，但也可以用em方法求解训练。 输入法可通过动态规划方法求解备选词，同时可以用余弦定理来构建个人语言模型与整体语言模型的插值模型，这是一个最大熵与通用的折衷方案，其实也是最优的 布隆过滤器，对字符随机转换为8个数字，然后构建一个二进制长向量，将8个数字对应的位置设为1，如果某个地址出现同样位置为1，那么过滤掉，用较小的空间对比较大的数目，比计算哈希值省空间，可用来快速过滤垃圾邮件 贝叶斯网络，条件概率的网络，训练出的模型可以预测其中变量间关系，然后可以反过来调整模型结构，例如我们可以知道文本对应的主题，也可以知道主题对应的文本，这样在主题跟文本还有关键词间可以构建一个有向网络来探索其之间的相互关系 如果关系是无向的贝叶斯网络那就是条件随机场，可用来解决句法分析问题 NLP词向量法来快速线性搜索相关词 tidytext包 quanteda包 jieba中文分词 "],["qi.html", "第18章 量化投资 18.1 股票收益模型 18.2 风险 18.3 收益 18.4 一般性投资 18.5 风险管理原理 18.6 金融技术与发明 18.7 投资组合 18.8 保险 18.9 有效市场假说 18.10 行为经济学 18.11 债券 18.12 银行 18.13 金融监管 18.14 信用评级 18.15 投行 18.16 股票 18.17 房产 18.18 期货 18.19 期权 18.20 金融民主化", " 第18章 量化投资 18.1 股票收益模型 股票指数可代表市场，收益率\\(r_M\\) 某股票跟市场的相关性是市场贝塔（market beta）\\(\\beta_M\\) 市场之外的贡献阿尔法\\(\\alpha\\) 特定股票收益率 \\(r = \\alpha + \\beta_M r_M\\) 资本资产定价模型（capital asset pricing model, CAPM）：所有股票阿尔法部分期望是零 套利定价理论（arbitrage pricing theory, APT）：除了市场因素，还有其他公用因素来解释股票收益 宏观经济因子模型（macroeconomic factor model, MFM）：\\(r_i = u_i+\\sum_{k=1}^{K}\\beta_{ik}f_k\\) 成熟的商业模型可以确定一些共同因素，但也面临不确定性 18.2 风险 单只股票波动很大，一般会组合投资降低风险 单只股票波动率\\(\\sigma_i\\)，两只股票之间的相关系数\\(\\rho_{ij}\\)，股票组合波动率\\(\\sigma_p^2 = \\sum_{i=1}^nw_i^2\\sigma_i^2 + \\sum_{i\\neq j}w_i\\sigma_i\\rho_{ij}\\sigma_jw_j\\)，其中\\(w\\)是股票权重 两两间需要估计的参数多 因为组合的股票多而共同因素少，可以直接估计与共同因素的相关性来替代总体估计 但是除了共同部分还有股票特有特征，所以个股的波动是个体波动与整体波动的综合 \\(\\sigma_i^2 = \\sigma_{S,i}^2 + \\sum_{l,m = 1,...,K}\\beta_{il}\\sigma_i\\rho_{lm}\\sigma_m\\beta_{im}\\)，这里我们认为股票间波动可以用共同波动来解释\\(\\sigma_i\\rho_{ij}\\sigma_j = \\sum_{l,m = 1,...,K}\\beta_{il}\\sigma_i\\rho_{lm}\\sigma_m\\beta_{im}\\) 所谓风险控制就是通过对每只股票权重的调节优化来降低波动率，但结果不稳定 通过风险控制就可以计算收益率，但毕竟有些因素是不可控的，解决的方法就是通过权重调整让其对总收益贡献为零或做空该因素对冲风险 风险价值VaR：在某个特定时间段内损失特定金额的概率。一项风险价值为一年5%的总额为1万美元的投资，在一年结束时损失超过1万美元的可能性为5%。简单公式\\(2M\\sqrt{N}\\)，N次事件中2.5%概率出现M变动的风险价值 18.3 收益 共同因素的收益可通过投资市场指数来获得 某特定共同因素的收益需要自己构建，smart beta 这属于被动投资，因为股票市场长期看总是上涨，所以收益不差 也存在主动投资，根据自己预测投资并不断调整，smart beta属于半被动投资 特异收益方面可以进行择时收益（timing skill），但一定注意风控 18.4 一般性投资 三要素：成本、收益、风险 时间序列分析：统计学 技术分析：根据价格曲线图形进行分析的一种方法，技术分析本质是经验分析，可以量化为模式进行识别，有些指标可以进行机理解释 收益的统计分析 - 环比：以月为周期的相对收益率 - 同比：以年为周期的相对收益率 - 收益率一般是正态分布，但也可能是肥尾的，极端事件发生概率高；甚至是长尾，比较极端事件也有可能发生；还有可能出现黑天鹅，非常极端事件 - 可预见事件会有过度反应然后回调，可进行事件驱动投资 影响价格因素的分析，要考虑专业知识、随机性、噪声、数据来源、混杂因素 18.5 风险管理原理 概率论是核心，17世纪出现，保险基础 概率乘法规则，每件事都是独立的，联合发生概率是乘积，保险公司认为被保的事相对独立不会同时发生，因为概率特别低 二项分布可用来估计准备金比率 均值表示集中，几何均值用来估计收益表现，全是正数，比算术均值小 方差表示离散 风险需要高均值低方差的收益率 协方差表示两个变量共同变动的能力 相关性是协方差除以各自的标准差 回归线截距就是阿尔法，斜率就是贝塔 现值就是某物当前的价格，n年后C元的现值是\\(C/(1+r)^n\\)，r是利率 永续国债每年承诺固定年金C，其现值计算就是个等比数列，等于\\(C/r\\)，利率越高国债不值钱，利率低时现值高 永续国债也可以承诺每年年金增长，年金现值等于\\(C/(r-g)\\)，g是增长利率，一定小于市场利率 固定期限年金C付款n年，现值是\\(C\\frac{1-(1/(1+r)^n)}{r}\\)，利率越高，年限越小，现值越高，贷款买房就是如此，按揭与利率年限有关，年限越长实际现在花的越少，流动性好 效用函数U表示钱的边际效果，钱越多，边际效果越低 18.6 金融技术与发明 长期风险，最大的是道德风险（共同利益与个人利益的冲突） 经济风险都是可以分担的，消费行为之间是有关联的，社会主义思想下消费行为趋同，通过计划分配来控制分摊风险，但道德风险无法规避 框架效应，含义相同但说法不同会导致不同的决策判断 公共财政设计税收与福利来控制社会风险，避免道德问题 心理账户多是货币框架，但实物框架要考虑消费指数与通胀 发明，技术推动金融发展，解决风险问题与框架效应 标准化、行政机构、社会保障、邮政服务促进了金融业的发展 信用违约交换CDS A借钱给B，但担心B借钱不还，就向C买一份保险，如果B违约，那么C赔付，如果B不违约，那么C净赚。如果B表现很好，那么A可以把买的CDS返卖给C来减少损失，如果表现不好，C也可到期前高价回收CDS来降低风险。这种关系不需要长期维持，可用来交易投机。 18.7 投资组合 高收益低方差组合 资产通常不独立 寻找预期、标准差、协方差的投资组合，找出有效边界，构成共同基金 所有共同基金都试图通过多样化来进行高收益低方差投资并试图打败市场 美国股市受益长期高于债券，约4%，发达国家类似，这个现象与政治有关系 税收，特别是受益税（企业利润税与个人所得税）对经济有重要调节作用 全球范围，企业利润约1/3会被课税（实际税率） 投资管理包括资产配置（多样化，占90%）、入场时机与证券选择 交易行为本身会对市场产生影响出现系统损耗与负和博弈 对冲基金存在生存偏差与回填偏差，多元化可以让投资平稳 如果要打败市场，就要主动出击，在多元化保护下平衡风险，吸纳各种来源的非传统投资收益，获取超额收益 18.8 保险 保险与共同基金一样都是通过汇集分摊个体风险管理受益的金融工具，共同基金的受益目标是增值，保险的受益目标是保值与未来损失，个体好恶会导致保险与基金成本不同 面对道德风险与选择歧视（只有有风险的买保险） 当独立个体风险汇聚一体（二项分布接近正态分布）时，整体风险的期望不变但方差可测算控制 合同设计用来标注风险、例外（规避道德风险与选择歧视）、数学模型、公司类型、政府监管（准备金） 两种公司，综合险种保险公司与单一险种保险公司，后者风险大、监管严（次贷危机影响） 主要类型：财产保险/健康保险/人寿保险 寿险保护孩子（遗产），比财险规模大 汽车保险收入最高，然后是住房保险 始于1600s，金融创新推动 1840s，高薪雇佣保险推销员来推动人们天生的抗拒（农业保险） 1900s，具有现金属性的保险，可升值，但取消后也损失，防止取消保险 19世纪卖给女性丈夫的保险，用宗教转述消除掉道德抵触 次贷危机中为债券提供保险的公司购买了大量次贷产品，当评级降低时，出现系统恐慌与抛售，政府举债募资困难，社会衰退 气候变化导致的风险是全球性的，也会导致社会衰退，这个风险在提高 巨灾债券：没有灾难时发行，有灾难时不偿付或少量偿付，一般是城市发行，用来均摊风险，收益率高与市场相关性低 18.9 有效市场假说 市场价格反映所有有效信息 股价反映未来股息价格的现值，否则就是击鼓传花，股息代表盈利能力 随机行走理论 \\(x_t = x_{t-1}+error\\) 一阶自相关回归 因为自相关数据可能回归原点 Grossman and Stiglitz paradox：如果投资者相信有效市场假说，他们就会停止分析，从而导致市场效率低下；而如果投资者认为市场效率低下，他们就会应用模型进行分析，从而提高市场效率。 18.10 行为经济学 股市是随机运行，现值一直平稳增长 期望效用曲线，在预期值附近厌恶损失喜欢收益 权重理论，对于确定性的事给更高的权重 祝愿性思考，总认为自己心仪的一方会表现好 注意力无法长期集中 锚定效应，指标锚定 赌博行为 迷信行为 营销手段：吹嘘、隐藏信息、病毒营销与过度交易 18.11 债券 今天的价格*利率=未来的现金流 债券是过去的固定利率 当前利率提升，债券贬值 当前利率下降，债券升值 短期折扣债券(bills，低于一年)，低于面值发售 中期债券(notes, 一年到十年)，付息 长期债券(bonds, 大于十年)，6个月付息一次，老式债券附带利息券，付息时剪下来去银行兑换钱 物价指数债券，调整过通胀或CPI的债券，早期指定物品来实现 中间商赚取买入卖出价的价差，流动性好的资产价差小，差的或市场小的价差大，卖方主导 利率期限结构，不同期限收益率与到期期限的关系 利率跟债券价格反向变动 18.12 银行 西方起源于金匠对黄金的保存，采用部分准备金制度进行借贷 银行分为商业银行、储蓄银行、存储协会与信用合作社 商业银行规模比较大，美国20%的银行资产是外资 信用合作社数量比较多，但资产规模小，多为区域内或行业内的 存储协会规模中等，数量不多 银行解决逆向选择问题，经营核心是关系，对借贷进行筛选 银行可以避免企业对债主不道德的资金使用 银行提供资金流动性，长贷短存，需要准备金应对挤兑但要保证企业有长期资金 发展中国家因为金融体系不健全，银行体系往往规模很大，关系国计民生 1988，巴塞尔条约规定银行风险标准 里根政府不限制存储协会存款利率，结果风险积聚，最后政府埋单 墨西哥政府银行私有化，结果银行过量发放贷款最后全部倒闭，墨西哥银行被海外资本控制 亚洲金融危机，外资集中撤资，大量银行倒闭 阿根廷银行挤兑风潮 美国影子银行发行商业短期借贷票据，银行通过内部组织（SIV）变相担保，但却不接受银行体系监管，出现风险积聚 央行是银行的银行，自然发展产物，防止通胀与失业，调节手段主要是准备金率与利率 18.13 金融监管 信息纰漏 电话销售促进“锅炉房”交易所的出现 SEC成立 不上市公司无法向公众登广告例如私募对冲基金，但也要接受监管，例如资产达标等 局内人与局外人监管，防止内幕信息出现公开时间差 会计监管 SIPC 证券投资保护公司 18.14 信用评级 穆迪评级 1909 S&amp;P 1916 统计方法评级 经营关系 接收被评级费用，用制度避免道德风险 18.15 投行 投行是承销证券的机构，不从事对个人的存储与券商业务，主要针对公司票据的发行 投行是解决信息不对称的，需要维护较高声誉来担保发行 投行可以包销或代销证券 预申报阶段，证监会监管发行，严禁公开讨论 文件申报静默期，红鲱鱼预招股书披露信息 证监会通过后可发行证券 通常首次发行也就是IPO时，投行会考虑低价制造高交易量与首日发行价 18.16 股票 公司是法人，要有董事会，公司就是为了盈利存在，向股东负责 非盈利公司不发行股票，但也有董事会 公司通常会进行股票分割，让股价维持在可买范围（20-40美元），一般一手100股 买股票是为了股息，股息董事会决定 净值与股票收益比例为PE，一般为15，也就是投资者15年收益回本，收益会计算出来的 股息除收益现在都是小于1，说明公司在留钱投资，大于1则出现在大萧条 公司可以进行股票回购，与分红本质一样，股利政策不影响价值 公司可以举债，提高杠杆率，举债不收税，但债务过高会导致破产成本高 林特纳模型认为股息的发放会影响价值与市场反应，股息与盈利间要进行平滑，稳定股息的发放 股票买卖要通过经纪人或交易商，前者收取买卖双方佣金，后者自己拥有资产，一个人不能同时是交易商与经纪人 交易商与经纪人可以由同一公司管辖，受到监管需要执照 股票市场有分级，一级纽交所，二级纳斯达克，三级市场小盘股粉单，四级市场大宗交易 交易是技术推动的，从纸到复写纸、打印机、电报、自动收录机，跨市场交易系统 纽交所曾经允许租用股票，大萧条后禁止 交易单分为市场订单与限制订单，前者按当前价格成交，后者除了数量还要求价格 目前交易是网上公开订单了 股票市场成立基础是人人平等与限制负债 股市存在羊群效应，散户追随机构大单，惧买是想等卖出大单进一步下跌再买，惜售是等大单进一步上涨再卖 Gopikrishnan等人发现从5分钟到120分钟的美股个股和指数的尾部都服从幂律形式，其正尾标度指数略大于负尾标度指数，但都接近于3 在中国股市中，惧买效应要大于惜售效应。 在中国股市中，不同市场时期的惧买与惜售效应的强度是不一样的：牛熊时期的惧买与惜售效应要大于震荡时期的惧买与惜售效应。 聪明钱交易，设计聪明系数Q，前20%聪明交易量占总交易量的比例，越高说明悲观逢高出货，越低说明乐观逢低吸筹，按Q排序，选最小的持有一个月卖出，聪明交易用惜售来表示 18.17 房产 美国房产规模与股票接近 房地产存在DPP，有限合伙制，可避税 商业房地产公司 REITS 限制很多 商业用房也可算资产，但不算地产公司 贷款价值比不能超过1 最早房产贷款期限很短，只有5年，贷款价值比不超过60%，但只还利息，最后还本金，续约时如果房产贬值就会收回房子 美国出台房屋贷款公司，提供15年贷款，但本息一起还 后来贷款进一步延长到30年，但因为考虑退休后收入下降，一般不超过30年 后来出现面向低收入者的2+28浮动利率贷款，但后面利率很高 房贷按揭固定还款最开始还的是利息，越往后本金比例越高，公式等同年金计算公式 房地产业存在全球尺度的非理性繁荣 18.18 期货 起源于日本农产品交易，每日交易结束会有导火线与泼水活动 最开始是现货交易，之后出现远期合约，约定货币交割的地点与日期的合同 期货跟远期合约的最大区别在于货品进行了标准化处理，这样交易流动性提高 期货价格的公允价格等于现货价格乘以一加到期利率与存储成本或其他成本 股指期货对标股票指数的期货，价格等于远期价格乘以现在价格在利率与分红调整的数，如果利率等于分红，那么期货与现价几乎一样，市场规模与股票类似 石油期货里存储成本很高 房地产指数期货 18.19 期权 包含行权日与行权价格 call 看涨 put 看跌 美式期权与欧式期权，后者只讨论行权日价格 1973 芝加哥首个期权交易所 CBOE 期货也有期权 股票与期权组合可以无风险套利 Black-Scholes 公式 可作为风险管理工具 18.20 金融民主化 政府是社会风险管理者，金融要提供工具 道德与职业化 行为经济学中普通人是弱势方 工资退税 德国 1883 全民社保 美国照搬德国，社会保险是个人企业配比的 破产法允许个人破产，比离婚比率高 小额贷款银行与慈善 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
